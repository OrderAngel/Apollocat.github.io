<!DOCTYPE html>


<html lang="zh-Hans">


<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="记录，学习，娱乐，博客" />
   
  <meta name="description" content="四界云官" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    论文收集 |  四界
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/greencat2.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">
  
<link rel="stylesheet" href="/css/custom.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  


<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

</html>

<body>
  <div id="app">
    
      
      <canvas width="1777" height="841"
        style="position: fixed; left: 0px; top: 0px; z-index: 99999; pointer-events: none;"></canvas>
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-论文收集"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  论文收集
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/%E8%AE%BA%E6%96%87%E6%94%B6%E9%9B%86/" class="article-date">
  <time datetime="2021-06-16T01:59:15.000Z" itemprop="datePublished">2021-06-16</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%A7%91%E7%A0%94/">科研</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">4.1k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">23 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="一、智慧交通"><a href="#一、智慧交通" class="headerlink" title="一、智慧交通"></a>一、智慧交通</h1><h2 id="1-1"><a href="#1-1" class="headerlink" title="1-1"></a>1-1</h2><p>   Real-Time Adaptive Traffic Control System For Smart Cities <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9402597">智慧城市实时自适应交通控制系统</a></p>
<ul>
<li><strong>作者</strong>：Shyam Shankaran R; Logesh Rajendran</li>
<li><strong>会议</strong>: 2021 International Conference on Computer Communication and Informatics (ICCCI)</li>
<li><strong>引用</strong>：0，浏览24</li>
<li><strong>摘要</strong>：In-country like India, billions of people start and end each working day stuck in traffic or commuting on congested trains and buses. It is vital to the quality of life to enhance the everyday commute. By 2025, cities that implement smart mobility systems on average, reduce commuting cycles by 15-20 percent, with some individuals experiencing even greater reductions. Depending on each city’s density, current transit facilities, and commuting habits, the capacity associated with each application is highly variable. Slowed synchronization of traffic signals leads to traffic congestion and delays. The pre-programmed, regular signal timing patterns are employed in traditional signal systems. To overcome the problems of traditional traffic control systems, there is a shift in adaption to an Adaptive traffic control system. The Adaptive Traffic Control System (ATCS) is a traffic management technique that modifies or adapts the timing of traffic signals based on the real demand for traffic and achieved using a control system that includes both hardware and software, where hardware is the sensor used for real-time traffic density estimation and software is designed using captured data analysis of the city’s current traffic flow. This paper depicts a model of camera-based traffic monitoring and processing system which reduces the cycle time and possesses special provisions for emergency vehicles.</li>
<li><strong>点评</strong>：使用opencv，光学传感器，偏向图像识别。</li>
</ul>
<h2 id="1-2"><a href="#1-2" class="headerlink" title="1-2"></a>1-2</h2><p>   Big Traffic Data Analytics For Smart Urban Intelligent Traffic System Using Machine Learning Techniques <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9291790">使用机器学习技术的智慧城市智能交通系统大交通数据分析</a></p>
<ul>
<li><strong>作者</strong>：Su Su Hlaing; Mie Mie Tin; Mie Mie Khin</li>
<li><strong>会议</strong>：2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)</li>
<li><strong>引用</strong>：1，浏览138</li>
<li><strong>摘要</strong>：Due to huge number of private and public vehicles in last two decades, the traffic load and congestion have increased significantly, which is major problem in transportation system. An intelligent traffic management system becomes an important part of the transportation system to manage the traffic properly in smart cities. In this paper, we have proposed intelligent traffic management system to build smart platform in Mandalay, Myanmar. The main aim of the paper is to reduce traffic congestion, road crash accidents, fuel consumption and save travel time. To provide safe, comfortable, and less frustrating travel, this paper uses big data technology and machine learning technique for analysis of the volume of traffic data and predicts optimal road traffic using machine learning.</li>
<li><strong>点评</strong>：论文很短，比起具体方法更像是框架构想。</li>
</ul>
<h2 id="1-3"><a href="#1-3" class="headerlink" title="1-3"></a>1-3</h2><p>   Internet of things — smart traffic management system for smart cities using big data analytics <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8301496">物联网——使用大数据分析的智慧城市智能交通管理系统</a></p>
<ul>
<li><strong>作者</strong>：Abida Sharif; Jianping Li; Mudassir Khalil</li>
<li><strong>会议</strong>：2017 14th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)</li>
<li><strong>引用</strong>：10，浏览2600</li>
<li><strong>摘要</strong>：Smart Traffic System (STS) is a one of the important aspect for future smart city. STS is more expensive and highly configurable to provide better quality of service for public traffic management. This paper proposes a low cost future STS to provide better service by deploying traffic update instantly. Low cost vehicle detecting sensors are fixed in the middle of road for every 500 meters. Internet of Things (IoT) is being used to attain public traffic data quickly and send it for data processing. The Real time streaming data is sent for Big Data analytics. There are several analytical scriptures to analyze the traffic density and provide solution through predictive analytics.</li>
<li><strong>点评</strong>：比较宏观，缺少细节</li>
</ul>
<h2 id="1-4"><a href="#1-4" class="headerlink" title="1-4"></a>1-4</h2><p>   Towards An Optimized Smart Traffic for Congestion Avoidance with Multi Layered (ST-CA) Framework<br>   <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8538401">使用多层 (ST-CA) 框架实现优化的智能交通拥塞避免</a></p>
<ul>
<li><strong>作者</strong>：Nada M. Alhakkak; Ban Salman; Najeeb Abbas Al-Sammarraie</li>
<li><strong>会议</strong>：2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE)</li>
<li><strong>引用</strong>：1，浏览127</li>
<li><strong>摘要</strong>：In many cities around the world, traffic congestion is considered a major problem that should be managed properly. Managing traffic flow is not simply applied by constructing new road or maintaining old ones; it is not just a matter of physical infrastructure. For managing traffic, there should be ‘’smart’’ ways to be taken by the use of available technologies’ facilities. Countries should think and act smart to manage today’s traffic in their cities. The use of controlled smart traffic systems is gaining a noticeable interest for the past few years and various solutions have been proposed, adopted and even implemented in several countries. In this paper, we propose Smart Traffic for Congestion Avoidance with Multi Layered (ST-CA) Framework, for solving the congestion problem. The proposed framework is constructed in multilayer approach for easy maintenance in the future. The STCA framework should be more flexible, in sending/ receiving messages, than others and depend in its decision making on expert systems.</li>
<li><strong>点评</strong>：交通控制框架，信号灯算法，针对交通堵塞</li>
</ul>
<h2 id="1-5"><a href="#1-5" class="headerlink" title="1-5"></a>1-5</h2><p>   Foundations for Smarter Cities <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/5512826">智慧城市的基础</a></p>
<ul>
<li><strong>作者</strong>：C. Harrison; B. Eckman; R. Hamilton</li>
<li><strong>年份</strong>：2010</li>
<li><strong>发表</strong>：IBM Journal of Research and Development</li>
<li><strong>引用</strong>：499，浏览1357</li>
<li><strong>摘要</strong>：This paper describes the information technology (IT) foundation and principles for Smarter Cities™. Smarter Cities are urban areas that exploit operational data, such as that arising from traffic congestion, power consumption statistics, and public safety events, to optimize the operation of city services. The foundational concepts are instrumented, interconnected, and intelligent. Instrumented refers to sources of near-real-time real-world data from both physical and virtual sensors. Interconnected means the integration of those data into an enterprise computing platform and the communication of such information among the various city services. Intelligent refers to the inclusion of complex analytics, modeling, optimization, and visualization in the operational business processes to make better operational decisions. This approach enables the adaptation of city services to the behavior of the inhabitants, which permits the optimal use of the available physical infrastructure and resources, for example, in sensing and controlling consumption of energy and water, managing waste processing and transportation systems, and applying optimization to achieve new efficiencies among these resources. Additional roles exist in intelligent interaction between the city and its inhabitants and further contribute to operational efficiency while maintaining or enhancing quality of life.</li>
<li><strong>关键词</strong>：Information technology, Urban areas, Smart buildings, Decision making, Intelligent structures, Structural engineering</li>
<li><strong>点评</strong>：宏观框架，需要一读</li>
</ul>
<h2 id="1-6"><a href="#1-6" class="headerlink" title="1-6"></a>1-6</h2><p>   Three Decades of Driver Assistance Systems: Review and Future Perspectives <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/6936444">驾驶辅助系统的三个十年：回顾和未来展望</a></p>
<ul>
<li><strong>作者</strong>：Klaus Bengler; Klaus Dietmayer; Berthold Farbe</li>
<li><strong>年份</strong>：2014</li>
<li><strong>发表</strong>：IEEE Intelligent Transportation Systems Magazine</li>
<li><strong>引用</strong>：414，,浏览10237</li>
<li><strong>摘要</strong>：This contribution provides a review of fundamental goals, development and future perspectives of driver assistance systems. Mobility is a fundamental desire of mankind. Virtually any society strives for safe and efficient mobility at low ecological and economic costs. Nevertheless, its technical implementation significantly differs among societies, depending on their culture and their degree of industrialization. A potential evolutionary roadmap for driver assistance systems is discussed. Emerging from systems based on proprioceptive sensors, such as ABS or ESC, we review the progress incented by the use of exteroceptive sensors such as radar, video, or lidar. While the ultimate goal of automated and cooperative traffic still remains a vision of the future, intermediate steps towards that aim can be realized through systems that mitigate or avoid collisions in selected driving situations. Research extends the state-of-the-art in automated driving in urban traffic and in cooperative driving, the latter addressing communication and collaboration between different vehicles, as well as cooperative vehicle operation by its driver and its machine intelligence. These steps are considered important for the interim period, until reliable unsupervised automated driving for all conceivable traffic situations becomes available. The prospective evolution of driver assistance systems will be stimulated by several technological, societal and market trends. The paper closes with a view on current research fields.</li>
<li><strong>关键词</strong>：Vehicle safety, Sensor systems, Laser radar, Advanced driver assistance systems, Vehicle dynamics, Automatic control, Research and development, Technology forecasting</li>
<li><strong>点评</strong>：综述类型，需要一读。</li>
</ul>
<h1 id="二、雷达-AI-无人驾驶"><a href="#二、雷达-AI-无人驾驶" class="headerlink" title="二、雷达+AI+无人驾驶"></a>二、雷达+AI+无人驾驶</h1><h2 id="2-1"><a href="#2-1" class="headerlink" title="2-1"></a>2-1</h2><p>   On-Road Vehicle Detection and Tracking Using MMW Radar and Monovision Fusion <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/7463071">使用毫米波雷达和 Monovision Fusion 进行道路车辆检测和跟踪</a></p>
<ul>
<li><strong>作者</strong>：Xiao Wang; Linhai Xu; Hongbin Sun; Jingmin Xin; Nanning Zheng</li>
<li><strong>年份</strong>：2016</li>
<li><strong>发表</strong>：IEEE Transactions on Intelligent Transportation Systems</li>
<li><strong>引用</strong>：80，浏览4229</li>
<li><strong>摘要</strong>：With the potential to increase road safety and provide economic benefits, intelligent vehicles have elicited a significant amount of interest from both academics and industry. A robust and reliable vehicle detection and tracking system is one of the key modules for intelligent vehicles to perceive the surrounding environment. The millimeter-wave radar and the monocular camera are two vehicular sensors commonly used for vehicle detection and tracking. Despite their advantages, the drawbacks of these two sensors make them insufficient when used separately. Thus, the fusion of these two sensors is considered as an efficient way to address the challenge. This paper presents a collaborative fusion approach to achieve the optimal balance between vehicle detection accuracy and computational efficiency. The proposed vehicle detection and tracking design is extensively evaluated with a real-world data set collected by the developed intelligent vehicle. Experimental results show that the proposed system can detect on-road vehicles with 92.36% detection rate and 0% false alarm rate, and it only takes ten frames (0.16 s) for the detection and tracking of each vehicle. This system is installed on Kuafu-II intelligent vehicle for the fourth and fifth autonomous vehicle competitions, which is called “Intelligent Vehicle Future Challenge” in China.</li>
<li><strong>关键词</strong>：Radar tracking, Radar detection, Vehicle detection, Vehicles, Cameras, Sensors</li>
<li><strong>点评</strong>：SVM，协同融合毫米波雷达和单目摄像头，可以关注一下“智能汽车未来挑战赛”，需要一读。</li>
</ul>
<h2 id="2-2"><a href="#2-2" class="headerlink" title="2-2"></a>2-2</h2><p>   Architecture Design and Implementation of an Autonomous Vehicle <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8340798">自动驾驶汽车的架构设计与实现</a></p>
<ul>
<li><strong>作者</strong>：Wenhao Zong; Changzhu Zhang; Zhuping Wang</li>
<li><strong>年份</strong>：2018</li>
<li><strong>发表</strong>：IEEE Access </li>
<li><strong>引用</strong>：12，浏览11325</li>
<li><strong>摘要</strong>：Architecture design is one of the most important problems for an intelligent system. In this paper, a practical framework of hardware and software is proposed to reveal the external configuration and internal mechanism of an autonomous vehicle-a typical intelligent system. The main contributions of this paper are as follows. First, we compare the advantages and disadvantages of three typical sensor plans and introduce a general autopilot for a vehicle. Second, we introduce a software architecture for an autonomous vehicle. The perception and planning performances are improved with the help of two inner loops of simultaneous localization and mapping. An algorithm to enlarge the detection range of the sensors is proposed by adding an inner loop to the perception system. A practical feedback to restrain mutations of two adjacent planning periods is also realized by the other inner loop. Third, a cross-platform virtual server (named project cocktail) for data transmission and exchange is presented in detail. Through comparisons with the robot operating system, the performance of project cocktail is proven to be considerably better in terms of transmission delay and throughput. Finally, a report on an autonomous driving test implemented using the proposed architecture is presented, which shows the effectiveness, flexibility, stability, and low-cost of the overall autonomous driving system.</li>
<li><strong>关键词</strong>：Robot sensing systems, Autonomous vehicles, Cameras, Millimeter wave radar, Laser radar, Wheels</li>
<li><strong>点评</strong>：论文里有三种传感器方案的比较，车的自动驾驶操作系统，硬软件都有，可以大致读一下</li>
</ul>
<h2 id="2-3"><a href="#2-3" class="headerlink" title="2-3"></a>2-3</h2><p>   Deep Learning-based Object Classification on Automotive Radar Spectra <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8835775">基于深度学习的汽车雷达光谱对象分类</a></p>
<ul>
<li><strong>作者</strong>：Kanil Patel; Kilian Rambach; Tristan Visentin</li>
<li><strong>年份</strong>：2019</li>
<li><strong>发表</strong>：2019 IEEE Radar Conference (RadarConf)</li>
<li><strong>引用</strong>：17，浏览1528</li>
<li><strong>摘要</strong>：Scene understanding for automated driving requires accurate detection and classification of objects and other traffic participants. Automotive radar has shown great potential as a sensor for driver assistance systems due to its robustness to weather and light conditions, but reliable classification of object types in real time has proved to be very challenging. Here we propose a novel concept for radar-based classification, which utilizes the power of modern Deep Learning methods to learn favorable data representations and thereby replaces large parts of the traditional radar signal processing chain. We propose to apply deep Convolutional Neural Networks (CNNs) directly to regions-of-interest (ROI) in the radar spectrum and thereby achieve an accurate classification of different objects in a scene. Experiments on a real-world dataset demonstrate the ability to distinguish relevant objects from different viewpoints. We identify deep learning challenges that are specific to radar classification and introduce a set of novel mechanisms that lead to significant improvements in object classification performance compared to simpler classifiers. Our results demonstrate that Deep Learning methods can greatly augment the classification capabilities of automotive radar sensors.</li>
<li><strong>关键词</strong>：Deep learning, Automotive engineering, Azimuth, Radar imaging, Radar tracking, Training</li>
<li><strong>点评</strong>：CNN应用于分析雷达光谱，优化传统雷达信号处理方法，可用的现实世界训练数据有限情况下。</li>
</ul>
<h2 id="2-4"><a href="#2-4" class="headerlink" title="2-4"></a>2-4</h2><p>   Robust vehicle localization in urban environments using probabilistic maps <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/5509700">使用概率图在城市环境中进行稳健的车辆定位</a></p>
<ul>
<li><strong>作者</strong>：Jesse Levinson; Sebastian Thrun</li>
<li><strong>年份</strong>：2010</li>
<li><strong>发表</strong>：2010 IEEE International Conference on Robotics and Automation</li>
<li><strong>引用</strong>：285，浏览4931</li>
<li><strong>摘要</strong>：Autonomous vehicle navigation in dynamic urban environments requires localization accuracy exceeding that available from GPS-based inertial guidance systems. We have shown previously that GPS, IMU, and LIDAR data can be used to generate a high-resolution infrared remittance ground map that can be subsequently used for localization. We now propose an extension to this approach that yields substantial improvements over previous work in vehicle localization, including higher precision, the ability to learn and improve maps over time, and increased robustness to environment changes and dynamic obstacles. Specifically, we model the environment, instead of as a spatial grid of fixed infrared remittance values, as a probabilistic grid whereby every cell is represented as its own gaussian distribution over remittance values. Subsequently, Bayesian inference is able to preferentially weight parts of the map most likely to be stationary and of consistent angular reflectivity, thereby reducing uncertainty and catastrophic errors. Furthermore, by using offline SLAM to align multiple passes of the same environment, possibly separated in time by days or even months, it is possible to build an increasingly robust understanding of the world that can be then exploited for localization. We validate the effectiveness of our approach by using these algorithms to localize our vehicle against probabilistic maps in various dynamic environments, achieving RMS accuracy in the 10cm-range and thus outperforming previous work. Importantly, this approach has enabled us to autonomously drive our vehicle for hundreds of miles in dense traffic on narrow urban roads which were formerly unnavigable with previous localization methods.</li>
<li><strong>关键词</strong>：Robustness, Remotely operated vehicles, Vehicle dynamics, Mobile robots, Navigation, Global Positioning System, Laser radar, Gaussian distribution, Bayesian methods, Reflectivity</li>
<li><strong>点评</strong>：在动态环境中根据概率图做车辆定位，地图导航向，有点意思。</li>
</ul>
<h2 id="2-5"><a href="#2-5" class="headerlink" title="2-5"></a>2-5</h2><p>   MapLite: Autonomous Intersection Navigation Without a Detailed Prior Map <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8936918">MapLite：无需详细事先地图的自主交叉路口导航</a></p>
<ul>
<li><strong>作者</strong>：Teddy Ort; Krishna Murthy; Rohan Banerjee</li>
<li><strong>年份</strong>：2019</li>
<li><strong>发表</strong>：IEEE Robotics and Automation Letters</li>
<li><strong>引用</strong>：1，浏览2964</li>
<li><strong>摘要</strong>：In this work, we present MapLite: a one-click autonomous navigation system capable of piloting a vehicle to an arbitrary desired destination point given only a sparse publicly available topometric map (from OpenStreetMap). The onboard sensors are used to segment the road region and register the topometric map in order to fuse the high-level navigation goals with a variational path planner in the vehicle frame. This enables the system to plan trajectories that correctly navigate road intersections without the use of an external localization system such as GPS or a detailed prior map. Since the topometric maps already exist for the vast majority of roads, this solution greatly increases the geographical scope for autonomous mobility solutions. We implement MapLite on a full-scale autonomous vehicle and exhaustively test it on over 15 km of road including over 100 autonomous intersection traversals. We further extend these results through simulated testing to validate the system on complex road junction topologies such as traffic circles.</li>
<li><strong>关键词</strong>：Roads, Navigation, Sensors, Autonomous vehicles, Laser radar, Support vector machines, Surface texture</li>
<li><strong>点评</strong>：地图导航向，激光雷达，无需详细地图的自动驾驶。</li>
</ul>
<h2 id="2-6"><a href="#2-6" class="headerlink" title="2-6"></a>2-6</h2><p>   Object Classification and Recognition From Mobile Laser Scanning Point Clouds in a Road Environment <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/7287763">基于移动激光扫描点云的道路环境目标分类与识别</a></p>
<ul>
<li><strong>作者</strong>：Matti Lehtomäki; Anttoni Jaakkola; Juha Hyyppä</li>
<li><strong>年份</strong>：2015</li>
<li><strong>发表</strong>：IEEE Transactions on Geoscience and Remote Sensing</li>
<li><strong>引用</strong>：51，浏览2410</li>
<li><strong>摘要</strong>：Automatic methods are needed to efficiently process the large point clouds collected using a mobile laser scanning (MLS) system for surveying applications. Machine-learning-based object recognition from MLS point clouds in a road and street environment was studied in order to create maps from the road environment infrastructure. The developed automatic processing workflow included the following phases: the removal of the ground and buildings, segmentation, segment classification, and object location estimation. Several novel geometry-based features, which were previously applied in autonomous driving and general point cloud processing, were applied for the segment classification of MLS point clouds. The features were divided into three sets, i.e., local descriptor histograms (LDHs), spin images, and general shape and point distribution features, respectively. These were used in the classification of the following roadside objects: trees, lamp posts, traffic signs, cars, pedestrians, and hoardings. The accuracy of the object recognition workflow was evaluated using a data set that contained more than 400 objects. LDHs and spin images were applied for the first time for machine-learning-based object classification in MLS point clouds in the surveying applications of the road and street environment. The use of these features improved the classification accuracy by 9.6% (resulting in 87.9% accuracy) compared with the accuracy obtained using 17 general shape and point distribution features that represent the current state of the art in the field of MLS; therefore, significant improvement in the classification accuracy was achieved. Connected component segmentation and ground extraction were the cause of most of the errors and should be thus improved in the future.</li>
<li><strong>关键词</strong>：Three-dimensional displays, Histograms, Roads, Image segmentation, Buildings, Object recognition, Accuracy</li>
<li><strong>点评</strong>：目标识别+移动激光扫描系统收集的大型点云，关系不大，仅供参考。</li>
</ul>
<h2 id="2-7"><a href="#2-7" class="headerlink" title="2-7"></a>2-7</h2><p>   Machine Vision Based Traffic Sign Detection Methods: Review, Analyses and Perspectives <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8746141">基于机器视觉的交通标志检测方法：回顾、分析和展望</a></p>
<ul>
<li><strong>作者</strong>：Chunsheng Liu; Shuang Li; Faliang Chang</li>
<li><strong>年份</strong>：2019</li>
<li><strong>发表</strong>：IEEE Access</li>
<li><strong>引用</strong>：18，浏览2431</li>
<li><strong>摘要</strong>：Traffic signs recognition (TSR) is an important part of some advanced driver-assistance systems (ADASs) and auto driving systems (ADSs). As the first key step of TSR, traffic sign detection (TSD) is a challenging problem because of different types, small sizes, complex driving scenes, and occlusions. In recent years, there have been a large number of TSD algorithms based on machine vision and pattern recognition. In this paper, a comprehensive review of the literature on TSD is presented. We divide the reviewed detection methods into five main categories: color-based methods, shape-based methods, color- and shape-based methods, machine-learning-based methods, and LIDAR-based methods. The methods in each category are also classified into different subcategories for understanding and summarizing the mechanisms of different methods. For some reviewed methods that lack comparisons on public datasets, we reimplemented part of these methods for comparison. The experimental comparisons and analyses are presented on the reported performance and the performance of our reimplemented methods. Furthermore, future directions and recommendations of the TSD research are given to promote the development of the TSD.</li>
<li><strong>关键词</strong>：Cameras, Shape, Laser radar, Color, Support vector machines, Machine vision, Roads</li>
<li><strong>点评</strong>：综述类型，针对交通标志识别，激光雷达，道路场景</li>
</ul>
<h2 id="2-8"><a href="#2-8" class="headerlink" title="2-8"></a>2-8</h2><p>   Unexpected Collision Avoidance Driving Strategy Using Deep Reinforcement Learning <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8961990">使用深度强化学习的意外碰撞避免驾驶策略</a></p>
<ul>
<li><strong>作者</strong>：Myounghoe Kim; Seongwon Lee; Jaehyun Lim</li>
<li><strong>年份</strong>：2020</li>
<li><strong>发表</strong>：IEEE Access</li>
<li><strong>引用</strong>：4，浏览1380</li>
<li><strong>摘要</strong>：In this paper, we generated intelligent self-driving policies that minimize the injury severity in unexpected traffic signal violation scenarios at an intersection using the deep reinforcement learning. We provided guidance on reward engineering in terms of the multiplicity of objective function. We used a deep deterministic policy gradient method in the simulated environment to train self-driving agents. We designed two agents, one with a single-objective reward function of collision avoidance and the other with a multi-objective reward function of both collision avoidance and goal-approaching. We evaluated their performances by comparing the percentages of collision avoidance and the average injury severity against those of human drivers and an autonomous emergency braking (AEB) system. The percentage of collision avoidance of our agents were 78.89% higher than human drivers and 84.70% higher than the AEB system. The average injury severity score of our agents were only 8.92% of human drivers and 6.25% of the AEB system.</li>
<li><strong>关键词</strong>：Reinforcement learning, Collision avoidance, Injuries, Vehicles, Gradient methods, Wheels, Laser radar</li>
<li><strong>点评</strong>：意外场景下避免碰撞的自动驾驶策略，仅使用单通道lidar，有点意思。</li>
</ul>
<h1 id="三、-多传感器融合"><a href="#三、-多传感器融合" class="headerlink" title="三、 多传感器融合"></a>三、 多传感器融合</h1><h2 id="2-1-1"><a href="#2-1-1" class="headerlink" title="2-1"></a>2-1</h2><h2 id="3-1"><a href="#3-1" class="headerlink" title="3-1"></a>3-1</h2><p>   An introduction to multisensor data fusion <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/554205">多传感器数据融合简介</a></p>
<ul>
<li><strong>作者</strong>：D.L. Hall; J. Llinas</li>
<li><strong>年份</strong>：1997</li>
<li><strong>发表</strong>：Proceedings of the IEEE</li>
<li><strong>引用</strong>：1403，浏览15349</li>
<li><strong>摘要</strong>：Multisensor data fusion is an emerging technology applied to Department of Defense (DoD) areas such as automated target recognition, battlefield surveillance, and guidance and control of autonomous vehicles, and to non-DoD applications such as monitoring of complex machinery, medical diagnosis, and smart buildings. Techniques for multisensor data fusion are drawn from a wide range of areas including artificial intelligence, pattern recognition, statistical estimation and other areas. This paper provides a tutorial on data fusion, introducing data fusion applications, process models, and identification of applicable techniques. Comments are made on the state-of-the-art in data fusion.</li>
<li><strong>关键词</strong>：Target recognition, Surveillance, Navigation, Automatic control, Intelligent vehicles, Remotely operated vehicles, Mobile robots, Biomedical monitoring, Computerized monitoring, Condition monitoring</li>
<li><strong>点评</strong>：综述类型，需要一读</li>
</ul>
<h1 id="四、5G定位-雷达"><a href="#四、5G定位-雷达" class="headerlink" title="四、5G定位+雷达"></a>四、5G定位+雷达</h1> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://apollomao.com/%E8%AE%BA%E6%96%87%E6%94%B6%E9%9B%86/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A7%91%E7%A0%94/" rel="tag">科研</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/NUS%E5%85%A5%E5%AD%A6%E9%9C%80%E7%9F%A5/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">NUS入学需知</div>
      </a>
    
  </nav>

  
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021
        <i class="ri-heart-fill heart_icon"></i> 阿波罗猫
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/bluecat.svg" alt="四界"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->


<script src="/js/clickBoom2.js"></script>


<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
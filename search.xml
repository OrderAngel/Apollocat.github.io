<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>EE5907-CA1</title>
    <url>/EE5907-CA1/</url>
    <content><![CDATA[<h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><h2 id="1-数据描述"><a href="#1-数据描述" class="headerlink" title="1. 数据描述"></a>1. 数据描述</h2><ol>
<li><p>数据集：SPAM E-mail Database。包含4601封邮件，每个样本有57维特征和一个标签（1=spam，0=!spam）</p>
</li>
<li><p>具体：</p>
</li>
</ol>
<ul>
<li>Xtrain<ul>
<li>3065x57 double</li>
</ul>
</li>
<li>ytrain<ul>
<li>3065x1 double</li>
</ul>
</li>
<li>Xtest<ul>
<li>1536x57 double</li>
</ul>
</li>
<li>ytest<ul>
<li>1536x1 double</li>
</ul>
</li>
</ul>
<ol start="3">
<li>描述：<a href="https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.info.txt">详情</a> </li>
</ol>
<ul>
<li><p>包括：</p>
<ul>
<li>Spam      1813  (39.4%)</li>
<li>Non-Spam  2788  (60.6%)</li>
</ul>
</li>
<li><p>特征：</p>
<ul>
<li>48 个word_freq_WORD类型的连续实数[0,100]属性 = 电子邮件中匹配WORD的单词的百分比<ul>
<li>即100 *(“word”在邮件中出现的次数)/电子邮件的总字数。在本例中，“word”是由非字母数字字符或字符串结束符限定的任何字母数字字符字符串。</li>
</ul>
</li>
<li>6 个char_freq_CHAR类型的连续实数[0,100]属性 = 电子邮件中匹配CHAR的字符百分比<ul>
<li>即100 *(“char”出现次数)/电子邮件中的字符总数</li>
</ul>
</li>
<li>1 个连续实数[1，…]属性类型为capital_run_length_average = 连续大写字母序列的平均长度</li>
<li>1 个连续整数[1，…]属性类型为capital_run_length_longest = 最长连续大写字母序列的长度</li>
<li>1 个连续整数[1，…]属性类型为capital_run_length_total = 连续的大写字母序列的长度之和 = 电子邮件中大写字母的总数</li>
</ul>
</li>
<li><p>缺失：None</p>
</li>
</ul>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2. 数据处理"></a>2. 数据处理</h2><p>可以尝试对特征进行不同的预处理：</p>
<ol>
<li>log-transform：对于每个特征使用ln(xij + 0.1)进行转换</li>
<li>binarization: 对特征进行二值化，如果大于0就设置为1，否则设置为0</li>
</ol>
<h1 id="Beta-binomial朴素贝叶斯"><a href="#Beta-binomial朴素贝叶斯" class="headerlink" title="Beta-binomial朴素贝叶斯"></a>Beta-binomial朴素贝叶斯</h1><h2 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h2><p>在数据处理部分的<strong>二值化数据</strong>上拟合一个beta-二项朴素贝叶斯分类器。</p>
<p>由于存在大量的垃圾邮件和非垃圾邮件，您不需要在类标签上假设任何先验。换句话说，<strong>类别标签的先验λ可以用ML估计</strong>，在测试时可以用λ ML作为插值估计。</p>
<p>另一方面，需要为特征分布假设Beta(α,α)，对于每个α={0,0.5,1,1.5,2,…,100}，在训练数据上拟合分类器并计算其错误率(即，电子邮件分类错误的百分比)。</p>
<p>对于特征（比如计算p(x|y)），请使用朴素贝叶斯（如后验预测）训练并测试。</p>
<p>报告至少需要包含以下内容：</p>
<ul>
<li>绘制关于α的训练和测试的错误率</li>
<li>当α改变时，你观察到的训练和测试的错误率</li>
<li>α=1,10,100时，训练和测试的错误率</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>1: class 1=spam；</p>
<p>0: class2=!spam</p>
<ul>
<li><p>特征xn经过二项处理后，只有0，1</p>
</li>
<li><p>数据（x,y）是58二项分布；</p>
</li>
<li><p>在训练集上建模：</p>
<p>特征xn是二项，使用每一类的训练样本的特征xn，使用“beta-二项后验预测公式”计算估计x的第n维特征的pdf，即我们会得到class1:2，feature1:57这2*57个二项特征对数似然（放到2x57维矩阵中，每个元素(a,b)表示当y=a时，xb的概率密度）；</p>
<p>以及ML估计的类别先验的对数；</p>
</li>
<li><p>训练+测试（分别在训练集和测试集上进行）：</p>
<p>针对每一个训练/测试数据，分别计算给定特征条件下，类别为1或0的概率。</p>
<p>即，57个特征对应的二项特征对数似然之和+ML估计类别先验对数；</p>
<p>将y=1的概率和y=0的概率对比，选择大概率的作为估计的标签y。</p>
</li>
<li><p>错误率：</p>
<p>对于估计的标签计算分错的样本数量/总样本；</p>
<p>这个操作对测试集和验证集分别搞一遍</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928161328.png"></p>
</li>
</ul>
<h1 id="高斯朴素贝叶斯"><a href="#高斯朴素贝叶斯" class="headerlink" title="高斯朴素贝叶斯"></a>高斯朴素贝叶斯</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>在数据处理部分的<strong>log转换数据</strong>上拟合一个高斯朴素贝叶斯分类器。</p>
<p>由于存在大量的垃圾邮件和非垃圾邮件，您不需要在类标签上假设任何先验。换句话说，<strong>类别标签的先验λ可以用ML估计</strong>，在测试时可以用λ ML作为插值估计。</p>
<p>对于本练习，只需使用ML估计每个特征的类条件均值和方差（eta），并使用ML估计作为测试的插值估计</p>
<p>报告至少需要包含以下内容：</p>
<ul>
<li>关于log转换数据的训练和测试的错误率</li>
</ul>
<h2 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h2><p>单变量高斯的ML估计可以得到μ_ML和σ^2_ML</p>
<p>因为#class=2，λ的ML估计可以用二项的N1/N；</p>
<p>eta是给定class=j时，特征的pdf=N(μ_ML,σ^2_ML)</p>
<p>和上一题类似，还是要先获得eta矩阵，矩阵中的每个元素(i,j)对应给定j类别时，第i维特征的条件概率。该值由ML估计的正态分布得到。</p>
<h2 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928161435.png"></p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>##题目<br>对于<strong>log转换数据</strong>，拟合一个l2正则的逻辑回归模型（牛顿方法+l2正则+从l2正则中排除偏移项）。</p>
<p>对于每个正则参数值λ={1,2,…,9,10,15,20,…95,100}，在训练集上拟合逻辑回归模型，并在测试集上计算它的错误率。</p>
<p>报告至少需要包含以下内容：</p>
<ul>
<li>绘制关于λ的训练和测试的错误率</li>
<li>当λ改变时，你观察到的训练和测试的错误率</li>
<li>λ=1,10,100时，训练和测试的错误率</li>
</ul>
<p>不要忘记在逻辑回归中包括偏倚项，而在l2正则化中排除偏移项。</p>
<h2 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h2><ul>
<li><p>变量</p>
<ul>
<li>W：(D+1)x1</li>
<li>w：Dx1</li>
<li>X：Nx(D+1)</li>
<li>Xi：(D+1)X1（每个样本的特征）Xi=[1,xi]</li>
<li>μ：里面的Xi和W都是D+1维的，Nx1</li>
<li>y：Nx1</li>
</ul>
</li>
<li><p>函数</p>
<ul>
<li>求μ(W,Xi)—(特征矩阵，w)</li>
<li>求NLLreg(特征矩阵,W，λ)</li>
<li>求greg(特征矩阵,类别矩阵,w,λ)</li>
<li>求Hreg(特征矩阵,类别矩阵,w，λ)</li>
</ul>
</li>
</ul>
<p>数据预处理</p>
<p>初始化：给X加一维’1’；步长1；阈值0.01</p>
<p>大循环：λ；</p>
<p>初始化w0—57+1维0向量（这个不是偏移向量）</p>
<p>中循环：while NLL&lt;阈值【目的是get：W】</p>
<ol>
<li> k+1</li>
<li> greg</li>
<li>hreg</li>
<li>W[k+1]—-要存记录</li>
<li>NLL</li>
</ol>
<p>end</p>
<p>用W预测：训练集+测试集（k，#样本数）</p>
<p>end</p>
<p>计算错误率</p>
<p>画图</p>
<h2 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928161533.png"></p>
<h1 id="k最近邻居"><a href="#k最近邻居" class="headerlink" title="k最近邻居"></a>k最近邻居</h1><h2 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h2><p>在<strong>log转换数据</strong>上，实现KNN分类器。用欧式距离来测量邻居之间的距离。</p>
<p>对于每个K={1, 2, …9,10,15,20,…95,100}，计算训练和测试的错误率。</p>
<p>报告至少需要包含以下内容：</p>
<ul>
<li>绘制关于K的训练和测试的错误率</li>
<li>当K改变时，你观察到的训练和测试的错误率</li>
<li>K=1,10,100时，训练和测试的错误率</li>
</ul>
<h2 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h2><p>先搞个函数来计算两个特征之间的距离；<br>再搞个函数来计算新样本和矩阵（训练集）中每个样本的距离</p>
<p>测试和训练时调用算距离函数，生成距离矩阵，每个点(i，j)表示新样本i和训练集样本j之间的距离。</p>
<p>对于每一个新样本，根据不同的K，得到距离该样本最近的K个训练点，对比其中类0和类1的比例，将新样本的标签预测为占比大的那个类。</p>
<p>训练集上的测试或许可以有一些tricky，因为生产的距离矩阵是对称的，且对角线值为0。</p>
<p>训练集：dist—3065<em>3065<br>测试集：dist—1536</em>3065</p>
<h2 id="结果-3"><a href="#结果-3" class="headerlink" title="结果"></a>结果</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928161622.png"></p>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>课程</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu18.04+VINS-MONO+RealsenseD453i 配置教程</title>
    <url>/ubuntu18-04-VINS-MONO-RealsenseD453i-%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="VINS-MONO"><a href="#VINS-MONO" class="headerlink" title="VINS-MONO"></a>VINS-MONO</h1><p>主要参考链接：<br><a href="https://blog.csdn.net/github_53583003/article/details/111187288">Ubuntu18配置VINS-MONO</a></p>
<p>初始配置：<br>ubuntu18.04+cmake+engine</p>
<h2 id="1-ROS配置"><a href="#1-ROS配置" class="headerlink" title="1. ROS配置"></a>1. ROS配置</h2><p><a href="http://wiki.ros.org/melodic/Installation/Ubuntu">ROS官方安装教程</a></p>
<p><em>前面的主要参考链接用的是16.04下的<code>kinetic</code>内核，20.04用的是<code>Neotic</code>内核，我用的是18.04下的<code>melodic</code>内核，所以使用官方教程</em></p>
<h2 id="2-opencv配置"><a href="#2-opencv配置" class="headerlink" title="2. opencv配置"></a>2. opencv配置</h2><p>根据mono的建议，cv版本用的是<a href="https://github.com/opencv/opencv/releases/tag/3.3.1">opencv-3.3.1</a>和<a href="https://github.com/opencv/opencv_contrib/releases/tag/3.3.1">opencv-contrib-3.3.1</a></p>
<p>location: <code>~/library/opencv-3.3.1</code></p>
<p>后续根据<a href="https://blog.csdn.net/github_53583003/article/details/111187288">参考链接</a>完成编译。</p>
<p>进行opencv的编译环境配置：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install build-essential libgtk2.0-dev libvtk6-dev libjpeg-dev libtiff4-dev libjasper-dev libopenexr-dev libtbb-dev</span><br></pre></td></tr></tbody></table></figure>
<p><em>注意，opencv的依赖包虽然是参考SLAM十四讲，但是由于版本区别，有的包要装升级后的版本，比如书里是libvtk5-dev，而我们需要装6</em></p>
<h2 id="3-安装Ceres库"><a href="#3-安装Ceres库" class="headerlink" title="3. 安装Ceres库"></a>3. 安装Ceres库</h2><p>Ceres solver 是谷歌开发的一款用于非线性优化的库，在谷歌的开源激光雷达slam项目cartographer中被大量使用</p>
<p>首先，安装依赖</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install liblapack-dev </span><br><span class="line">sudo apt-get install libsuitesparse-dev </span><br><span class="line">sudo apt-get install libcxsparse3.1.2</span><br><span class="line">sudo apt-get install libgflags-dev </span><br><span class="line">sudo apt-get install libgoogle-glog-dev libgtest-dev</span><br></pre></td></tr></tbody></table></figure>
<p><em>如果有的包无法定位，可能是因为更换了版本名，<a href="https://packages.ubuntu.com/">https://packages.ubuntu.com/</a> <code>Search package directories</code>搜一下keyword，注意与当前ubuntu版本对应；也可以参考<a href="https://www.cnblogs.com/qilai/p/13654810.html">无法定位lib3.1.2</a>，我用的第二种方法</em></p>
<p>然后，下载<a href="https://github.com/ceres-solver/ceres-solver/releases">Ceres</a></p>
<p><em>我下的是cere2.0.0，解压后location: <code>~/library/ceres-solver-2.0.0</code></em></p>
<p>进入目录下编译ceres:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake ..</span><br><span class="line">sudo make install</span><br></pre></td></tr></tbody></table></figure>
<h2 id="4-VINS-MONO编译"><a href="#4-VINS-MONO编译" class="headerlink" title="4. VINS-MONO编译"></a>4. VINS-MONO编译</h2><p>VINS-MONO，2017年港科老师开源的一个单目视觉惯导的实时SLAM方案，是视觉与IMU的经典融合，定位精度可以媲美OKVIS，在Linux上运行，并与ROS完全集成。</p>
<p>该算法基于优化和滑动窗口的 VIO ，使用 IMU 预积分构建紧耦合框架，同时还有自动初始化，在线外参标定，重定位，闭环检测，以及全局位姿图优化功能。</p>
<ul>
<li>准备数据</li>
</ul>
<p>首先下载<a href="https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets#the_euroc_mav_dataset">EuRoC数据集</a>，该数据集是微型飞行器 (MAV) 上收集的视觉惯性数据集。数据集包含立体图像、同步 IMU 测量以及精确的运动和结构地面实况。</p>
<p><em>我下的是<code>Machine Hall 01 (ROS bag)</code>用来测试，location: <code>~/DATA/VINS-MONO/MH_01_easy.bag</code></em></p>
<p>此外还要下载<a href="https://github.com/HKUST-Aerial-Robotics/VINS-Mono">VINS-MONO代码</a>。</p>
<ul>
<li><p>创建ROS工作空间</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">mkdir -p ~/catkin_ws/src              </span><br><span class="line">cd ~/catkin_ws/src</span><br><span class="line">catkin_init_workspace</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>编译VINS</p>
</li>
</ul>
<p>将前面下载的Vins-mono的代码移动到<code>~/catkin_ws/src</code>文件夹下。</p>
<p>编译：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">cd ~/catkin_ws</span><br><span class="line">catkin_make</span><br><span class="line">source ~/catkin_ws/devel/setup.bash</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>修改配置文件内容在VINS-Mono-master主工程目录下的config子目录中找到euroc文件夹，并打开其中的euroc_config.yaml文件，将其中结果输出保存路径修改为本地的绝对路径或相对路径<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">output_path: "/home/yj/HZL/VINS-MONO-REALSENSE/output/"</span><br><span class="line">pose_graph_save_path: "/home/yj/HZL/VINS-MONO-REALSENSE/output/pose_graph/"</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<ul>
<li>修改source如果每次运行前需要都需要用source来指定文件位置未免太麻烦，可以直接在<code>.bashrc</code>中添加source<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sudo  gedit ~/.bashrc</span><br></pre></td></tr></tbody></table></figure>
在.bashrc中加上：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">source ~/catkin_ws/devel/setup.bash</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<ul>
<li>运行<ul>
<li>1号终端启动ROS核心：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roscore</span><br></pre></td></tr></tbody></table></figure></li>
<li>2号终端：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roslaunch vins_estimator euroc.launch</span><br></pre></td></tr></tbody></table></figure></li>
<li>3号终端启动rviz软件<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roslaunch vins_estimator vins_rviz.launch</span><br></pre></td></tr></tbody></table></figure></li>
<li>4号终端输入数据：注意把数据包地址改成自己的<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rosbag play /home/yj/DATA/VINS-MONO/MH_01_easy.bag </span><br></pre></td></tr></tbody></table></figure></li>
</ul>
</li>
</ul>
<h1 id="使用Realsense-D453i运行VINS-MONO"><a href="#使用Realsense-D453i运行VINS-MONO" class="headerlink" title="使用Realsense D453i运行VINS-MONO"></a>使用Realsense D453i运行VINS-MONO</h1><p><a href="https://blog.csdn.net/weixin_44580210/article/details/89789416">参考链接</a></p>
<h2 id="1-安装librealsense-SDK-2-0"><a href="#1-安装librealsense-SDK-2-0" class="headerlink" title="1. 安装librealsense SDK 2.0"></a>1. 安装librealsense SDK 2.0</h2><p><a href="https://github.com/IntelRealSense/librealsense/releases/tag/v2.48.0">v2.48.0</a></p>
<p><a href="https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md">官方指南</a></p>
<p>librealsense SDK相当于相机的驱动，D435i是librealsense SDK 2.0；SDK的安装方式有两种，一是从源码编译安装，二是直接命令行安装，官方指南的公钥法用的2。</p>
<p><em>我装的是librealsense SDK v2.48.0，支持18.04</em></p>
<p>测试：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">realsense-viewer</span><br></pre></td></tr></tbody></table></figure>
<p><em>注意：使用3.0的usb口</em></p>
<h2 id="2-安装测试realsense相机对应的ROS包"><a href="#2-安装测试realsense相机对应的ROS包" class="headerlink" title="2. 安装测试realsense相机对应的ROS包"></a>2. 安装测试realsense相机对应的ROS包</h2><p><a href="https://github.com/IntelRealSense/realsense-ros">官方指南</a><br>（用的是指南里的realsense distribution方案）</p>
<p>进入ros空间: </p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">cd ~/catkin_ws/src</span><br><span class="line">git clone https://github.com/IntelRealSense/realsense-ros.git</span><br><span class="line">cd realsense-ros/</span><br><span class="line">git checkout `git tag | sort -V | grep -P "^2.\d+\.\d+" | tail -1`</span><br></pre></td></tr></tbody></table></figure>
<p>补一些依赖: </p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">mkdir -p ~/catkin_ws/src/realsense</span><br><span class="line">rosdep install --from-paths src --ignore-src -r -y    # 这步第二次安装的时候失败</span><br><span class="line">sudo apt purge ros-melodic-librealsense2</span><br></pre></td></tr></tbody></table></figure>
<p>继续安装：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">cd ~/catkin_ws</span><br><span class="line">catkin_make clean</span><br><span class="line">catkin_make -DCATKIN_ENABLE_TESTING=False -DCMAKE_BUILD_TYPE=Release</span><br><span class="line">catkin_make install</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>出现报错，原因是缺少ddynamic_reconfigure，解决方案是从<a href="https://github.com/pal-robotics/ddynamic_reconfigure/tree/kinetic-devel">这里</a>将其下载，克隆到工作区<code>~/catkin_ws/src/</code>中</li>
</ul>
<p>改<code>.bashrc</code>：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">echo "source ~/catkin_ws/devel/setup.bash" &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></tbody></table></figure>
<p>运行rviz：</p>
<ul>
<li>1号终端启动ROS核心：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roscore</span><br></pre></td></tr></tbody></table></figure></li>
<li>2号终端：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rosrun rviz rviz</span><br></pre></td></tr></tbody></table></figure>
运行realsense：<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roslaunch realsense2_camera rs_camera.launch filters:=pointcloud</span><br></pre></td></tr></tbody></table></figure>
这时候应该无图像，需要在rviz中修改一些配置，当然配置有很多选择，对于新手来说有图就行orz，以下只是举个例子：</li>
<li>把fixed frame改成<code>camera_...</code>，不能是<code>map</code>，Global Status由红色变绿</li>
<li>Add -&gt; 上方点击 By topic -&gt; /depth_registered 下的 /points 下的/PointCloud2，这是针对上面命令中<code>filters:=pointcloud</code>部分选择的type</li>
<li>Add -&gt; 上方点击 By topic -&gt; /color 下的 /image_raw 下的image</li>
</ul>
<h2 id="3-在D453i上运行VINS-MONO"><a href="#3-在D453i上运行VINS-MONO" class="headerlink" title="3. 在D453i上运行VINS-MONO"></a>3. 在D453i上运行VINS-MONO</h2><p>这里建议先把catkin_ws备份一下<br><a href="https://zhuanlan.zhihu.com/p/390933690">参考链接0</a><br><a href="https://blog.csdn.net/weixin_44580210/article/details/89789416">参考链接1</a><br><a href="https://blog.csdn.net/qq_41839222/article/details/86552367">参考链接2</a></p>
<h3 id="1）修改rs-camera-launch文件"><a href="#1）修改rs-camera-launch文件" class="headerlink" title="1）修改rs_camera.launch文件"></a>1）修改rs_camera.launch文件</h3><p>location：<code>~/catkin_ws/src/realsense-ros/realsense2_camera/launch</code></p>
<ul>
<li>修改unite_imu_method如下，这里是让IMU的角速度和加速度作为一个topic输出<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arg name="unite_imu_method"      default="copy"/&gt;</span><br></pre></td></tr></tbody></table></figure></li>
<li>修改enable_sync参数为true，这里是开启相机和IMU的同步<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arg name="enable_sync"           default="true"/&gt;</span><br></pre></td></tr></tbody></table></figure></li>
<li>打开陀螺仪和加速度计<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arg name="enable_gyro"         default="true"/&gt;</span><br><span class="line">&lt;arg name="enable_accel"        default="true"/&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="2）修改realsense-color-config-yaml文件"><a href="#2）修改realsense-color-config-yaml文件" class="headerlink" title="2）修改realsense_color_config.yaml文件"></a>2）修改realsense_color_config.yaml文件</h3></li>
</ul>
<p>location：<code>~/catkin_ws/src/VINS-Mono-master/config/realsense/realsense_color_config.yaml</code></p>
<ul>
<li>修改订阅的topic<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">imu_topic: "/camera/imu"</span><br><span class="line">image_topic: "/camera/color/image_raw"</span><br><span class="line">output_path: "/home/yj/HZL/VINS-MONO-REALSENSE/output/"  #自己的地址</span><br><span class="line"></span><br><span class="line">pose_graph_save_path: "/home/yj/HZL/VINS-MONO-REALSENSE/output/pose_graph/"</span><br></pre></td></tr></tbody></table></figure></li>
<li>修改相机的内参<br><a href="https://zhuanlan.zhihu.com/p/390933690">指南</a><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rostopic echo /camera/color/camera_info #查看内参命令</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#camera calibration </span><br><span class="line">model_type: PINHOLE</span><br><span class="line">camera_name: camera</span><br><span class="line">image_width: 1280</span><br><span class="line">image_height: 720</span><br><span class="line">distortion_parameters:</span><br><span class="line">   k1: 0 #9.2615504465028850e-02</span><br><span class="line">   k2: 0 #-1.8082438825995681e-01</span><br><span class="line">   p1: 0 #-6.5484100374765971e-04</span><br><span class="line">   p2: 0 #-3.5829351558557421e-04</span><br><span class="line">projection_parameters:</span><br><span class="line">   fx: 9.194400024414062e+02 #6.0970550296798035e+02</span><br><span class="line">   fy: 9.189413452148438e+02 #6.0909579671294716e+02</span><br><span class="line">   cx: 6.383787841796875e+02 #3.1916667152289227e+02</span><br><span class="line">   cy: 3.5089337158203125e+02 #2.3558360480225772e+02</span><br></pre></td></tr></tbody></table></figure></li>
<li>IMU到相机的变换矩阵，这里我根据注释的提示修改成2</li>
</ul>
<p>初始为0，选0的话，IMU和camera之间的外参矩阵建议使用Kalibr工具进行离线标定，也可以改成1或者2让估计器自己标定和优化。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># Extrinsic parameter between IMU and Camera.</span><br><span class="line">estimate_extrinsic: 2   </span><br><span class="line">                # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.</span><br><span class="line">                # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.</span><br><span class="line">                # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.                        </span><br><span class="line">                # If you choose 0 or 1, you should write down the following matrix.</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>IMU参数，这里我全部修改注释给的参数<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#imu parameters       The more accurate parameters you provide, the better performance</span><br><span class="line">acc_n: 0.2          # accelerometer measurement noise standard deviation. #0.2</span><br><span class="line">gyr_n: 0.05         # gyroscope measurement noise standard deviation.     #0.05</span><br><span class="line">acc_w: 0.02         # accelerometer bias random work noise standard deviation.  #0.02</span><br><span class="line">gyr_w: 4.0e-5       # gyroscope bias random work noise standard deviation.     #4.0e-5</span><br><span class="line">g_norm: 9.80       # gravity magnitude</span><br></pre></td></tr></tbody></table></figure></li>
<li>是否需要在线估计同步时差，根据上述博主的建议这里选择不需要<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#unsynchronization parameters</span><br><span class="line">estimate_td: 0                      # online estimate time offset between camera and imu</span><br><span class="line">td: 0.000                           # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)</span><br></pre></td></tr></tbody></table></figure></li>
<li>相机曝光改成全局曝光<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#rolling shutter parameters</span><br><span class="line">rolling_shutter: 0                      # 0: global shutter camera, 1: rolling shutter camera</span><br><span class="line">rolling_shutter_tr: 0               # unit: s. rolling shutter read out time per frame (from data sheet). </span><br></pre></td></tr></tbody></table></figure>
<h3 id="3）运行"><a href="#3）运行" class="headerlink" title="3）运行"></a>3）运行</h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roscore</span><br><span class="line">roslaunch realsense2_camera rs_camera.launch  #启动realsense驱动sdk，输出相应图像和IMU话题</span><br><span class="line">roslaunch vins_estimator realsense_color.launch #启动vins-mono，数据来源是相机</span><br><span class="line">roslaunch vins_estimator vins_rviz.launch #启动rviz界面</span><br></pre></td></tr></tbody></table></figure>
在global option里把word改成camera_link</li>
</ul>
<h1 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h1><p>不显示特征点和轨迹，报错如下：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[ INFO] [1629687186.636584239]: init begins</span><br><span class="line">[ INFO] [1629687186.672642097]: Loaded config_file: /home/yj/catkin_ws/src/VINS-Mono-master/feature_tracker/../config/realsense/realsense_color_config.yaml</span><br><span class="line">vocabulary_file/home/yj/catkin_ws/src/VINS-Mono-master/pose_graph/../support_files/brief_k10L6.bin</span><br><span class="line">result path /home/yj/HZL/VINS-MONO-REALSENSE/output//vins_result_no_loop.csv</span><br><span class="line">[ INFO] [1629687186.683639120]: ROW: 480.000000 COL: 640.000000 </span><br><span class="line">[ WARN] [1629687186.683652444]: have no prior about extrinsic param, calibrate extrinsic param</span><br><span class="line"></span><br><span class="line">[ INFO] [1629688187.806394607]: Synchronized sensors, fix time offset: 0</span><br><span class="line">[ WARN] [1629688187.806432117]: waiting for image and imu...</span><br><span class="line">vocabulary_file/home/yj/catkin_ws/src/VINS-Mono-master/pose_graph/../support_files/brief_k10L6.bin</span><br><span class="line">loop start load vocabulary</span><br><span class="line">BRIEF_PATTERN_FILE/home/yj/catkin_ws/src/VINS-Mono-master/pose_graph/../support_files/brief_pattern.yml</span><br><span class="line">no previous pose graph</span><br><span class="line">OpenCV Error: Assertion failed (_mask.empty() || (_mask.type() == CV_8UC1 &amp;&amp; _mask.sameSize(_image))) in goodFeaturesToTrack, file /build/opencv-L2vuMj/opencv-3.2.0+dfsg/modules/imgproc/src/featureselect.cpp, line 366</span><br><span class="line">terminate called after throwing an instance of 'cv::Exception'</span><br><span class="line">  what():  /build/opencv-L2vuMj/opencv-3.2.0+dfsg/modules/imgproc/src/featureselect.cpp:366: error: (-215) _mask.empty() || (_mask.type() == CV_8UC1 &amp;&amp; _mask.sameSize(_image)) in function goodFeaturesToTrack</span><br><span class="line"></span><br><span class="line">[feature_tracker-1] process has died [pid 1331, exit code -6, cmd /home/yj/catkin_ws/devel/lib/feature_tracker/feature_tracker __name:=feature_tracker __log:=/home/yj/.ros/log/8f26fcba-03bf-11ec-9c16-b07b250c6f90/feature_tracker-1.log].</span><br><span class="line">log file: /home/yj/.ros/log/8f26fcba-03bf-11ec-9c16-b07b250c6f90/feature_tracker-1*.log</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>解决策略：</p>
<ul>
<li><p>第一次跑的时候没配置opencv，现在补充配置opencv，按照《高翔SLAM》p108中的配置安装依赖包（这部分已补充在上文），以下是安装以上依赖时附带安装的依赖，仅作为记录，不作为参考：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install build-essential libopenmpi1.6 libvtk5.8 mpi-default-dev</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>还是不显示，参考<a href="https://github.com/HKUST-Aerial-Robotics/VINS-Mono/issues/26">链接</a>，发现是相机参数未同步的原因：</p>
<p><strong>最终解决方案</strong>：除了要在上述的<code>realsense_color_config.yaml</code>中修改相机参数，还需要在<code>/home/yj/catkin_ws/src/VINS-Mono-master/config/euroc/euroc_config.yaml</code>文件中修改<code>#camera calibration</code></p>
<p>我的problem还有，在<code>realsense_color_config.yaml</code>中只修改了<code>distortion_parameters</code>和<code>projection_parameters</code>，而未修改分辨率<code>(image_width: 1280, image_height: 720)</code></p>
<ul>
<li>查看相机内参指令(不同相机内参是不一样的)：</li>
</ul>
  <figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">roscore</span><br><span class="line">roslaunch realsense2_camera rs_camera.launch  #打开相机节点</span><br><span class="line">rostopic echo /camera/color/camera_info   #查看相机内参</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>本科知识整理</title>
    <url>/%E6%9C%AC%E7%A7%91%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h1 id="算法设计与分析"><a href="#算法设计与分析" class="headerlink" title="算法设计与分析"></a>算法设计与分析</h1><p>《算法设计与分析第三版-王晓东》</p>
<ol>
<li>算法引论<ol>
<li>算法与程序</li>
<li>表达算法的抽象机制</li>
<li>描述算法</li>
<li>算法复杂性分析</li>
</ol>
</li>
<li>递归与分治策略<ol>
<li>递归的概念</li>
<li>分治法的基本思想</li>
<li>二分搜索技术</li>
<li>大整数的乘法</li>
<li>Strassen矩阵乘法</li>
<li>棋盘覆盖</li>
<li>合并排序</li>
<li>快速排序</li>
<li>线性时间选择</li>
<li>最接近点对问题</li>
<li>循环赛日程表</li>
</ol>
</li>
<li>动态规划<ol>
<li> 矩阵连乘问题</li>
<li> 动态规划算法的基本要素</li>
<li> 最长公共子序列</li>
<li> 凸多边形最优三角划分</li>
<li> 多边形游戏</li>
<li> 图像压缩</li>
<li> 电路布线</li>
<li> 流水作业调度</li>
<li> 0-1背包问题</li>
<li>最优二叉搜索树</li>
</ol>
</li>
<li>贪心算法<ol>
<li> 活动安排问题</li>
<li>贪心算法的基本要素<ol>
<li> 贪心选择性质</li>
<li> 最优子结构性质</li>
<li> 贪心算法与动态规划算法的差异</li>
</ol>
</li>
<li>最优装载</li>
<li>哈夫曼编码<ol>
<li>前编码</li>
<li>构造哈弗曼编码</li>
<li>哈夫曼算法的正确性</li>
</ol>
</li>
<li>单源最短路径<ol>
<li>算法基本思想</li>
<li>算法的正确性和计算复杂性</li>
</ol>
</li>
<li>最小生成树<ol>
<li>最小生成树性质</li>
<li>Prim算法</li>
<li>Kruskal算法</li>
<li>多机调度问题</li>
<li>贪心算法的理论基础<ol>
<li>拟阵</li>
<li>带权拟阵的贪心算法</li>
<li>任务时间表问题</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>回溯法<ol>
<li>回溯法的算法框架<ol>
<li>问题的解空间</li>
<li>回溯法的基本思想</li>
<li>递归回溯</li>
<li>迭代回溯</li>
<li>子集树与排列数</li>
</ol>
</li>
<li>装载问题</li>
<li>批处理作业调度</li>
<li>符号三角形问题</li>
<li>n后问题</li>
<li>0-1背包问题</li>
<li>最大团问题</li>
<li>图的m着色问题</li>
<li>旅行售货员问题</li>
<li>圆排列问题</li>
<li>电路板排列问题</li>
<li>连续邮资问题</li>
<li>回溯法的效率分析</li>
</ol>
</li>
<li>分支限界法<ol>
<li>分支限界法的基本思想</li>
<li>单源最短路径问题</li>
<li>装载问题</li>
<li>布线问题</li>
<li>0-1背包问题</li>
<li>最大团问题</li>
<li>旅行售货员问题</li>
<li>电路板排列问题</li>
<li>批处理作业调度</li>
</ol>
</li>
<li>概率算法<ol>
<li> 随机数</li>
<li>数值概率算法<ol>
<li> 用随机投点法计算π值</li>
<li> 计算定积分</li>
<li> 解非线性方程组</li>
</ol>
</li>
<li>舍伍德算法<ol>
<li>线性时间选择算法</li>
<li>跳跃表</li>
</ol>
</li>
<li>拉斯维加斯算法<ol>
<li>n后问题</li>
<li>整数因子分解</li>
</ol>
</li>
<li>蒙特卡罗算法<ol>
<li>蒙特卡罗算法的基本思想</li>
<li>主元素问题</li>
<li>素数测试</li>
</ol>
</li>
</ol>
</li>
<li>NP完全性理论<ol>
<li>计算模型<ol>
<li>随机存取机RAM</li>
<li>随机存取存储程序机RASP</li>
<li>RAM，模型的变形与简化</li>
<li>图灵机</li>
<li>图灵机模型与RAM模型的关系</li>
<li>问题变换与计算复杂性归约</li>
</ol>
</li>
<li>P类与NP类问题<ol>
<li>非确定性图灵机</li>
<li>P类与NP类语言</li>
<li>多项式时间验证</li>
</ol>
</li>
<li>NP完全问题<ol>
<li>多项式时间变换</li>
<li>COok定理</li>
</ol>
</li>
<li>一些典型的NP完全问题<ol>
<li>合取范式的可满足性问题</li>
<li>3元合取范式的可满足性问题</li>
<li>团问题</li>
<li>顶点覆盖问题</li>
<li>子集和问题</li>
<li>哈密顿回路问题</li>
<li>旅行售货员问题</li>
</ol>
</li>
</ol>
</li>
<li> 近似算法</li>
<li>近似算法的性能</li>
<li>顶点覆盖问题的近似算法</li>
<li>旅行售货员问题的近似算法<ol>
<li>具有三角不等式性质的旅行售货员问题</li>
<li>一般的旅行售货员问题</li>
</ol>
</li>
<li>集合覆盖问题的近似算法</li>
<li>子集和问题的近似算法<ol>
<li>子集和问题的指数时间算法</li>
<li>子集和问题的完全多项式时间近似格式</li>
</ol>
</li>
<li>算法优化策略<ol>
<li>算法设计策略的比较与选择<ol>
<li>最大子段和问题的简单算法</li>
<li>最大子段和问题的分治算法</li>
<li>最大子段和问题的动态规划算法</li>
<li>最大子段和问题与动态规划算法的推广</li>
</ol>
</li>
<li>动态规划加速原理<ol>
<li>货物储运问题</li>
<li>算法及其优化</li>
</ol>
</li>
<li>问题的算法特性<ol>
<li>贪心策略</li>
<li>对贪心策略的改进</li>
<li>算法三部曲</li>
<li>算法实现</li>
<li>算法复杂性</li>
</ol>
</li>
<li>优化数据结构<ol>
<li>带权区间最短路问题</li>
<li>算法设计思想</li>
<li>算法实现方案</li>
<li>并查集</li>
<li>可并优先队列</li>
</ol>
</li>
<li>优化搜索策略</li>
</ol>
</li>
<li>在线算法设计<ol>
<li> 在线算法设计的基本概念</li>
<li> 页调度问题</li>
<li> 势函数分析</li>
<li>k服务问题竞争比的下界<ol>
<li> 平衡算法</li>
<li> 对称移动算法</li>
</ol>
</li>
<li> Steiner树问题</li>
<li> 在线任务调度</li>
<li> 负载平衡</li>
</ol>
</li>
</ol>
<h1 id="概率论"><a href="#概率论" class="headerlink" title="概率论"></a>概率论</h1><p>《概率论与数理统计应用第二版-施雨+概率统计辅导书-魏平、王宁》</p>
<ol>
<li>随机事件与概率<ol>
<li>随机事件</li>
<li>概率</li>
<li>古典概率的计算</li>
<li>条件概率 事件的相互独立性</li>
</ol>
</li>
<li>随机变量与概率分布<ol>
<li>一维随机变量</li>
<li>二维随机变量</li>
<li>条件分布</li>
<li>随机变量的相互独立性</li>
<li>随机变量的函数的概率分布</li>
</ol>
</li>
<li>随机变量的数字特性<ol>
<li>数学期望</li>
<li>方差</li>
<li>协方差与相关系数</li>
<li>条件期望与条件方差</li>
</ol>
</li>
<li>大数定律与中心极限定理<ol>
<li>大数定律</li>
<li>中心极限定理</li>
</ol>
</li>
<li>数理统计学的基本概念<ol>
<li>总体与样本</li>
<li>样本分布</li>
<li>统计量</li>
<li>抽样分布</li>
</ol>
</li>
<li>参数估计<ol>
<li>点估计</li>
<li>估计量与评选标准</li>
<li>区间估计</li>
<li>正态总体参数的区间估计</li>
</ol>
</li>
<li>假设检验<ol>
<li>假设检验的基本概念</li>
<li>正态总体参数的假设检验</li>
<li>单边假设检验</li>
<li>多数假设的大样本检验</li>
<li>分布假设检验</li>
</ol>
</li>
<li>方差分析<ol>
<li>单因素方差分析</li>
<li>双因素方差分析</li>
</ol>
</li>
<li>回归分析<ol>
<li>一元线性回归</li>
<li>可线性化的一元非线性回归</li>
<li>多元线性回归</li>
</ol>
</li>
<li>随机过程的基本知识<ol>
<li> 随机过程的概念和记号</li>
<li> 随机过程的概率特性</li>
<li> 随机过程的基本类型</li>
<li> 泊松过程与布朗运动</li>
</ol>
</li>
<li>平稳过程<ol>
<li> 平稳过程的概念</li>
<li> 平稳过程的性质</li>
<li> 平稳过程的谱密度</li>
<li> 各态历经性</li>
</ol>
</li>
<li>附录<ol>
<li> 标准正态分布表</li>
<li> 泊松分布表</li>
<li> t分布表</li>
<li> X^2分布表</li>
<li> F分布表</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>博客简介</title>
    <url>/%E5%8D%9A%E5%AE%A2%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Hi, guys！</p>
<p>这里是 阿波罗猫 的博客——四界。</p>
<p>主要作用是记录个人生活，整理所学知识，放飞自我， 天天向上！</p>
<p>这里先许下一个心愿：<strong>希望未来能顺利毕业！</strong></p>
<span id="more"></span>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><table>
<thead>
<tr>
<th align="center"><strong>侧栏名称</strong></th>
<th align="center"><strong>简介</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>主页</strong></td>
<td align="center">博客主页</td>
</tr>
<tr>
<td align="center"><strong>归档</strong></td>
<td align="center">罗列所有文章</td>
</tr>
<tr>
<td align="center"><strong>分类</strong></td>
<td align="center">按类型分类文章</td>
</tr>
<tr>
<td align="center"><strong>标签</strong></td>
<td align="center">按标签分类文章</td>
</tr>
<tr>
<td align="center"><strong>随笔</strong></td>
<td align="center">日常相关的吐槽</td>
</tr>
<tr>
<td align="center"><strong>关于我</strong></td>
<td align="center">个人简历</td>
</tr>
</tbody></table>
<h1 id="关于“四界”"><a href="#关于“四界”" class="headerlink" title="关于“四界”"></a>关于“四界”</h1><p>“四界”这个名字来自于我初高中时的自产小说，小说内容就不说了，满满都是中二，而且还坑了2333。</p>
<p>Anyway，这个博客名字可以理解为致敬青春吧。</p>
<p>祝愿我的未来无论走出多远，归来仍是少年。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>健身清单</title>
    <url>/%E5%81%A5%E8%BA%AB%E6%B8%85%E5%8D%95/</url>
    <content><![CDATA[<p>背：拉，胸：推+宽于肩<br>史密斯：直背-肩，平躺：胸，45度，胳膊？</p>
<p>参考链接：<a href="https://www.hiyd.com/dongzuo/">https://www.hiyd.com/dongzuo/</a></p>
<h1 id="腿部训练"><a href="#腿部训练" class="headerlink" title="腿部训练"></a>腿部训练</h1><table>
<thead>
<tr>
<th align="left">标号</th>
<th align="left">名称</th>
<th align="left">指标</th>
<th align="left">次数</th>
<th align="left">部位</th>
<th align="left">链接/图示</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">哑铃高脚杯深蹲</td>
<td align="left">30lbs</td>
<td align="left">16*4</td>
<td align="left">臀+大腿前后</td>
<td align="left"><a href="https://www.gotokeep.com/exercises/595f4d3aff247f33e297ea5a?gender=f">keep视频</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">倒蹬</td>
<td align="left">80kg</td>
<td align="left">16*4</td>
<td align="left">大腿</td>
<td align="left"><a href="https://www.163.com/dy/article/F7S7PBNQ0533BETQ.html">文字配图</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">腿屈伸</td>
<td align="left">23kg</td>
<td align="left">16*4</td>
<td align="left">大腿面</td>
<td align="left"><a href="https://show.gotokeep.com/exercises/5763d3b011fc5077c3acf58d?gender=f">keep</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">腿弯举</td>
<td align="left">32kg</td>
<td align="left">16*4</td>
<td align="left">大腿后侧</td>
<td align="left">我练的是坐姿版，如果只有卧姿，可以用硬拉替代</td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">箭步蹲</td>
<td align="left">20lbs</td>
<td align="left">12*4</td>
<td align="left">大腿面</td>
<td align="left"><a href="https://show.gotokeep.com/exercises/57e34ab509a2d8a73b790705?gender=f">keep视频</a>，可以双手提俩哑铃，也可以原地</td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">壶铃硬拉</td>
<td align="left">45lbs</td>
<td align="left">16*4</td>
<td align="left">臀部+大腿后侧</td>
<td align="left"><a href="https://keep.com/exercises/5c0e44cfa29e340410e9761f">keep视频</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">坐姿腿外展</td>
<td align="left">50lbs</td>
<td align="left">16*4</td>
<td align="left">大腿外侧</td>
<td align="left"><a href="https://show.gotokeep.com/exercises/5763d3b011fc5077c3acf580?gender=f">keep图片</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">坐姿腿内收</td>
<td align="left">50lbs</td>
<td align="left">16*4</td>
<td align="left">大腿内侧</td>
<td align="left"><a href="https://www.gotokeep.com/exercises/5763d3b011fc5077c3acf595?gender=f">keep图片</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">自由深蹲</td>
<td align="left">-</td>
<td align="left">16*4</td>
<td align="left">臀+大腿面</td>
<td align="left"><a href="https://www.gotokeep.com/exercises/564b0b02a9f7e955480feff2?gender=f">keep视频</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">倒蹬</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">直腿硬拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">臀+大腿后侧</td>
<td align="left"><a href="http://show.gotokeep.com/exercises/595f4ee1ff247f33e297eb64">keep视频</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">腿屈伸</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">大腿面</td>
<td align="left"><a href="https://show.gotokeep.com/exercises/5763d3b011fc5077c3acf58d?gender=f">keep</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">腿弯举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">大腿后侧</td>
<td align="left">我练的是坐姿版，如果只有卧姿，可以用硬拉替代</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">坐姿腿外展</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">大腿外侧</td>
<td align="left"><a href="https://show.gotokeep.com/exercises/5763d3b011fc5077c3acf580?gender=f">keep图片</a></td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">史密斯深蹲</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">臀+大腿</td>
<td align="left"><a href="https://www.gotokeep.com/exercises/5763d3b011fc5077c3acf581">keep图片</a></td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">臀桥</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://keep.com/exercises/55cc42cd5f9bd587372f64c9?gender=f">keep图片</a>??????我感觉不是这个啊</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">腿屈伸</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">腿弯举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">坐姿腿外展</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">-</td>
</tr>
</tbody></table>
<h1 id="背部训练"><a href="#背部训练" class="headerlink" title="背部训练"></a>背部训练</h1><table>
<thead>
<tr>
<th align="left">标号</th>
<th align="left">名称</th>
<th align="left">指标</th>
<th align="left">次数</th>
<th align="left">部位</th>
<th align="left">链接/图示</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">器械坐姿划船</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">高位下拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">背部左右下侧</td>
<td align="left"><a href="https://show.gotokeep.com/exercises/5763d3b011fc5077c3acf5b6?gender=f">keep图片</a>，我感觉我好像是站着做的？问一下</td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">T杠划船</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">中背部</td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/234/">视频</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">绳索划船</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">斜方肌</td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/944/">视频</a>，需要问一下</td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">屈腿硬拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">？</td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">直臂下压</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://gotokeep.com/exercises/5763d3b011fc5077c3acf578">keep图片</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">助力引体向上(fall)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">高位下拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">T杠划船</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">中背部</td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/234/">视频</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">坐姿划船(挺胸版)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">？</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">坐姿划船(含胸版)</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">？</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">屈腿硬拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<h1 id="胸部训练"><a href="#胸部训练" class="headerlink" title="胸部训练"></a>胸部训练</h1><table>
<thead>
<tr>
<th align="left">标号</th>
<th align="left">名称</th>
<th align="left">指标</th>
<th align="left">次数</th>
<th align="left">部位</th>
<th align="left">链接/图示</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">史密斯上斜卧推</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="http://gotokeep.com/exercises/5763d3b011fc5077c3acf559">keep图片</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">史密斯平板卧推</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://gotokeep.com/exercises/5763d3b011fc5077c3acf562">keep图片</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">哑铃飞鸟</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://gotokeep.com/exercises/5763d3b011fc5077c3acf59d">keep图片</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">坐姿夹胸</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/1104/">视频</a></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">坐姿推胸2</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/844/">视频</a>，双臂一起</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">杠铃卧推</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/852/">视频</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">上斜杠铃卧推</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/277/">视频</a></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">坐姿推胸1</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/251/">视频</a>，双臂分开</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">坐姿推胸2</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/844/">视频</a>，双臂一起</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">坐姿夹胸</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/1104/">视频</a></td>
</tr>
</tbody></table>
<h1 id="肩部训练（三角肌）"><a href="#肩部训练（三角肌）" class="headerlink" title="肩部训练（三角肌）"></a>肩部训练（三角肌）</h1><table>
<thead>
<tr>
<th align="left">名称</th>
<th align="left">指标</th>
<th align="left">次数</th>
<th align="left">部位</th>
<th align="left">链接/图示</th>
</tr>
</thead>
<tbody><tr>
<td align="left">肩上推举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">??? <a href="https://www.hiyd.com/dongzuo/1523/">视频</a></td>
</tr>
<tr>
<td align="left">前平举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/1516/">视频</a></td>
</tr>
<tr>
<td align="left">侧平举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/1519/">视频</a></td>
</tr>
<tr>
<td align="left">颈前提拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">？</td>
</tr>
<tr>
<td align="left">俯身飞鸟</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">区别？</td>
</tr>
<tr>
<td align="left">反向飞鸟</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">区别？</td>
</tr>
</tbody></table>
<h1 id="手臂训练（二三头）"><a href="#手臂训练（二三头）" class="headerlink" title="手臂训练（二三头）"></a>手臂训练（二三头）</h1><table>
<thead>
<tr>
<th align="left">名称</th>
<th align="left">指标</th>
<th align="left">次数</th>
<th align="left">部位</th>
<th align="left">链接/图示</th>
</tr>
</thead>
<tbody><tr>
<td align="left">仰卧臂屈伸</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.hiyd.com/dongzuo/833/">视频</a></td>
</tr>
<tr>
<td align="left">直杆二头弯举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">所以这些弯举区别是啥</td>
</tr>
<tr>
<td align="left">绳索下拉</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">曲杆弯举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://www.gotokeep.com/exercises/5763d3b011fc5077c3acf59b">视频</a> ？</td>
</tr>
<tr>
<td align="left">凳上臂屈伸</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">锤式弯举</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"><a href="https://show.gotokeep.com/exercises/5979cae611fc50467bd124ed?gender=f">视频</a>，不确定是不是哑铃，大概是绳索？</td>
</tr>
</tbody></table>
<h1 id="体能训练（循环4-6组）"><a href="#体能训练（循环4-6组）" class="headerlink" title="体能训练（循环4-6组）"></a>体能训练（循环4-6组）</h1><table>
<thead>
<tr>
<th align="left">标号</th>
<th align="left">名称</th>
<th align="left">指标</th>
<th align="left">次数</th>
<th align="left">部位</th>
<th align="left">链接/图示</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">俯卧撑</td>
<td align="left">-</td>
<td align="left">20</td>
<td align="left">肩、胸</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">登山</td>
<td align="left">-</td>
<td align="left">60s</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">站立划船</td>
<td align="left"></td>
<td align="left">15</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">卷腹</td>
<td align="left">-</td>
<td align="left">30</td>
<td align="left">上腹</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">站立举桶</td>
<td align="left"></td>
<td align="left">30</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">举腿</td>
<td align="left"></td>
<td align="left">25</td>
<td align="left">小腹</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">开合跳</td>
<td align="left"></td>
<td align="left">40</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">平板支撑</td>
<td align="left"></td>
<td align="left">1.5min-3min</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">登山</td>
<td align="left">-</td>
<td align="left">60s</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">跳台阶</td>
<td align="left">-</td>
<td align="left">30</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">硬拉</td>
<td align="left"></td>
<td align="left">20</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">波比跳</td>
<td align="left">-</td>
<td align="left">20</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">弓箭步举桶</td>
<td align="left"></td>
<td align="left">20</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">平板支撑</td>
<td align="left"></td>
<td align="left">3min</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>健身</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo+Github博客搭建教程</title>
    <url>/Hexo-Github%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>新手小白，第一次搭博客，先向前辈们大佬们隔空致敬。</p>
<p>搭建博客有很多种方法，我选择的是Hexo静态博客框架，利用Github Page服务器，比较节省时间和金钱，可以更加专注于内容本身。</p>
<span id="more"></span>

<p>首先附上参考链接：</p>
<table>
<thead>
<tr>
<th align="center">类型</th>
<th align="left">链接</th>
</tr>
</thead>
<tbody><tr>
<td align="center">概述</td>
<td align="left">1. <a href="https://zoomyale.com/2016/why_blogging/">为什么要在老掉牙的独立博客上写东西</a></td>
</tr>
<tr>
<td align="center">参考教程</td>
<td align="left">1. <a href="https://godweiyang.com/2018/04/13/hexo-blog/">超详细Hexo+Github博客搭建小白教程-韦阳</a><br>2. <a href="https://zhuanlan.zhihu.com/p/26625249">GitHub+Hexo 搭建个人网站详细教程 - 知乎</a><br>3. <a href="https://www.cnblogs.com/shwee/p/11421156.html">Hexo+Github: 个人博客网站搭建完全教程- 博客园</a><br>4. <a href="https://segmentfault.com/a/1190000021979631">超级详细Hexo+GitHub+阿里云域名的博客搭建教程，新手也能轻松学会</a><br>5. <a href="https://www.cnblogs.com/shwee/p/11421156.html">Hexo+Github: 个人博客网站搭建完全教程</a><br>6. <a href="https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/">在Hexo博客中发布文章</a></td>
</tr>
<tr>
<td align="center">个性化</td>
<td align="left">1. <a href="https://shen-yu.gitee.io/2019/ayer/">Ayer主题</a><br>2. <a href="https://yuchen-lea.github.io/2016-01-18-hexo-dir-struct/">hexo目录结构小探</a></td>
</tr>
<tr>
<td align="center">写作</td>
<td align="left">1. <a href="http://itmyhome.com/markdown/index.html">Markdown 入门参考</a><br>2. <a href="https://zhuanlan.zhihu.com/p/56943330">使用vscode开始Markdown写作之旅 - 知乎</a><br>3. <a href="https://hexo.io/zh-cn/docs/">Hexo-文档</a></td>
</tr>
<tr>
<td align="center">图床</td>
<td align="left">1. <a href="https://www.jianshu.com/p/bff6638e450f">图床工具推荐</a><br>2. <a href="https://sunhwee.com/posts/1788dd4a.html">PicGo+GitHub：你的最佳免费图床选择-洪卫</a></td>
</tr>
</tbody></table>
<h1 id="搭建博客框架"><a href="#搭建博客框架" class="headerlink" title="搭建博客框架"></a>搭建博客框架</h1><h2 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h2><p>Hexo基于Node.js，首先要下载<a href="https://nodejs.org/en/download/">Node.js安装包</a>（建议选LTS版本，current版本或许无法安装一些插件），改一下安装路径，其他安装选项选择默认就行。</p>
<p>安装完成后，<code>win+R</code>打开命令行，输入<code>node -v</code>和<code>npm -v</code>，显示版本号则安装成功。</p>
<h2 id="添加镜像"><a href="#添加镜像" class="headerlink" title="添加镜像"></a>添加镜像</h2><p>如果没有梯子，npm部分可以用阿里国内镜像加速。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></tbody></table></figure>

<h2 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h2><p>为了将本地网页文件上传到Github上，需要安装分布式版本控制工具<a href="https://git-scm.com/download/win">Git</a>。</p>
<p>有兴趣深入了解Git的话，可以参考廖雪峰老师的<a href="https://www.liaoxuefeng.com/wiki/896043488029600">Git教程</a></p>
<p>安装完成后在命令行输入git –version验证是否安装成功。</p>
<h2 id="Github部分"><a href="#Github部分" class="headerlink" title="Github部分"></a>Github部分</h2><p>每个程序猿都该有个Github啦，毕竟这就是猿的浪漫了~如果没有也没有关系，你可以从现在开始拥有这份独特的浪漫。</p>
<ol>
<li><p>注册一个<a href="https://github.com/">Github</a>账号，强烈建议名字正常一点。</p>
</li>
<li><p>新建一个仓库：</p>
<div align="center">
<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github-Picbed20210415174145.png" width="300/">
</div></li>
<li><p>仓库基本配置如下：</p>
<p>这里要注意的是：仓库的命名一定要跟用户名一样！</p>
<div align="center">
<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github-Picbed20210415222443.png">
</div></li>
<li><p>在新建好的仓库界面选择<code>setting</code>–<code>Pages</code>–<code>Choose a theme</code>，这里的主题可以随便选一个，后期可以换成别的。</p>
</li>
<li><p>刷新一下，<code>Pages</code>界面会出现你自己的网页链接，比如：<code>Your site is ready to be published at http://OrderAngel.com/OrderAngel.github.io</code></p>
<p>虽然简陋，但是这就是你的博客啦~</p>
</li>
</ol>
<h2 id="安装Hexo，生成静态框架"><a href="#安装Hexo，生成静态框架" class="headerlink" title="安装Hexo，生成静态框架"></a>安装Hexo，生成静态框架</h2><p>Hexo是一款基于Node.js的静态博客框架，生成的静态网页可以借助Github服务器发布。</p>
<ol>
<li><p>在合适的地方（这里说的一定不是C盘!）新建一个文件夹,用于存放博客文件，比如<code>E:\Study\Apollocat\blog</code>。</p>
</li>
<li><p>在该目录下右键，点击<code>Git Bash Here</code>，如果右键没有就直接搜Git bash，<code>cd</code>过去也行。</p>
</li>
<li><p>在该目录下输入<code>npm i hexo-cli -g</code>安装Hexo，或许有报错，直接无视就行。</p>
</li>
<li><p>安装完输入<code>hexo v</code>出现版本号则安装成功。</p>
</li>
<li><p>输入<code>hexo init</code>初始化文件夹，接着输入<code>nmp install</code>安装必要组件。</p>
</li>
<li><p>为了检测网站雏形，输入<code>hexo new "hello world"</code>新建文章。打开<code>E:\Study\Apollocat\blog\source\_posts</code>目录，可以看到一个<code>hello world.md</code>，这就是你新建的文章文件。</p>
</li>
<li><p>输入<code>hexo g</code>生成静态网页，再输入<code>hexo s</code>打开本地服务器。（Actually, 不生成静态网页，直接输入<code>hexo s</code>进行预览测试也可以）</p>
<p>这时用浏览器打开<code>localhost:4000</code>就能看到你的第一篇博客了，即便它只有一个标题，且只是静态的。</p>
<p>最后<code>ctrl+c</code>关闭本地服务器。</p>
</li>
</ol>
<h2 id="链接Github与本地Git"><a href="#链接Github与本地Git" class="headerlink" title="链接Github与本地Git"></a>链接Github与本地Git</h2><p>我们的网站在本地搭建完毕，如果想要发布到Github上就需要用到Git了。前面我们已经在本地安装Git了，现在需要将你的本地Git与Github链接，该步骤我们通过设置ssh秘钥来完成。</p>
<ol>
<li><p>鼠标右键打开Git Bash，设置本地Git的用户名和邮箱，注意要与Github相同，别输错了：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git config --global user.name "GitHub用户名"</span><br><span class="line">git config --global user.email "GitHub注册邮箱"</span><br></pre></td></tr></tbody></table></figure>
<p>可以用以下两条命令，检查一下你有没有输对:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git config user.name</span><br><span class="line">git config user.email</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>生成ssh秘钥：</p>
<p>ssh简单而言是一个秘钥，<code>id_rsa</code>是本地电脑的私人秘钥，<code>id_rsa.pub</code>是公共秘钥。公钥放在Github上，当链接本地与Github时，会根据公钥匹配私钥，匹配上则成功链接，之后可以用Git上传本地文件到Github上。</p>
<p>为啥需要设置ssh秘钥？由于Github要求每次上传文件的都是合法用户，因此每次上传都需要输入账号和密码来进行验证。这里设置ssh秘钥就是为了省去手动验证的步骤，上传时由Git自行匹配私钥与公钥完成验证。</p>
<p>输入命令生成ssh秘钥：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C "GitHub注册邮箱"</span><br></pre></td></tr></tbody></table></figure>
<p>直接回车，默认不设密码。</p>
</li>
<li><p>找到生成的.ssh文件夹中的id_rsa.pub秘钥，复制全部内容。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github-Picbed20210416095437.png"><br>回到Github，打开<code>Settings</code>（是头像处的settings）– <code>SSH and GPG Keys</code> – <code>New SSH Key</code>：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github-Picbed20210416101521.png"></p>
<p>Title随便写，Key部分将刚才复制的id_rsa.pub秘钥粘进去，最后点<code>Add SHH Key</code>。</p>
</li>
<li><p>在本地的Git Bash里检测Github公钥是否成功设置，输入<code>ssh git@github.com</code>，如果输出部分出现你的用户名，则设置成功。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github-Picbed20210416102021.png"></p>
</li>
</ol>
<h2 id="发布网站"><a href="#发布网站" class="headerlink" title="发布网站"></a>发布网站</h2><p>此时我们的网站已经在本地搭好了，而且本地Git也和Github成功链接，接下来要做的就是把本地搭的网站发布出去，让网站可以被其他人访问。</p>
<ol>
<li><p>打开本地blog根目录下的站点配置文件_config.yml，该文件用于配置博客的基本信息。</p>
<p>需要注意的是，theme文件夹中有个同名文件，我们称之为主题配置文件，用于配置博客的主题信息。</p>
</li>
<li><p>修改站点配置文件_config.yml的最后一行配置并保存：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210416105511.png"></p>
<p>这里的<code>repository</code>可以简写为<code>repo</code>，是你Github上创建的博客仓库的路径。</p>
<p><strong>注意</strong>：这里的branch可以设置为main或者master，但务必与Github仓库中<code>Settings</code>–<code>Pages</code>–<code>Source</code>–<code>Branch</code>相匹配，否则即使上传成功也看不到你的网站。</p>
<p>修改deploy其实是在给网站部署命令<code>hexo d</code>做相应配置，使用该命令进行部署时，hexo就能知道要把blog部署到Github的博客仓库中。</p>
</li>
<li><p>安装Git部署插件：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>分别输入以下三条命令：</p>
<figure class="highlight c"><table><tbody><tr><td class="code"><pre><span class="line">hexo clean <span class="comment">//清除缓存，若是网页正常情况下可以忽略这条命令</span></span><br><span class="line">hexo g <span class="comment">//生成静态网页</span></span><br><span class="line">hexo d <span class="comment">//部署</span></span><br></pre></td></tr></tbody></table></figure>
<p>之后打开浏览器，输入部分博客仓库路径<code>OrderAngel.github.io</code>，就能看到你发布的博客了。</p>
</li>
</ol>
<h1 id="优化博客框架"><a href="#优化博客框架" class="headerlink" title="优化博客框架"></a>优化博客框架</h1><h2 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h2><p>如果嫌弃<code>balabala.github.io</code>这种统一标识的域名，可以绑定自己的个性化域名。</p>
<ol>
<li><p>没有域名的话要先买个域名，百度云阿里云腾讯云之类的都能买，我个人用的是<a href="https://homenew.console.aliyun.com/home/dashboard/ProductAndService">阿里云</a>。</p>
<p>登陆后进入右上角的<code>控制台</code>，点<code>产品与服务</code> – <code>域名</code> –<code>域名注册</code>。</p>
<p>把喜欢的域名买下来吧~</p>
</li>
<li><p>解析域名：在域名控制台界面下，点击<code>解析</code>。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418093157.png"></p>
<p>在解析设置界面，点击<code>添加记录</code>，添加两条记录：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418093651.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418093743.png"></p>
<p>记录值这里是：<code>用户名.github.io</code>这个现在可以直接访问的部分仓库路径。</p>
</li>
<li><p>回到你的Github博客仓库中，选择<code>Settings</code> – <code>Pages</code>，在<code>Custom domain</code>这里， 输入你购买的域名后保存。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418094423.png"></p>
<p>这里的<code>www.</code>输不输都行。</p>
</li>
<li><p>在本地blog文件夹中，blog/source目录下，创建一个记事本文件，输入你购买的域名。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418095345.png"></p>
<p>这里的域名建议不带<code>www.</code>，如果带上以后必须有完整的<code>www.balabala..</code>才能访问，如果不带，以后域名有没有<code>www.</code>都能访问。</p>
<p>文件命名为<code>CNAME</code>，保存类型为<code>所有文件(*.*)</code>。</p>
</li>
<li><p>最后，将我们改动的配置同步到Github中就行了：在本地blog目录下，进入Git Bash命令行(cmd和powershell也行)，输入：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">hexo clean </span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></tbody></table></figure>

<p>现在，打开浏览器输入你自己的域名，就可以直接进入你的博客了~</p>
</li>
</ol>
<h2 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h2><p>之前随便选的Hexo主题或许不合心意，但不用care，因为我们还可以更换其他主题。</p>
<p>可以在<a href="https://hexo.io/themes/">Theme</a>中Pick心水的主题。我个人用的是<a href="https://shen-yu.gitee.io/">Ayer</a>，这位博主的写的主题配置教程很nice。其他常用的，比如Next主题，也很棒。</p>
<ol>
<li>如果Theme的博主有相关教程，按说明进行安装配置；如果没有的话，先去Github里下载下来，放在本地的<code>blog\themes</code>目录下：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418105207.png"></li>
</ol>
<ol start="2">
<li><p>在本地blog目录下，打开站点配置文件<code>_config.yml</code>，修改theme为你选的主题名，比如ayer。这里注意要与<code>blog\themes</code>目录下该主题命名相同。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418105658.png"></p>
</li>
<li><p>一般关于该主题的使用教程会在Theme博主的Blog里给出；如果没有的话，搜下有无相关教程，或者自行研究一下本地<code>blog\themes\主题名</code>目录下的主题配置文件<code>_config.yml</code>，主题相关的主要配置都在该文件中。</p>
<p>关于主题文件夹的目录说明，可以参考<a href="https://hexo.io/zh-cn/docs/themes.html">主题hexo</a>。</p>
</li>
<li><p>最后，再次部署网站，还是：</p>
<figure class="highlight c"><table><tbody><tr><td class="code"><pre><span class="line">hexo s <span class="comment">//本地预览测试：可以先打开本地服务器，在localhost:4000中看看效果</span></span><br><span class="line">hexo clean <span class="comment">//清除缓存</span></span><br><span class="line">hexo g <span class="comment">//生成</span></span><br><span class="line">hexo d <span class="comment">//部署</span></span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<h2 id="hexo私人定制"><a href="#hexo私人定制" class="headerlink" title="hexo私人定制"></a>hexo私人定制</h2><p>工欲善其事，必先利其器。在进行一些更高级的私人配置前，我们有必要先了解一下blog文件夹里的文件都是用来干啥的。</p>
<h3 id="hexo目录说明"><a href="#hexo目录说明" class="headerlink" title="hexo目录说明"></a>hexo目录说明</h3><p>这是我blog文件夹下的目录，由于使用了一段时间，因此也有些私设，请大致参考。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">|──_config.yml</span><br><span class="line">|──package.json</span><br><span class="line">|──.deploy_git</span><br><span class="line">|──node_modules</span><br><span class="line">|──public</span><br><span class="line">|──scaffolds</span><br><span class="line">|──source</span><br><span class="line">      |──_posts</span><br><span class="line">      |──categories</span><br><span class="line">      |──pictures</span><br><span class="line">      |──tags</span><br><span class="line">|──themes</span><br><span class="line">      |──landscape</span><br><span class="line">      |──ayer</span><br></pre></td></tr></tbody></table></figure>
<h4 id="1-config-yml"><a href="#1-config-yml" class="headerlink" title="1. _config.yml"></a>1. _config.yml</h4><p>   站点配置文件，初始化时自动创建。</p>
<p>   具体配置可参考<a href="https://hexo.io/zh-cn/docs/configuration.html">配置hexo</a></p>
<h4 id="2-package-json"><a href="#2-package-json" class="headerlink" title="2. package.json"></a>2. package.json</h4><p>   应用程序文件，初始化时自动创建。</p>
<p>   可以查看hexo版本以及安装的扩展版本。</p>
<h4 id="3-deploy-git"><a href="#3-deploy-git" class="headerlink" title="3. .deploy_git"></a>3. .deploy_git</h4><p>   对应Github博客仓库中的内容 = 最近一次成功上传到Github上的public文件夹内容。在部署到Github后自动创建。</p>
<p>   可能出现的与public内容不一致，是由于重新生成但未上传所致。简而言之，public是<code>hexo g</code>生成静态页面的内容，而.deploy_git中是<code>hexo d</code>部署到Github中的内容。</p>
<h4 id="4-node-modules"><a href="#4-node-modules" class="headerlink" title="4. node_modules"></a>4. node_modules</h4><p>   存放安装的Hexo扩展，还有node .js的各种库。</p>
<h4 id="5-public"><a href="#5-public" class="headerlink" title="5. public"></a>5. public</h4><p>   执行<code>hexo g</code>命令后，Hexo会解析source文件夹和当前的Theme，从而生成静态网页，该内容存放于public文件夹中。</p>
<h4 id="6-scaffolds"><a href="#6-scaffolds" class="headerlink" title="6. scaffolds"></a>6. scaffolds</h4><p>   模板文件夹。<br>   内有页面模板<code>page.md</code>、文章模板<code>post.md</code>、草稿模板<code>draft.md</code>三个文件。<br>   具体可参考<a href="https://hexo.io/zh-cn/docs/templates.html">模板hexo</a>。</p>
<h4 id="7-source"><a href="#7-source" class="headerlink" title="7. source"></a>7. source</h4><p>   存放用户资源。</p>
<ol>
<li><p>_post</p>
<p>存放文章。<br>其中markdown文件(md)、html文件、org文件在<code>hexo g</code>生成页面过程中会被解析并拷贝到public文件夹中，最终通过<code>hexo d</code>发布。</p>
</li>
<li><p>其他_balabala文件夹/文件</p>
<p>生成时将会被忽略。</p>
<p>因此可以在此目录下创建_drafts文件夹来存放草稿。</p>
</li>
<li><p>其他非_balabala文件夹/文件</p>
<p>生成时会被拷贝到public中。</p>
<p>除了文章外，还会有图片、标签等用户资源，可以使用<code>hexo new page pilipili</code>来新建子目录<code>pilipili</code>。</p>
<p>比如我的目录下就有categories、pictures、tags等子目录。</p>
</li>
</ol>
<h4 id="themes"><a href="#themes" class="headerlink" title="themes"></a>themes</h4><p>   主题文件夹。<br>   我使用的是Ayer主题，因此在我的themes文件夹下，除了默认主题lanscape外，还有ayer文件夹。</p>
<h3 id="可以考虑的定制"><a href="#可以考虑的定制" class="headerlink" title="可以考虑的定制"></a>可以考虑的定制</h3><h4 id="1-对-config-yml进行修改"><a href="#1-对-config-yml进行修改" class="headerlink" title="1. 对_config.yml进行修改"></a>1. 对_config.yml进行修改</h4><p>   对blog目录下的站点配置文件_config.yml进行个性化修改，具体可以参考<a href="https://hexo.io/zh-cn/docs/configuration.html">配置hexo</a>。</p>
<h5 id="网站Site："><a href="#网站Site：" class="headerlink" title="网站Site："></a>网站Site：</h5><p>我们可以对文件中的site部分进行修改，比如：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction20210418121141.png"></p>
<h5 id="网址URL"><a href="#网址URL" class="headerlink" title="网址URL"></a>网址URL</h5><p>将url改成自己的网站域名，如：<code>http://apollomao.com</code>。</p>
<p>还可以对网址的永久链接格式进行修改，具体可参考<a href="https://hexo.io/zh-cn/docs/permalinks">永久链接</a></p>
<h4 id="2-对scaffolds文件夹中的模板文件进行修改"><a href="#2-对scaffolds文件夹中的模板文件进行修改" class="headerlink" title="2. 对scaffolds文件夹中的模板文件进行修改"></a>2. 对scaffolds文件夹中的模板文件进行修改</h4><p>所谓模板，即就是预定义，可以在每创建一篇文章后，预定义文章头部，省事。</p>
<p>比如，我的文章模板<code>post.md</code>为：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210418230721.png"></p>
<p>那么我每次<code>hexo new post balabala</code>生成新的文章，该文章的头部就会是：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210418230825.png"></p>
<p>只需要按照需求补充一下tages、categories等值即可：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210418231042.png"></p>
<p>网页模板<code>page.md</code>和草稿模板<code>draft.md</code>也可参考<code>post.md</code>进行设置。创建命令分别是<code>hexo new page balabala</code>和<code>hexo new draft balabala</code>。</p>
<h4 id="3-其他"><a href="#3-其他" class="headerlink" title="3. 其他"></a>3. 其他</h4><p>还有一些常见的定制策略，比如加背景、加侧栏菜单、加背景音乐、加404界面等等，部分功能可能主题自带的，其他感兴趣的可以自行搜索~（开头的<a href="https://www.cnblogs.com/shwee/p/11421156.html">参考教程5</a>中包含一些，我没有尝试，仅供参考）</p>
<h2 id="图床"><a href="#图床" class="headerlink" title="图床"></a>图床</h2><p>图床是可以上传图片的服务器。常用的图床有很多，可以参考开头的<a href="https://www.jianshu.com/p/bff6638e450f">图床工具推荐</a>选择合适的图床和图床工具。</p>
<p>我个人用的是Github + PicGo的组合，因为省钱233</p>
<p>具体安装教程可以参考开头的<a href="https://sunhwee.com/posts/1788dd4a.html">PicGo+GitHub：你的最佳免费图床选择-洪卫</a>。</p>
<p>附上我的PicGo配置仅供参考：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419001244.png"></p>
<p>需要注意的是，与参考教程不同，在配置PicGo阶段，设定分支名需要与Github仓库中<code>Settings</code>–<code>Pages</code>–<code>Source</code>–<code>Branch</code>相对应，而不是统一设master。</p>
<ul>
<li>Note<ul>
<li>PicGo为了稳定期间最好别装测试版。</li>
<li>不要试图装watermark插件，别问我怎么知道的… orz</li>
</ul>
</li>
</ul>
<h1 id="牛刀小试"><a href="#牛刀小试" class="headerlink" title="牛刀小试"></a>牛刀小试</h1><p>现在我们来正经发一篇文章。</p>
<h2 id="Markdown基础"><a href="#Markdown基础" class="headerlink" title="Markdown基础"></a>Markdown基础</h2><p>博客文章主要用Markdown编写，有很多写作工具，我个人用的是VSCode。</p>
<p>零基础的同学可以参考<a href="https://zhuanlan.zhihu.com/p/56943330">使用vscode开始Markdown写作之旅</a>进行学习，亲测很好用~</p>
<p>附上其中的基础语法仅供参考：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419002530.png"></p>
<p>等你正式开始写文章的时候，具体一些用法还可以参考<a href="http://itmyhome.com/markdown/index.html">Learning-Markdown (Markdown 入门参考)</a></p>
<ul>
<li>最后再贴出来一个范例：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419003218.png"></p>
<p>这部分除了基础语法，我还用到了插入链接 <code>[title](网址)</code>，以及插入图片 <code>![title](图床地址or本地链接)</code>(直接从PicGo图床里复制就行)。</p>
<h2 id="正经发布一篇文章"><a href="#正经发布一篇文章" class="headerlink" title="正经发布一篇文章"></a>正经发布一篇文章</h2><p>get了最基础的markdown语法后，我们来走一遍完整流程。</p>
<ol>
<li><p>创建一篇文章”博客简介”</p>
<p>在本地blog目录下，右键进入Git Bash，输入：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">hexo new post "博客简介"</span><br></pre></td></tr></tbody></table></figure>
<p><strong>注意</strong>：</p>
<ul>
<li><p>post是默认值可以省略。</p>
</li>
<li><p>如果title有空格，必须要加双引号，否则双引号可以省略。</p>
</li>
</ul>
</li>
<li><p>编辑文章</p>
<p>在 blog\source_posts 路径下生成了<code>博客简介.md</code>文件，用vscode打开，编辑自己的文章。</p>
<p>比如我的博客简介是这么写的（仅供参考）：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419093855.png"></p>
<ul>
<li><p>可以在文章任意位置添加<code>&lt;!--more--&gt;</code>，首页只会显示more前的内容，more后的内容点击阅读全文后展示。</p>
</li>
<li><p>如果想给文章添加分类和标签，可以在文章头部补充，比如我是这么写的：<br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419093519.png"></p>
</li>
</ul>
</li>
<li><p>本地预览</p>
<p>写好文章后保存。</p>
<p><code>hexo s</code>启动本地服务器，在 <a href="http://localhost:4000/">http://localhost:4000</a> 进行预览测试。</p>
</li>
<li><p>发布文章<br>Finally!<br>输入以下命令，将写好的“博客简介”发布到网站上吧~</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></tbody></table></figure>
<p>此时，在浏览器访问自己的博客域名，就可以看到我们写的第一篇正经文章啦~ <span class="github-emoji"><span>☀</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2600.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>😼</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f63c.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419101933.png"><br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/Blogconstruction/Hexo20210419101753.png"></p>
<ul>
<li>附上<a href="https://sunhwee.com/posts/a927e90e.html#toc-heading-5">Markdown Emoji表情语法速查表</a></li>
</ul>
</li>
</ol>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>Anyway，终于搞完了~</p>
<p>4.12号开始搭，断断续续搞，也遇到了不少bug，4.14才搭的差不多，然后这篇教程又断断续续写了4天 orz</p>
<p>希望能对你有所帮助，欢迎批评指正，爱你ღ( ´･ᴗ･` )</p>
<hr>
<p>阿波罗猫</p>
<p>20210419</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>V-SLAM整理1</title>
    <url>/V-SLAM%E6%95%B4%E7%90%861/</url>
    <content><![CDATA[<p>VSLAM学习素材是高翔老师的《视觉SLAM十四讲第二版》。这是我首次接触SLAM，感觉还算有趣。学士学完了，但是还需要系统的梳理一遍知识体系。</p>
<p>内容比较多，放在两个博客里记述，第一部分是基础知识，第二部分是SLAM实践。</p>
<p>好了，废话不多说，开始吧~</p>
<h1 id="第1讲-预备知识"><a href="#第1讲-预备知识" class="headerlink" title="第1讲 预备知识"></a>第1讲 预备知识</h1><p>没啥内容，略过</p>
<hr>
<h1 id="第2将-初始SLAM"><a href="#第2将-初始SLAM" class="headerlink" title="第2将 初始SLAM"></a>第2将 初始SLAM</h1><h2 id="2-2-经典视觉SLAM框架"><a href="#2-2-经典视觉SLAM框架" class="headerlink" title="2.2 经典视觉SLAM框架"></a>2.2 经典视觉SLAM框架</h2><p>一图以蔽之：<br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928163420.png"></p>
<p>我们把相机传感器放到一个未知空间中，相机边移动边拍摄，我们的目的是通过这些帧图构建未知空间的地图。那么我们首先要先反向计算出相机是怎么移动的，再根据相机的移动轨迹来建图。<strong>【建图这里也许还要加上拍摄图片，记不清了，先这么理解，后面再说】</strong></p>
<p>我们通过相机传感器得到了数据，现在需要用堆数据来建图。相机在不停的移动，我们把某个时刻得到的帧图交给前端视觉里程器，视觉里程器可以通过相邻帧的数据（这里要调前面传进来的帧图）来估算相邻相机的运动，进而算出此刻相机的位姿，还要估算这部分数据对应的局部地图。前端会将估计的相机位姿和局部地图提供给后端。</p>
<p>这些数据除了要交给视觉里程计，还要同时给回环检测，回环检测会对比当前帧图和之前的帧图，来判断相机是否之前来过此地，一旦检测到回环，就会将回环信息提供给后端。搞回环主要是为了修正漂移。</p>
<p>后端接收前端和回环给的信息，将这些信息进行优化，得到全局一致的相机轨迹和地图。</p>
<p>建图环节会根据估计的轨迹和任务需求，来建立不同的地图。</p>
<h2 id="2-3-SLAM问题的数学表达"><a href="#2-3-SLAM问题的数学表达" class="headerlink" title="2.3 SLAM问题的数学表达"></a>2.3 SLAM问题的数学表达</h2><p>运动方程：k时刻相机位姿&lt;—k-1时刻位姿x + k时刻运动传感器的读数/输入u + k 时刻噪声w。</p>
<p>观测方程：j位置k时刻的观测数据z&lt;—j位置路标y + k时刻相机位姿x + 噪声v，相机对路标点拍摄后得到图像中的像素。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928170515.png"></p>
<p>在SLAM里面，通常会已知运动测量的读数u（输入数据）来估计位置x（定位），已知传感器读数z（观测数据）来估计y（建图）。</p>
<p><em>这俩方程其实挺不规整的，要估计的值一个在右边一个在左边…有毒。</em></p>
<h2 id="2-4-编程"><a href="#2-4-编程" class="headerlink" title="2.4 编程"></a>2.4 编程</h2><ol>
<li>linux 18.04</li>
<li>g++编译器</li>
<li>cmake编译器</li>
<li>IDE：KDevelop</li>
</ol>
<hr>
<h1 id="第3讲-三维空间刚体运动"><a href="#第3讲-三维空间刚体运动" class="headerlink" title="第3讲 三维空间刚体运动"></a>第3讲 三维空间刚体运动</h1><h2 id="3-1-旋转矩阵"><a href="#3-1-旋转矩阵" class="headerlink" title="3.1 旋转矩阵"></a>3.1 旋转矩阵</h2><h3 id="3-1-1-点、向量、坐标系"><a href="#3-1-1-点、向量、坐标系" class="headerlink" title="3.1.1 点、向量、坐标系"></a>3.1.1 点、向量、坐标系</h3><p>反对称符号^</p>
<h3 id="3-1-2-坐标系间的欧式变换"><a href="#3-1-2-坐标系间的欧式变换" class="headerlink" title="3.1.2 坐标系间的欧式变换"></a>3.1.2 坐标系间的欧式变换</h3><p>将坐标系A中的向量通过计算变换到坐标系B中，可以用<strong>欧式变换</strong>来实现。</p>
<p>欧式变换包括旋转和平移。其中旋转可以用一个<strong>旋转矩阵R</strong>来描述，旋转+平移用<strong>变换矩阵T</strong>来描述。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928175923.png"></p>
<p>需要注意的是：</p>
<ul>
<li>旋转矩阵是一个正交矩阵，其逆亦为其转置</li>
<li>旋转矩阵的逆表示一个相反的旋转</li>
<li>R12指坐标系2变换到坐标系1</li>
</ul>
<h3 id="3-1-3-变换矩阵与齐次坐标"><a href="#3-1-3-变换矩阵与齐次坐标" class="headerlink" title="3.1.3 变换矩阵与齐次坐标"></a>3.1.3 变换矩阵与齐次坐标</h3><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928175642.png"></p>
<p>通过引入齐次坐标，两次变换的叠加便可以用两个变换矩阵相乘来表示，算是一个数学上的trick。</p>
<p>需要注意，旋转矩阵不引入齐次坐标。</p>
<h2 id="3-2-编程1"><a href="#3-2-编程1" class="headerlink" title="3.2 编程1"></a>3.2 编程1</h2><p>Eigen库：主要用来作矩阵运算</p>
<h2 id="3-3-旋转向量和欧拉角"><a href="#3-3-旋转向量和欧拉角" class="headerlink" title="3.3 旋转向量和欧拉角"></a>3.3 旋转向量和欧拉角</h2><h3 id="3-3-1-旋转向量"><a href="#3-3-1-旋转向量" class="headerlink" title="3.3.1 旋转向量"></a>3.3.1 旋转向量</h3><p>旋转矩阵缺陷：</p>
<ul>
<li>自由度冗余</li>
<li>矩阵自带约束</li>
</ul>
<p>旋转向量是另一种描述选择的方式，由旋转轴+旋转角组成。</p>
<p>（nθ）</p>
<p>旋转向量和旋转矩阵直接可以相互转换。</p>
<h3 id="3-3-2-欧拉角"><a href="#3-3-2-欧拉角" class="headerlink" title="3.3.2 欧拉角"></a>3.3.2 欧拉角</h3><p>首先，这个欧拉角和欧拉变换没啥直接关系，就是撞名了。</p>
<p>由于旋转矩阵和旋转向量都不够直观，这里引出足够直观的另一种描述旋转的方式：欧拉角。</p>
<p>（[r,p,y]^T）</p>
<p>欧拉角将一次旋转分解为3次绕不同轴的旋转：</p>
<ul>
<li>绕z，偏航角yaw</li>
<li>绕y，俯仰角pitch</li>
<li>绕x，滚转角roll</li>
</ul>
<p>例如，rpy角的旋转顺序是ZYX</p>
<p>欧拉角的缺陷：万向锁，即欧拉角存在奇异性。</p>
<h2 id="3-4-四元数"><a href="#3-4-四元数" class="headerlink" title="3.4 四元数"></a>3.4 四元数</h2><h3 id="3-4-1-四元数的定义"><a href="#3-4-1-四元数的定义" class="headerlink" title="3.4.1 四元数的定义"></a>3.4.1 四元数的定义</h3><ul>
<li>旋转矩阵缺点：不够直观，冗余</li>
<li>旋转向量缺点：不够直观，奇异性</li>
<li>欧拉角缺点：奇异性</li>
<li>四元数缺点：不够直观，运算复杂</li>
</ul>
<p>单位四元数可以描述一个三维旋转。</p>
<p>四元数和复数类有点像，一个实部+三个虚部。</p>
<p>q=q0+q1i+q2j+q3k;</p>
<p>q=[s,v]^T, s=q0, v=[q1,q2,q3]^T</p>
<h3 id="3-4-2-四元数的运算"><a href="#3-4-2-四元数的运算" class="headerlink" title="3.4.2 四元数的运算"></a>3.4.2 四元数的运算</h3><ol>
<li>加减</li>
<li>乘法</li>
<li>模长</li>
<li>共轭</li>
<li>逆</li>
<li>数乘</li>
</ol>
<h3 id="3-4-3-用四元数表示旋转"><a href="#3-4-3-用四元数表示旋转" class="headerlink" title="3.4.3 用四元数表示旋转"></a>3.4.3 用四元数表示旋转</h3><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928204734.png">，</p>
<p>其中q为旋转四元数，等于把p转到四维空间再转回来。</p>
<h3 id="3-4-4-四元数到其他旋转表示的旋转"><a href="#3-4-4-四元数到其他旋转表示的旋转" class="headerlink" title="3.4.4 四元数到其他旋转表示的旋转"></a>3.4.4 四元数到其他旋转表示的旋转</h3><p>简单来说：</p>
<ul>
<li>四元数和旋转向量可以相互转换</li>
<li>旋转矩阵和旋转向量可以相互转换</li>
</ul>
<h2 id="3-5-相似、仿射、射影变换"><a href="#3-5-相似、仿射、射影变换" class="headerlink" title="3.5 相似、仿射、射影变换"></a>3.5 相似、仿射、射影变换</h2><p>这些变化都是前面的欧式变换的拓展，思路差不多：</p>
<ol>
<li>相似变换</li>
<li>仿射变换</li>
<li>射影变换</li>
</ol>
<h2 id="3-6-编程2"><a href="#3-6-编程2" class="headerlink" title="3.6 编程2"></a>3.6 编程2</h2><p>Eigen几何模块</p>
<h2 id="3-7-编程3"><a href="#3-7-编程3" class="headerlink" title="3.7 编程3"></a>3.7 编程3</h2><p>可视化演示</p>
<h3 id="3-7-1-显示运动轨迹"><a href="#3-7-1-显示运动轨迹" class="headerlink" title="3.7.1 显示运动轨迹"></a>3.7.1 显示运动轨迹</h3><p>Pangolin库：支持3D绘图</p>
<ul>
<li>轨迹文件每一行格式：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928205725.png">，其中t为平移。</p>
<ul>
<li>所谓轨迹，就是把一系列机器人坐标系原点在世界坐标系中的坐标连起来：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928210214.png"></p>
<h3 id="3-7-2-显示相机位姿"><a href="#3-7-2-显示相机位姿" class="headerlink" title="3.7.2 显示相机位姿"></a>3.7.2 显示相机位姿</h3><hr>
<h1 id="第4讲-李群与李代数"><a href="#第4讲-李群与李代数" class="headerlink" title="第4讲 李群与李代数"></a>第4讲 李群与李代数</h1><h2 id="4-1-李群与李代数基础"><a href="#4-1-李群与李代数基础" class="headerlink" title="4.1 李群与李代数基础"></a>4.1 李群与李代数基础</h2><p>旋转矩阵构成了特殊正交群SO(3)，变换矩阵构成了特殊欧式群SE(3)。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210928222743.png"></p>
<p>旋转矩阵和变换矩阵——只对乘法封闭，对加法不封闭。</p>
<p>群：只有一个封闭运算的集合</p>
<h3 id="4-1-1-群"><a href="#4-1-1-群" class="headerlink" title="4.1.1 群"></a>4.1.1 群</h3><p>更严谨的定义一下群：群是一种集合加上一种运算的代数结构。<br>群里的集合对于群的运算满足以下性质：</p>
<ul>
<li>封闭性</li>
<li>结合律</li>
<li>幺元</li>
<li>逆</li>
</ul>
<p>李群：具有连续性质的群。</p>
<ul>
<li>SO(3)、SE(3)</li>
</ul>
<p>但是由于SO(3)和SE(3)只有定义良好的乘法而没有加法，因此难以求导，故，引入李代数。</p>
<p>每一个李群都对应着一个李代数。</p>
<h3 id="4-1-2-李代数的引出"><a href="#4-1-2-李代数的引出" class="headerlink" title="4.1.2 李代数的引出"></a>4.1.2 李代数的引出</h3><p>对旋转矩阵求导引出的概念</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929091937.png"></p>
<h3 id="4-1-3-李代数的定义"><a href="#4-1-3-李代数的定义" class="headerlink" title="4.1.3 李代数的定义"></a>4.1.3 李代数的定义</h3><p>每个李群对应一个李代数。</p>
<p>李代数描述李群的局部性质，是单位元附近的正切空间。</p>
<p>李代数g：集合V + 数域F + 二元运算(李括号)[,]</p>
<h3 id="4-1-4-李代数so-3"><a href="#4-1-4-李代数so-3" class="headerlink" title="4.1.4 李代数so(3)"></a>4.1.4 李代数so(3)</h3><p>SO(3)对应的李代数so(3)里的元素记作Φ：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929091427.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929091737.png"></p>
<p>so(3)是一个由三维向量组成的集合，每个向量对应一个反对称矩阵，可以用于表达旋转矩阵的导数。</p>
<p>so(3)与SO(3)关系：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929092033.png"></p>
<h3 id="4-1-5-李代数se-3"><a href="#4-1-5-李代数se-3" class="headerlink" title="4.1.5 李代数se(3)"></a>4.1.5 李代数se(3)</h3><p>se(3)的每个元素是一个6维向量，前三维表示平移，后三维表示旋转，其后三维就是so(3)的元素Φ。因此，se(3)可以理解为一个三维平移加上一个so(3)元素。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929092633.png"></p>
<ul>
<li>∧：指代从向量到矩阵</li>
<li>∨：指代从矩阵到向量</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929092531.png"></p>
<h1 id="4-2-指数与对数映射"><a href="#4-2-指数与对数映射" class="headerlink" title="4.2 指数与对数映射"></a>4.2 指数与对数映射</h1><p>前面有提到so(3)和SO(3)之间可以用exp来转换，这章主要是说so(3)、se(3)和SO(3)、SE(3)之间的转换（也就是这个exp）究竟是如何计算的。</p>
<p>有趣的是，SO(3)对应旋转矩阵，而so(3)对应旋转向量。</p>
<h3 id="4-2-1-SO-3-上的指数映射"><a href="#4-2-1-SO-3-上的指数映射" class="headerlink" title="4.2.1 SO(3)上的指数映射"></a>4.2.1 SO(3)上的指数映射</h3><ul>
<li>so(3)—&gt;SO(3)：通过指数映射，可以将so(3)中的任意一个向量对应到SO(3)中的一个旋转矩阵上。</li>
</ul>
<p>R=exp(Φ^)=exp(θa^), 其中θ是模长，a是方向。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929094246.png"></p>
<ul>
<li>SO(3)—&gt;so(3)：对数映射</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929094947.png"></p>
<ul>
<li>需要注意的是，这种映射并不是一一对应的，一个SO(3)可能对应多个so(3)。</li>
</ul>
<h3 id="4-2-2-SE-3-上的指数映射"><a href="#4-2-2-SE-3-上的指数映射" class="headerlink" title="4.2.2 SE(3)上的指数映射"></a>4.2.2 SE(3)上的指数映射</h3><ul>
<li>se(3)—&gt;SE(3)：指数映射</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929095400.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929095524.png"></p>
<ul>
<li><p>SE(3)—&gt;se(3)：略</p>
</li>
<li><p><strong>总结一下转换关系：</strong></p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929095957.png"></p>
<h2 id="4-3-李代数求导与扰动模型"><a href="#4-3-李代数求导与扰动模型" class="headerlink" title="4.3 李代数求导与扰动模型"></a>4.3 李代数求导与扰动模型</h2><h3 id="4-3-1-BCH公式与近似模型"><a href="#4-3-1-BCH公式与近似模型" class="headerlink" title="4.3.1 BCH公式与近似模型"></a>4.3.1 BCH公式与近似模型</h3><p>探索一下李群乘法和李代数加法之间的关系。</p>
<ul>
<li><p>SO(3) &amp; so(3)：</p>
<ul>
<li><p>李群乘法：在李群上左乘小量，等于在李代数上加上一个左雅克比的逆乘小量</p>
<p>给旋转矩阵R左乘一个微小扰动—ΔR·R（左乘右乘区别不大，可以互推）</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929101057.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929101149.png"></p>
</li>
<li><p>李代数加法：在李代数上加上小量，等于在李群上左乘一个左雅克比乘小量</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929101614.png"></p>
</li>
</ul>
</li>
<li><p>SE(3) &amp; se(3)：</p>
<p>  <img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929101716.png"></p>
</li>
</ul>
<h3 id="4-3-2-SO-3-上的李代数求导"><a href="#4-3-2-SO-3-上的李代数求导" class="headerlink" title="4.3.2 SO(3)上的李代数求导"></a>4.3.2 SO(3)上的李代数求导</h3><p>选择矩阵R的求导在SLAM上有很强的应用性：</p>
<p>观测方程：z=Tp+w，相机以T位姿观察到p点，在w噪声情况下产生观测数据z。</p>
<p>虽然有时候我们是用观测数据和通过运动方程得到的相机位姿来估计路标点p，但有时候并没有相机位姿反而有路标点p的数据，我们也可以利用路标点和观测来估计位姿。在这种情况下，相当于寻找一个最优的T，使得整体误差最小化：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929102802.png"></p>
<p>这是最小二乘估计，求解时目标函数J要对变换矩阵T求导。</p>
<p>总之就是SLAM里面经常出现”与位姿相关的函数对位姿求导”的情况，这时就需要对李群求导，但由于李群没有加法不太好搞，于是需要利用李代数来解决李群上的求导问题，思路包括：</p>
<ol>
<li>李代数求导模型：通过李群到李代数的转换，用李代数来表示位姿，然后对李代数求导</li>
<li>扰动模型：对李群左乘（右乘）微小扰动，对该扰动求导</li>
</ol>
<h3 id="4-3-3-李代数求导"><a href="#4-3-3-李代数求导" class="headerlink" title="4.3.3 李代数求导"></a>4.3.3 李代数求导</h3><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929104458.png"> 等效于 <img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929104519.png"></p>
<p>这个思路逻辑比较清晰，但是计算略麻烦，故通常并不使用这个求导思路。</p>
<h3 id="4-3-4-扰动模型（左乘）"><a href="#4-3-4-扰动模型（左乘）" class="headerlink" title="4.3.4 扰动模型（左乘）"></a>4.3.4 扰动模型（左乘）</h3><p>空间点p经过一次旋转R，对左扰动对应的李代数求导：设左扰动ΔR对应李代数φ</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929104832.png"></p>
<h3 id="4-3-5-SE-3-上的李代数求导"><a href="#4-3-5-SE-3-上的李代数求导" class="headerlink" title="4.3.5 SE(3)上的李代数求导"></a>4.3.5 SE(3)上的李代数求导</h3><p>扰动模型</p>
<p>空间点p经过一次变化T，对左扰动对应的李代数求导</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929105439.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929105514.png"></p>
<h2 id="编程"><a href="#编程" class="headerlink" title="编程"></a>编程</h2><h3 id="4-4-1-Sophus基本使用"><a href="#4-4-1-Sophus基本使用" class="headerlink" title="4.4.1 Sophus基本使用"></a>4.4.1 Sophus基本使用</h3><p>Sophus库：李群/李代数库，本书使用带模板的Sophus库</p>
<h3 id="4-4-2-评估轨迹误差"><a href="#4-4-2-评估轨迹误差" class="headerlink" title="4.4.2 评估轨迹误差"></a>4.4.2 评估轨迹误差</h3><p>误差指标：</p>
<ul>
<li>绝对轨迹误差ATE</li>
<li>绝对平移误差</li>
<li>相对位姿误差RPE</li>
<li>相对位姿平移误差</li>
</ul>
<h2 id="4-5-相似变换群与李代数"><a href="#4-5-相似变换群与李代数" class="headerlink" title="4.5 相似变换群与李代数"></a>4.5 相似变换群与李代数</h2><p>没看，略</p>
<hr>
<h1 id="第5讲-相机与图像"><a href="#第5讲-相机与图像" class="headerlink" title="第5讲 相机与图像"></a>第5讲 相机与图像</h1><h2 id="5-1-相机模型"><a href="#5-1-相机模型" class="headerlink" title="5.1 相机模型"></a>5.1 相机模型</h2><p>相机将三维世界坐标点（m）映射到二维图像平面（像素）的过程可以用一个几何模型来描述。</p>
<p>相机内参数：针孔模型 + 畸变模型，外部三维点投影到相机内部的成像平面。</p>
<h3 id="5-1-1-针孔相机模型"><a href="#5-1-1-针孔相机模型" class="headerlink" title="5.1.1 针孔相机模型"></a>5.1.1 针孔相机模型</h3><p>步骤：</p>
<ul>
<li>现实世界P[X,Y,Z]^T</li>
<li>成像平面P’[X’,Y’,Z’]^T<ul>
<li>真实成像平面</li>
<li>对称成像平面</li>
<li>归一化成像平面[x,y]^T </li>
</ul>
</li>
<li>像素平面[u,v]^T：在成像平面上对像进行采样和量化</li>
</ul>
<p><strong>内参</strong>：矩阵K为相机的内参数，有时生产厂商会告诉你，但有时也需要自己去标定。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929113717.png"></p>
<p><strong>外参</strong>：上面公式中的P实际上是<code>相机的世界坐标</code>根据<code>相机位姿</code>变换到<code>相机坐标系</code>下的结果。<code>相机位姿</code>，也就是这个变换矩阵就是<code>相机外参</code>。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929114250.png"></p>
<p>这里的外参是SLAM中的待估计目标，代表着机器人的轨迹。</p>
<p>值得一提的是，这个过程中丢失了深度信息。</p>
<h3 id="5-1-2-畸变模型"><a href="#5-1-2-畸变模型" class="headerlink" title="5.1.2 畸变模型"></a>5.1.2 畸变模型</h3><p>径向畸变（失真）：透镜形状引起的畸变</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929114910.png"></p>
<p>切向畸变：透镜未和成像平面严格平行引起的畸变</p>
<p>畸变系数：k1, k2, k3, p1, p2（前3个为径向的，后2个为切向的）</p>
<p>畸变变换发生在<code>归一化成像平面[x,y]^T</code>到<code>像素平面[u,v]^T</code>的过程中：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929115410.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929115515.png"></p>
<ul>
<li>去畸变处理（畸变矫正）<ul>
<li>对整张图像去畸变，再用这个图像去对应空间位置</li>
<li>对图像上的每个像素点去畸变，对应其畸变前的空间点</li>
</ul>
</li>
</ul>
<p><strong>总的来说</strong>：</p>
<ul>
<li><code>世界坐标Pw</code> –+外参T–&gt;</li>
<li><code>相机坐标Pc</code> —&gt; </li>
<li><code>归一化坐标</code> –+畸变–+内参α,β,c,f–&gt; </li>
<li><code>像素坐标Puv</code></li>
</ul>
<h3 id="5-1-3-双目相机模型"><a href="#5-1-3-双目相机模型" class="headerlink" title="5.1.3 双目相机模型"></a>5.1.3 双目相机模型</h3><p>双目相机的原理是同步采集左右相机图像，计算图像<code>视差</code>，计算每个像素点的深度。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929120525.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929120549.png">，b为基线</p>
<p>计算量比较大，要用GPU或FPGA来实现实时计算。</p>
<h3 id="5-1-4-RGB-D-相机模型"><a href="#5-1-4-RGB-D-相机模型" class="headerlink" title="5.1.4 RGB-D 相机模型"></a>5.1.4 RGB-D 相机模型</h3><p>RGB-D相机原理：主动测量每个像素深度</p>
<ul>
<li>通过<code>红外结构光</code>原理测量 深度</li>
<li>通过<code>飞行时间</code>原理测量深度</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929121048.png"></p>
<p>主要问题是，发射-接收测量方式使得使用范围比较受限。</p>
<h2 id="5-2-图像"><a href="#5-2-图像" class="headerlink" title="5.2 图像"></a>5.2 图像</h2><p>计算机中图像存储为数值矩阵。</p>
<p>灰度图：每个像素位置对应一个灰度值I</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> image[<span class="number">480</span>][<span class="number">640</span>]   <span class="comment">//一张宽640像素，高480像素分辨率的灰度图</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> pixel = image[y][x]   <span class="comment">//访问图像像素，pixel=I(x,y)，注意下标</span></span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>深度图</li>
<li>彩色图：多通道<ul>
<li>opencv中通道顺序是B、G、R</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929121909.png"></p>
<h2 id="5-3-编程：计算机中的图像"><a href="#5-3-编程：计算机中的图像" class="headerlink" title="5.3 编程：计算机中的图像"></a>5.3 编程：计算机中的图像</h2><h3 id="5-3-1-opencv基本使用"><a href="#5-3-1-opencv基本使用" class="headerlink" title="5.3.1 opencv基本使用"></a>5.3.1 opencv基本使用</h3><p>opencv库：图像处理算法库</p>
<p>本书用的是opencv3</p>
<h3 id="5-3-2-图像去畸变"><a href="#5-3-2-图像去畸变" class="headerlink" title="5.3.2 图像去畸变"></a>5.3.2 图像去畸变</h3><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">cv::<span class="built_in">Undistort</span>() <span class="comment">//去畸变函数</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="5-4-编程：3D视觉"><a href="#5-4-编程：3D视觉" class="headerlink" title="5.4 编程：3D视觉"></a>5.4 编程：3D视觉</h2><h3 id="5-4-1-双目视觉"><a href="#5-4-1-双目视觉" class="headerlink" title="5.4.1 双目视觉"></a>5.4.1 双目视觉</h3><p>从双目视觉的左右图像出发，计算图像对应的视差图，然后将像素点转换回相机坐标，构成物体的点云。</p>
<p>SGBM算法：计算视差</p>
<h3 id="5-4-2-RGB-D视觉"><a href="#5-4-2-RGB-D视觉" class="headerlink" title="5.4.2 RGB-D视觉"></a>5.4.2 RGB-D视觉</h3><p>位姿记录形式：[x,y,z,qx,qy,qz,qw]—平移向量+旋转四元数</p>
<ol>
<li>根据内参计算一对RGB-D图像对应的点云</li>
<li>根据各张图的相机位姿，把点云加起来，组成地图</li>
</ol>
<hr>
<h1 id="第6将-非线性优化"><a href="#第6将-非线性优化" class="headerlink" title="第6将 非线性优化"></a>第6将 非线性优化</h1><h2 id="6-1-状态估计问题"><a href="#6-1-状态估计问题" class="headerlink" title="6.1 状态估计问题"></a>6.1 状态估计问题</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929164600.png"></p>
<p>根据第5讲的内容，观测方程可以写成：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929163749.png"></p>
<p>SLAM的目标是通过带噪声的观测数据z和输入u，来推断位姿x和地图y，这就是个状态估计问题。</p>
<p>两种方案：</p>
<ul>
<li>滤波器/增量方法<ul>
<li>在当前时刻的估计状态下，来一个新数据，更新一次状态</li>
<li>只关心当前的xk</li>
</ul>
</li>
<li>批量方法<ul>
<li>攒一波数据，然后一并处理</li>
<li>目前的主流</li>
<li>为了达到实时性，可以固定一些历史轨迹，仅对当前时刻附近的一些轨迹进行优化（滑动窗口估计）</li>
</ul>
</li>
</ul>
<h3 id="6-1-1-批量状态估计与最大后验估计"><a href="#6-1-1-批量状态估计与最大后验估计" class="headerlink" title="6.1.1 批量状态估计与最大后验估计"></a>6.1.1 批量状态估计与最大后验估计</h3><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929170517.png"></p>
<p>MAP估计：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929170545.png"></p>
<p>ML估计：在什么样的状态下(x,y)下，最可能产生当前观测到的数据</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929170719.png"></p>
<h3 id="6-1-2-最小二乘的引出"><a href="#6-1-2-最小二乘的引出" class="headerlink" title="6.1.2 最小二乘的引出"></a>6.1.2 最小二乘的引出</h3><p>先不考虑运动方程，且假设噪声是高斯分布。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929171226.png"></p>
<p>这个式子等同于在最小化噪声项，因此ML估计可以等价于最小化误差项(噪声)。</p>
<ul>
<li>上式的Q逆是信息矩阵</li>
<li>噪声项是一个二次型，称为马氏距离。</li>
</ul>
<hr>
<p>现在假设运动方程，考虑批量数据。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929171708.png">（因为独立）</p>
<p>上式的ML估计等同于最小化所有时刻的误差项：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929171832.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929171855.png"></p>
<p>这就是一个<strong>最小二乘问题</strong>了。</p>
<h3 id="6-1-3-例子：批量状态估计"><a href="#6-1-3-例子：批量状态估计" class="headerlink" title="6.1.3 例子：批量状态估计"></a>6.1.3 例子：批量状态估计</h3><p>略</p>
<h2 id="6-2-非线性最小二乘"><a href="#6-2-非线性最小二乘" class="headerlink" title="6.2 非线性最小二乘"></a>6.2 非线性最小二乘</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929173626.png"></p>
<p>这是一个比较正常的最小二乘的样子，一般用<code>梯度下降</code>来解</p>
<p>具体步骤：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174103.png"></p>
<h3 id="6-2-1-一阶和二阶梯度法"><a href="#6-2-1-一阶和二阶梯度法" class="headerlink" title="6.2.1 一阶和二阶梯度法"></a>6.2.1 一阶和二阶梯度法</h3><p>J：一阶导数，梯度、雅克比矩阵</p>
<p>H：二阶导数，海塞矩阵</p>
<ul>
<li><p>一阶梯度：最速下降法（并不是最小二乘）</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174156.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174253.png"></p>
</li>
<li><p>二阶梯度：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174411.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174516.png"></p>
</li>
<li><p>缺点：</p>
<ul>
<li>最速过于贪心</li>
<li>二阶里的H过于难算</li>
</ul>
</li>
</ul>
<h3 id="6-2-2-高斯牛顿法"><a href="#6-2-2-高斯牛顿法" class="headerlink" title="6.2.2 高斯牛顿法"></a>6.2.2 高斯牛顿法</h3><p>对误差：f(x)，而不是目标函数：F(x)，做一阶泰勒展开：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174805.png"></p>
<p>构建最小二乘问题：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929174937.png"></p>
<p>得到<code>增量方程（高斯牛顿方程）</code>：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929175144.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929175209.png"></p>
<p>可以看到，高斯牛顿法用JJ^T来做H的近似，避免了H的复杂计算。</p>
<ul>
<li><p>算法步骤：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929175400.png"></p>
</li>
<li><p>算法缺点：</p>
<ul>
<li>JJ^T不一定可逆，可能会导致无法收敛</li>
</ul>
</li>
<li><p>补救措施：</p>
<ul>
<li>线搜索法：加上步长，即先找到方向，再确定长度。</li>
<li>阻尼牛顿：引入信赖区域，认为近似只在区域内可靠</li>
</ul>
</li>
</ul>
<h3 id="6-2-3-列文伯格-马夸尔特方法"><a href="#6-2-3-列文伯格-马夸尔特方法" class="headerlink" title="6.2.3 列文伯格-马夸尔特方法"></a>6.2.3 列文伯格-马夸尔特方法</h3><p>又名阻尼牛顿法。</p>
<p>根据近似模型下降的值 如果能近似等于 函数实际下降的值，说明这个近似很nice，可以扩大近似的范围。（下式接近1）</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929181536.png"></p>
<p>算法步骤：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929181856.png"></p>
<p>拉格朗日乘子来解，最后推导到求解：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929183816.png"></p>
<p>值得注意的是，上面的非线性优化都需要提供初始值，SLAM中，通常使用ICP、PnP等算法来提供初始值x0。</p>
<h2 id="6-3-编程：曲线拟合问题"><a href="#6-3-编程：曲线拟合问题" class="headerlink" title="6.3 编程：曲线拟合问题"></a>6.3 编程：曲线拟合问题</h2><h3 id="6-3-1-手写高斯牛顿算法"><a href="#6-3-1-手写高斯牛顿算法" class="headerlink" title="6.3.1 手写高斯牛顿算法"></a>6.3.1 手写高斯牛顿算法</h3><h3 id="6-3-2-使用Ceres进行曲线拟合"><a href="#6-3-2-使用Ceres进行曲线拟合" class="headerlink" title="6.3.2 使用Ceres进行曲线拟合"></a>6.3.2 使用Ceres进行曲线拟合</h3><p>Cere库：最小二乘问题求解库</p>
<p>Ceres求解的最小二乘问题的一般形式（带边界的核函数最小二乘）：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929185010.png"></p>
<h4 id="图优化理论"><a href="#图优化理论" class="headerlink" title="图优化理论"></a>图优化理论</h4><p>G2o库：图优化库，SLAM领域广泛使用。</p>
<p>图优化是一种将非线性优化和图论结合起来的理论，将优化问题用图（贝叶斯图）的形式呈现。</p>
<p>图：顶点+边</p>
<ul>
<li>顶点：表示优化变量</li>
<li>边：表示误差项</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929191415.png"></p>
<ul>
<li>使用g2o拟合曲线</li>
</ul>
<p>需要先将问题转化为图优化问题。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210929191653.png"></p>
<p>曲线拟合问题中只有一个优化变量，而带噪声的数据构成了诸多误差项。</p>
<p>步骤：</p>
<ol>
<li>定义顶点和边的类型</li>
<li>构件图</li>
<li>选择优化算法</li>
<li>调用g2o进行优化，返回结果</li>
</ol>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>VSCode+Clang+MinGW+OpenGl配置教程</title>
    <url>/VSCode-Clang-MinGW-OpenGl%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这几天帮别人跑一个天空盒代码，需要用到OpenGl环境，配置过程掉坑比较多略为艰难，因此写个教程记录一下，免得以后换电脑配环境的时候又掉坑233。</p>
<p>顺便吐槽一下，这位仁兄电脑是联想核显，据说因为木有GPU，跑不了OpenGl程序，多好的反面教材<span class="github-emoji"><span>😄</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>~ 这里提醒诸君，搞计算机视觉的话，电脑还是独显比较好。</p>
<p>其实很久以前笔者在CodeBlocks上配置过OpenGl环境，当时用的是袁学长提供的傻瓜教程，私以为so easy……In fact，光是环境配置就要了老命，果然配置教程这种东西要及时记录！</p>
<p><strong>掉坑的核心：64位和32位一定要区分清楚，所有配置必须all32或all64，否则程序会出现<code>skipping imcompatible</code>的问题。</strong></p>
<p><strong>——以下配置都是64bit！</strong></p>
<p>老规矩，附上参考链接，向前辈致敬：</p>
<table>
<thead>
<tr>
<th>链接</th>
</tr>
</thead>
<tbody><tr>
<td>1. <a href="https://zhuanlan.zhihu.com/p/87864677">VSCode配置C/C++环境</a></td>
</tr>
<tr>
<td>2. <a href="https://anyway521.github.io/post/fb46ea0d.html">VSCode配置C/C++环境完整版(附OpenGL配置)</a></td>
</tr>
<tr>
<td>3. <a href="https://blog.csdn.net/qq_41523096/article/details/104628484">20秒 一键配置 VSCode (Visual Studio Code) C/C++开发环境</a></td>
</tr>
<tr>
<td>4. <a href="https://my.oschina.net/u/4277479/blog/3525117">VS Code + MinGW + Clang + OpenGL (vscode 配置 opengl环境)</a></td>
</tr>
</tbody></table>
<h1 id="VSCode配置C-C-环境"><a href="#VSCode配置C-C-环境" class="headerlink" title="VSCode配置C/C++环境"></a>VSCode配置C/C++环境</h1><p>首先，如果你只需要一个在VSCode上的C/C++环境，其他类似OpenGL、OpenCV等等都不需求，那么强烈推荐<a href="https://blog.csdn.net/qq_41523096/article/details/104628484">C参考链接3</a>，全自动傻瓜配置，非常nice。</p>
<p>另外，如果你还没有装VSCode或者想要卸载，推荐<a href="https://zhuanlan.zhihu.com/p/87864677">参考链接1</a>，里面有VSCode的安装教程，在此就不累述了。</p>
<p>那么，正文开始。</p>
<h2 id="1-安装Clang"><a href="#1-安装Clang" class="headerlink" title="1. 安装Clang"></a>1. 安装Clang</h2><p>根据维基百科的定义，Clang是一个编译器前端，采用LLVM（一款用来开发编译器前后端的软件）作为其后端。Clang作为GNU编译器套装（<code>GCC</code>）的替代品，支持GNU编译器的大多数编译设定。Clang支持C、C++、Objective-C和Objective-C++。简单来说，我们安装LLVM等同于安装配置Clang。</p>
<ul>
<li>下载地址：<a href="https://releases.llvm.org/download.html">LLVM</a></li>
</ul>
<p>以LLVM 11.1.0为例：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210427120902.png"><br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210427121320.png"></p>
<p>笔者的安装位置：<code>D:\Programfiles\LLVM</code>，安装过程中注意勾选：<code>添加环境变量</code></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210427121625.png"></p>
<h2 id="2-安装MinGM-W64"><a href="#2-安装MinGM-W64" class="headerlink" title="2. 安装MinGM-W64"></a>2. 安装MinGM-W64</h2><p>首先我们需要大概了解一下MinGM是个啥。前述的Clang作为GCC的替代品，和GCC一样也是主要用在Unix系统下的，我们想在Windows系统中使用Clang，便需要借助MinGM (Minimalist GNU for Windows)的力量。</p>
<p>MinGM简单来讲，就是Window上的GNU开发平台，等于说有了MinGM你不用装linux也可以在Windows上玩GNU。</p>
<ul>
<li>版本说明：<ul>
<li><p>MinGM（mingm32）—32位；</p>
</li>
<li><p>MinGM-w64—32+64位【我用的是这个】</p>
<p>下载地址：<a href="https://sourceforge.net/projects/mingw-w64/files/">MinGW-w64 - for 32 and 64 bit Window</a></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428111555.png"></p>
</li>
</ul>
</li>
<li><strong>注意：</strong> MinGW是在线安装，但是由于某种不可抗力，安装过程缓慢到不能忍受，因此我最后用的是离线安装的方法。</li>
</ul>
<h3 id="离线安装方法"><a href="#离线安装方法" class="headerlink" title="离线安装方法"></a>离线安装方法</h3><ol>
<li><p>下载X86_64-win32-seh：<br>下载地址：<a href="https://sourceforge.net/projects/mingw-w64/files/">MinGW-w64 - for 32 and 64 bit Windows</a></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428111823.png"></p>
</li>
<li><p>解压、合并文件：将解压后<code>mingw64</code>文件夹中的所有文件直接复制到之前的LLVM安装目录<code>D:\Programfiles\LLVM</code>，系统会自动整合同名文件夹中的文件。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428112733.png"></p>
</li>
<li><p>输入<code>clang -v</code>和<code>gcc -v</code>进行测试，出现版本号则安装成功。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428130609.png"></p>
<p>当前系统的环境变量为：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428131225.png"></p>
</li>
</ol>
<h2 id="3-安装VSCode插件"><a href="#3-安装VSCode插件" class="headerlink" title="3. 安装VSCode插件"></a>3. 安装VSCode插件</h2><p>在VSCode左侧的<code>扩展</code>中搜索安装以下插件：</p>
<p><em>ps，在此之前，建议通过重定向将插件储存位置从C盘改出来:<br><code>"D:\Program Files (x86)\Microsoft VS Code\Code.exe" --extensions-dir "D:\Program Files (x86)\Microsoft VS Code\extensions"</code></em></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428132711.png"></p>
<ul>
<li><p>插件1：C/C++</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428132109.png"></p>
</li>
<li><p>插件2：C/C++ Clang Command Adapter</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428132325.png"></p>
</li>
<li><p>插件3：Code Runner</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210428132842.png"></p>
</li>
</ul>
<h1 id="VSCode配置Gult环境"><a href="#VSCode配置Gult环境" class="headerlink" title="VSCode配置Gult环境"></a>VSCode配置Gult环境</h1><p>Gult是OpenGl需要的相关依赖，包括<code>glut.h</code>，<code>glut32.lib</code>，<code>glut32.dll</code>文件。</p>
<p>值得注意的是，由于之前的C++环境是64位的，gult版本必须与之对应，即64位。</p>
<ol>
<li><p>下载<code>glut.h</code>，<code>glut32.lib</code>，<code>glut32.dll</code>：</p>
<p>下载地址：<a href="https://pan.baidu.com/s/1PN_0SxxKGJ-D_AZRDa4LDA">https://pan.baidu.com/s/1PN_0SxxKGJ-D_AZRDa4LDA</a> 提取码：sf1z </p>
</li>
<li><p>将gult文件放到相应目录下（LLVM安装路径）：</p>
</li>
</ol>
<ul>
<li><code>gult.h</code>放到目录：<code>D:\Programfiles\LLVM\include</code></li>
<li><code>gult32.dll</code>放到目录：<code>D:\Programfiles\LLVM\bin</code></li>
<li><code>gult32.lib</code>放到目录：<code>D:\Programfiles\LLVM\lib</code></li>
</ul>
<h1 id="VSCode配置文件"><a href="#VSCode配置文件" class="headerlink" title="VSCode配置文件"></a>VSCode配置文件</h1><p>在文件夹里新建<code>.vscode</code>，<code>include</code>和<code>lib</code>文件夹，<code>include</code>和<code>lib</code>现在先不用管，先专注<code>.vscode</code>文件夹，做VSCode下C/C++环境的基本配置。</p>
<p>在<code>.vscode</code>文件夹里新建<code>c_cpp_properties.json</code>，<code>launch.json</code>，<code>settings.json</code>以及<code>tasks.json</code>。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210430102555.png"></p>
<h2 id="1-配置编译器：c-cpp-properties-json"><a href="#1-配置编译器：c-cpp-properties-json" class="headerlink" title="1. 配置编译器：c_cpp_properties.json"></a>1. 配置编译器：c_cpp_properties.json</h2><p>首先配置编译器路径。</p>
<h3 id="方法-1："><a href="#方法-1：" class="headerlink" title="方法 1："></a>方法 1：</h3><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">    <span class="string">"configurations"</span>: [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"MinGW"</span>,</span><br><span class="line">            <span class="string">"intelliSenseMode"</span>: <span class="string">"clang-x64"</span>,</span><br><span class="line">            <span class="string">"compilerPath"</span>: <span class="string">"D:/Programfiles/LLVM/bin/g++.exe"</span>, <span class="comment">//之前安装的编译器的路径</span></span><br><span class="line">            <span class="string">"includePath"</span>: [</span><br><span class="line">                <span class="string">"${workspaceFolder}/**"</span>,</span><br><span class="line">                <span class="string">"${workspaceFolder}/include/*"</span>, <span class="comment">//当前文件夹下的include</span></span><br><span class="line">                <span class="string">"D:/Programfiles/LLVM/include/*"</span>, <span class="comment">//LLVM的include</span></span><br><span class="line">                <span class="string">"D:/Programfiles/LLVM/lib/gcc/x86_64-w64-mingw32/8.1.0/include/*"</span> <span class="comment">//mingw的include</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="string">"defines"</span>: [],</span><br><span class="line">            <span class="string">"browse"</span>: {</span><br><span class="line">                <span class="string">"path"</span>: [</span><br><span class="line">                    <span class="string">"${workspaceFolder}"</span></span><br><span class="line">                ],</span><br><span class="line">                <span class="string">"limitSymbolsToIncludedHeaders"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="string">"databaseFilename"</span>: <span class="string">""</span></span><br><span class="line">            },</span><br><span class="line">            <span class="string">"cStandard"</span>: <span class="string">"c11"</span>,</span><br><span class="line">            <span class="string">"cppStandard"</span>: <span class="string">"c++17"</span></span><br><span class="line">        }</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"version"</span>: <span class="number">4</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="方法-2："><a href="#方法-2：" class="headerlink" title="方法 2："></a>方法 2：</h3><p><a href="https://zhuanlan.zhihu.com/p/87864677">参考链接1</a>中<code>配置编译器</code>部分给出了另一种图形化的配置方式。</p>
<p>简单来说就是不需要手动新建<code>.vscode</code>文件夹和<code>c_cpp_properties.json</code>文件，直接用<code>Ctrl+Shift+P</code>调出控制面板，输入<code>C/C++</code>选择<code>Edit Configurations(UI)</code>进入配置。</p>
<ul>
<li><p>修改编译器路径：D:/Programfiles/LLVM/bin/g++.exe</p>
</li>
<li><p>修改intelliSense：clang-x64</p>
</li>
</ul>
<p>配置完成后，自动新建了<code>.vscode</code>文件夹和<code>c_cpp_properties.json</code>文件，再在<code>c_cpp_properties</code>文件中修改include路径即可。</p>
<h2 id="2-配置构建任务tasks-json"><a href="#2-配置构建任务tasks-json" class="headerlink" title="2. 配置构建任务tasks.json"></a>2. 配置构建任务tasks.json</h2><p><code>tasks.json</code>可以告诉VSCode如何编译程序。</p>
<h3 id="方法-1：-1"><a href="#方法-1：-1" class="headerlink" title="方法 1："></a>方法 1：</h3><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">{</span><br><span class="line">    <span class="string">"version"</span>: <span class="string">"2.0.0"</span>,</span><br><span class="line">    <span class="string">"tasks"</span>: [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"label"</span>: <span class="string">"Compile"</span>, <span class="comment">// 任务名称，与launch.json的preLaunchTask相对应</span></span><br><span class="line">            <span class="string">"command"</span>: <span class="string">"clang++"</span>,</span><br><span class="line">            <span class="string">"args"</span>: [ <span class="comment">//编译时的参数</span></span><br><span class="line">                <span class="string">"${file}"</span>,</span><br><span class="line">                <span class="string">"-o"</span>, <span class="comment">//指定输出文件名</span></span><br><span class="line">                <span class="string">"${fileDirname}/${fileBasenameNoExtension}.exe"</span>,</span><br><span class="line">                <span class="string">"-g"</span>, <span class="comment">//添加gdb调试选项</span></span><br><span class="line">                <span class="string">"-Wall"</span>,  <span class="comment">//开启额外警告</span></span><br><span class="line">                <span class="string">"-static-libgcc"</span>, <span class="comment">//静态链接libgcc</span></span><br><span class="line">                <span class="string">"--target=x86_64-w64-mingw"</span>,  <span class="comment">//clang编译器需要加上这条，因为它默认的target是msvc；如果用gcc或者linux要注释掉</span></span><br><span class="line">                <span class="string">"-std=c++17"</span>,</span><br><span class="line">                <span class="string">"-I${workspaceFolder}/include"</span>, <span class="comment">//添加工作路径下的include</span></span><br><span class="line">                <span class="string">"-L${workspaceFolder}/lib"</span>, <span class="comment">//添加工作路径下的lib</span></span><br><span class="line">                <span class="string">"-lglut32"</span>, <span class="comment">//使用glut</span></span><br><span class="line">                <span class="string">"-lglu32"</span>,  <span class="comment">//使用glut</span></span><br><span class="line">                <span class="string">"-lopengl32"</span>, <span class="comment">//使用opengl</span></span><br><span class="line">                <span class="string">"-lglad"</span>, <span class="comment">//使用glad+glfw，这里可以先注释掉</span></span><br><span class="line">                <span class="string">"-lglfw3"</span>,  <span class="comment">//使用glad+glfw，这里可以先注释掉 </span></span><br><span class="line">                <span class="string">"-lglfw3dll"</span>, <span class="comment">//使用glad+glfw，这里可以先注释掉</span></span><br><span class="line">                <span class="string">"-lgdi32"</span>,  <span class="comment">//使用glad+glfw，这里可以先注释掉</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="string">"group"</span>: {</span><br><span class="line">                <span class="string">"kind"</span>: <span class="string">"build"</span>,</span><br><span class="line">                <span class="string">"isDefault"</span>: <span class="literal">true</span> <span class="comment">//表示快捷键Ctrl+Shift+B可以运行该任务</span></span><br><span class="line">            },</span><br><span class="line">            <span class="string">"presentation"</span>: {</span><br><span class="line">                <span class="string">"echo"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="string">"reveal"</span>: <span class="string">"always"</span>, <span class="comment">// 执行任务时是否跳转到终端面板</span></span><br><span class="line">                <span class="string">"focus"</span>: <span class="literal">false</span>,</span><br><span class="line">                <span class="string">"panel"</span>: <span class="string">"shared"</span> <span class="comment">// 不同的文件的编译信息共享一个终端面板</span></span><br><span class="line">            },</span><br><span class="line">            <span class="string">"problemMatcher"</span>: []</span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h3 id="方法-2：-1"><a href="#方法-2：-1" class="headerlink" title="方法 2："></a>方法 2：</h3><p><a href="https://zhuanlan.zhihu.com/p/87864677">参考链接1</a>中<code>配置构建任务</code>部分给出了另一种图形化的配置方式。</p>
<p>不需要手动新建<code>tasks.json</code>文件，直接用<code>Ctrl+Shift+P</code>调出控制面板，输入<code>tasks</code>选择<code>Tasks:Configure Default Build Task</code>，自动生成tasks.json文件，主要修改其中的<code>"args"</code>参数部分。</p>
<h2 id="配置调试设置launch-json"><a href="#配置调试设置launch-json" class="headerlink" title="配置调试设置launch.json"></a>配置调试设置launch.json</h2><p><code>launch.json</code>用来配置调试的相关信息。</p>
<h3 id="方法-1：-2"><a href="#方法-1：-2" class="headerlink" title="方法 1："></a>方法 1：</h3><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">    <span class="string">"version"</span>: <span class="string">"0.2.0"</span>,</span><br><span class="line">    <span class="string">"configurations"</span>: [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"(gdb) Launch"</span>, <span class="comment">// 配置名称，将会在启动配置的下拉菜单中显示</span></span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"cppdbg"</span>, <span class="comment">// 配置类型，cppdbg对应cpptools提供的调试功能；可以认为此处只能是cppdbg</span></span><br><span class="line">            <span class="string">"request"</span>: <span class="string">"launch"</span>, <span class="comment">// 请求配置类型，可以为launch（启动）或attach（附加）</span></span><br><span class="line">            <span class="string">"program"</span>: <span class="string">"${fileDirname}/${fileBasenameNoExtension}.exe"</span>, <span class="comment">// 将要进行调试的程序的路径</span></span><br><span class="line">            <span class="string">"args"</span>: [], <span class="comment">// 程序调试时传递给程序的命令行参数，一般设为空即可</span></span><br><span class="line">            <span class="string">"stopAtEntry"</span>: <span class="literal">false</span>, <span class="comment">// 设为true时程序将暂停在程序入口处，相当于在main上打断点</span></span><br><span class="line">            <span class="string">"cwd"</span>: <span class="string">"${workspaceFolder}"</span>, <span class="comment">// 调试程序时的工作目录，此为工作区文件夹；改成${fileDirname}可变为文件所在目录</span></span><br><span class="line">            <span class="string">"environment"</span>: [], <span class="comment">// 环境变量</span></span><br><span class="line">            <span class="string">"externalConsole"</span>: <span class="literal">false</span>, <span class="comment">// 为true时使用单独的cmd窗口，与其它IDE一致；18年10月后设为false可调用VSC内置终端</span></span><br><span class="line">            <span class="string">"internalConsoleOptions"</span>: <span class="string">"neverOpen"</span>, <span class="comment">// 如果不设为neverOpen，调试时会跳到“调试控制台”选项卡，你应该不需要对gdb手动输命令吧？</span></span><br><span class="line">            <span class="string">"MIMode"</span>: <span class="string">"gdb"</span>, <span class="comment">// 指定连接的调试器，可以为gdb或lldb。但我没试过lldb</span></span><br><span class="line">            <span class="string">"miDebuggerPath"</span>: <span class="string">"gdb.exe"</span>, <span class="comment">// 调试器路径，Windows下后缀不能省略，Linux下则不要</span></span><br><span class="line">            <span class="string">"setupCommands"</span>: [</span><br><span class="line">                { <span class="comment">// 模板自带，好像可以更好地显示STL容器的内容，具体作用自行Google</span></span><br><span class="line">                    <span class="string">"description"</span>: <span class="string">"Enable pretty-printing for gdb"</span>,</span><br><span class="line">                    <span class="string">"text"</span>: <span class="string">"-enable-pretty-printing"</span>,</span><br><span class="line">                    <span class="string">"ignoreFailures"</span>: <span class="literal">false</span></span><br><span class="line">                }</span><br><span class="line">            ],</span><br><span class="line">            <span class="string">"preLaunchTask"</span>: <span class="string">"Compile"</span> <span class="comment">// 调试会话开始前执行的任务，一般为编译程序。与tasks.json的label相对应</span></span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h3 id="方法-2：-2"><a href="#方法-2：-2" class="headerlink" title="方法 2："></a>方法 2：</h3><p>菜单栏<code>运行</code>-<code>启动调试</code>-<code>C++(GDB/LLDB)</code>，自动生成一个<code>launch.json</code>文件，再根据需要修改相关配置。</p>
<p>ps，不推荐该方法，原博主也遇到了没解决的问题，笔者也没深究，还是建议方法1。</p>
<h2 id="配置用户设置settings-json"><a href="#配置用户设置settings-json" class="headerlink" title="配置用户设置settings.json"></a>配置用户设置settings.json</h2><figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">  <span class="string">"files.defaultLanguage"</span>: <span class="string">"cpp"</span>, <span class="comment">// ctrl+N新建文件后默认的语言</span></span><br><span class="line">  <span class="string">"editor.formatOnType"</span>: <span class="literal">true</span>, <span class="comment">// 输入时就进行格式化，默认触发字符较少，分号可以触发</span></span><br><span class="line">  <span class="string">"editor.snippetSuggestions"</span>: <span class="string">"top"</span>, <span class="comment">// snippets代码优先显示补全</span></span><br><span class="line">  <span class="string">"code-runner.runInTerminal"</span>: <span class="literal">true</span>, <span class="comment">// 设置成false会在“输出”中输出，无法输入</span></span><br><span class="line">  <span class="string">"code-runner.executorMap"</span>: {</span><br><span class="line">      <span class="string">"c"</span>: <span class="string">"cd $dir &amp;&amp; clang $fileName -o $fileNameWithoutExt.exe -Wall -g -Og -static-libgcc -fcolor-diagnostics --target=x86_64-w64-mingw -std=c11 &amp;&amp; $dir$fileNameWithoutExt"</span>,</span><br><span class="line">      <span class="string">"cpp"</span>: <span class="string">"cd $dir &amp;&amp; clang++ $fileName -o $fileNameWithoutExt.exe -Wall -g -Og -static-libgcc -fcolor-diagnostics --target=x86_64-w64-mingw -lglut32 -lglu32 -lopengl32 -std=c++17 &amp;&amp; $dir$fileNameWithoutExt"</span> </span><br><span class="line">  }, <span class="comment">// 设置code runner的命令行</span></span><br><span class="line">  <span class="string">"code-runner.saveFileBeforeRun"</span>: <span class="literal">true</span>, <span class="comment">// run code前保存</span></span><br><span class="line">  <span class="string">"code-runner.preserveFocus"</span>: <span class="literal">true</span>, <span class="comment">// 若为false，run code后光标会聚焦到终端上。如果需要频繁输入数据可设为false</span></span><br><span class="line">  <span class="string">"code-runner.clearPreviousOutput"</span>: <span class="literal">false</span>, <span class="comment">// 每次run code前清空属于code runner的终端消息</span></span><br><span class="line"></span><br><span class="line">  <span class="string">"C_Cpp.clang_format_sortIncludes"</span>: <span class="literal">true</span>, <span class="comment">// 格式化时调整include的顺序（按字母排序）</span></span><br><span class="line">  <span class="string">"C_Cpp.intelliSenseEngine"</span>: <span class="string">"Default"</span>, <span class="comment">// 可以为Default或Tag Parser，后者较老，功能较简单。具体差别参考cpptools扩展文档</span></span><br><span class="line">  <span class="string">"C_Cpp.errorSquiggles"</span>: <span class="string">"Disabled"</span>, <span class="comment">// 因为有clang的lint，所以关掉</span></span><br><span class="line">  <span class="string">"C_Cpp.autocomplete"</span>: <span class="string">"Disabled"</span>, <span class="comment">// 因为有clang的补全，所以关掉</span></span><br><span class="line"></span><br><span class="line">  <span class="string">"clang.cflags"</span>: [ <span class="comment">// 控制c语言静态检测的参数</span></span><br><span class="line">      <span class="string">"--target=x86_64-w64-mingw"</span>,</span><br><span class="line">      <span class="string">"-std=c11"</span>,</span><br><span class="line">      <span class="string">"-Wall"</span>,</span><br><span class="line">      <span class="string">"-I./include"</span>,</span><br><span class="line">      <span class="string">"-L./lib"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"clang.cxxflags"</span>: [ <span class="comment">// 控制c++静态检测时的参数</span></span><br><span class="line">      <span class="string">"--target=x86_64-w64-mingw"</span>,</span><br><span class="line">      <span class="string">"-std=c++17"</span>,</span><br><span class="line">      <span class="string">"-Wall"</span>,</span><br><span class="line">      <span class="string">"-I./include"</span>,</span><br><span class="line">      <span class="string">"-L./lib"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"clang.completion.enable"</span>:<span class="literal">true</span>, <span class="comment">// 效果效果比cpptools要好</span></span><br><span class="line">  <span class="string">"clang.diagnostic.delay"</span>:<span class="number">300</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<p><strong>值得注意的是</strong>，之前我run code一直报错找不到一些glut函数定义，只有debug能跑。后来发现问题出在<code>code-runner.executorMap</code>这里。</p>
<p>之前<code>tasks.json</code>中调试参数部分为：<br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210430124111.png"></p>
<p>而<code>settings.json</code>的<code>code-runner.executorMap</code>部分需要与之对应：<br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210430124608.png"></p>
<p>加上红框部分就能run code了。</p>
<h2 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h2><p>至此VSCode配置结束，之后跑新的C++项目只需要将<code>.vscode</code>文件夹复制过去就行，如果要用到其他库，只需要对其中一些参数稍作修改。</p>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>最后，我们建个main.cpp来测试一下：</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;glut.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span>{</span><br><span class="line">    <span class="built_in">glutInit</span>(&amp;argc, argv);</span><br><span class="line">    <span class="built_in">glutInitDisplayMode</span>(GLUT_RGB | GLUT_SINGLE);</span><br><span class="line">    <span class="built_in">glutInitWindowPosition</span>(<span class="number">800</span>, <span class="number">150</span>);</span><br><span class="line">    <span class="built_in">glutInitWindowSize</span>(<span class="number">600</span>, <span class="number">400</span>);</span><br><span class="line">    <span class="built_in">glutCreateWindow</span>(<span class="string">"OpenGL 3D View"</span>);</span><br><span class="line">    <span class="built_in">init</span>();</span><br><span class="line">    <span class="built_in">glutDisplayFunc</span>(display);</span><br><span class="line">    <span class="built_in">glutMainLoop</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="built_in">glClearColor</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_PROJECTION);</span><br><span class="line">    <span class="built_in">glOrtho</span>(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">-5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">15</span>);</span><br><span class="line">    <span class="built_in">glMatrixMode</span>(GL_MODELVIEW);</span><br><span class="line">    <span class="built_in">gluLookAt</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>{</span><br><span class="line">    <span class="built_in">glClear</span>(GL_COLOR_BUFFER_BIT);</span><br><span class="line">    <span class="built_in">glColor3f</span>(<span class="number">0</span>, <span class="number">1.0</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">glutWireTeapot</span>(<span class="number">3</span>);</span><br><span class="line">    <span class="built_in">glFlush</span>();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>run code：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210430121933.png"></p>
<p>大功告成！<span class="github-emoji"><span>☀</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2600.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>🐱</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f431.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>~</p>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>emm，没啥好说的啦，干的不错喵喵喵~</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>OpenGl</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title>论文收集</title>
    <url>/%E8%AE%BA%E6%96%87%E6%94%B6%E9%9B%86/</url>
    <content><![CDATA[<h1 id="一、智慧交通"><a href="#一、智慧交通" class="headerlink" title="一、智慧交通"></a>一、智慧交通</h1><h2 id="1-1"><a href="#1-1" class="headerlink" title="1-1"></a>1-1</h2><p>   Real-Time Adaptive Traffic Control System For Smart Cities <a href="https://ieeexplore.ieee.org/document/9402597">智慧城市实时自适应交通控制系统</a></p>
<ul>
<li><strong>作者</strong>：Shyam Shankaran R; Logesh Rajendran</li>
<li><strong>会议</strong>: 2021 International Conference on Computer Communication and Informatics (ICCCI)</li>
<li><strong>引用</strong>：0，浏览24</li>
<li><strong>摘要</strong>：In-country like India, billions of people start and end each working day stuck in traffic or commuting on congested trains and buses. It is vital to the quality of life to enhance the everyday commute. By 2025, cities that implement smart mobility systems on average, reduce commuting cycles by 15-20 percent, with some individuals experiencing even greater reductions. Depending on each city’s density, current transit facilities, and commuting habits, the capacity associated with each application is highly variable. Slowed synchronization of traffic signals leads to traffic congestion and delays. The pre-programmed, regular signal timing patterns are employed in traditional signal systems. To overcome the problems of traditional traffic control systems, there is a shift in adaption to an Adaptive traffic control system. The Adaptive Traffic Control System (ATCS) is a traffic management technique that modifies or adapts the timing of traffic signals based on the real demand for traffic and achieved using a control system that includes both hardware and software, where hardware is the sensor used for real-time traffic density estimation and software is designed using captured data analysis of the city’s current traffic flow. This paper depicts a model of camera-based traffic monitoring and processing system which reduces the cycle time and possesses special provisions for emergency vehicles.</li>
<li><strong>点评</strong>：使用opencv，光学传感器，偏向图像识别。</li>
</ul>
<h2 id="1-2"><a href="#1-2" class="headerlink" title="1-2"></a>1-2</h2><p>   Big Traffic Data Analytics For Smart Urban Intelligent Traffic System Using Machine Learning Techniques <a href="https://ieeexplore.ieee.org/document/9291790">使用机器学习技术的智慧城市智能交通系统大交通数据分析</a></p>
<ul>
<li><strong>作者</strong>：Su Su Hlaing; Mie Mie Tin; Mie Mie Khin</li>
<li><strong>会议</strong>：2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)</li>
<li><strong>引用</strong>：1，浏览138</li>
<li><strong>摘要</strong>：Due to huge number of private and public vehicles in last two decades, the traffic load and congestion have increased significantly, which is major problem in transportation system. An intelligent traffic management system becomes an important part of the transportation system to manage the traffic properly in smart cities. In this paper, we have proposed intelligent traffic management system to build smart platform in Mandalay, Myanmar. The main aim of the paper is to reduce traffic congestion, road crash accidents, fuel consumption and save travel time. To provide safe, comfortable, and less frustrating travel, this paper uses big data technology and machine learning technique for analysis of the volume of traffic data and predicts optimal road traffic using machine learning.</li>
<li><strong>点评</strong>：论文很短，比起具体方法更像是框架构想。</li>
</ul>
<h2 id="1-3"><a href="#1-3" class="headerlink" title="1-3"></a>1-3</h2><p>   Internet of things — smart traffic management system for smart cities using big data analytics <a href="https://ieeexplore.ieee.org/document/8301496">物联网——使用大数据分析的智慧城市智能交通管理系统</a></p>
<ul>
<li><strong>作者</strong>：Abida Sharif; Jianping Li; Mudassir Khalil</li>
<li><strong>会议</strong>：2017 14th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)</li>
<li><strong>引用</strong>：10，浏览2600</li>
<li><strong>摘要</strong>：Smart Traffic System (STS) is a one of the important aspect for future smart city. STS is more expensive and highly configurable to provide better quality of service for public traffic management. This paper proposes a low cost future STS to provide better service by deploying traffic update instantly. Low cost vehicle detecting sensors are fixed in the middle of road for every 500 meters. Internet of Things (IoT) is being used to attain public traffic data quickly and send it for data processing. The Real time streaming data is sent for Big Data analytics. There are several analytical scriptures to analyze the traffic density and provide solution through predictive analytics.</li>
<li><strong>点评</strong>：比较宏观，缺少细节</li>
</ul>
<h2 id="1-4"><a href="#1-4" class="headerlink" title="1-4"></a>1-4</h2><p>   Towards An Optimized Smart Traffic for Congestion Avoidance with Multi Layered (ST-CA) Framework<br>   <a href="https://ieeexplore.ieee.org/document/8538401">使用多层 (ST-CA) 框架实现优化的智能交通拥塞避免</a></p>
<ul>
<li><strong>作者</strong>：Nada M. Alhakkak; Ban Salman; Najeeb Abbas Al-Sammarraie</li>
<li><strong>会议</strong>：2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE)</li>
<li><strong>引用</strong>：1，浏览127</li>
<li><strong>摘要</strong>：In many cities around the world, traffic congestion is considered a major problem that should be managed properly. Managing traffic flow is not simply applied by constructing new road or maintaining old ones; it is not just a matter of physical infrastructure. For managing traffic, there should be ‘’smart’’ ways to be taken by the use of available technologies’ facilities. Countries should think and act smart to manage today’s traffic in their cities. The use of controlled smart traffic systems is gaining a noticeable interest for the past few years and various solutions have been proposed, adopted and even implemented in several countries. In this paper, we propose Smart Traffic for Congestion Avoidance with Multi Layered (ST-CA) Framework, for solving the congestion problem. The proposed framework is constructed in multilayer approach for easy maintenance in the future. The STCA framework should be more flexible, in sending/ receiving messages, than others and depend in its decision making on expert systems.</li>
<li><strong>点评</strong>：交通控制框架，信号灯算法，针对交通堵塞</li>
</ul>
<h2 id="1-5"><a href="#1-5" class="headerlink" title="1-5"></a>1-5</h2><p>   Foundations for Smarter Cities <a href="https://ieeexplore.ieee.org/document/5512826">智慧城市的基础</a></p>
<ul>
<li><strong>作者</strong>：C. Harrison; B. Eckman; R. Hamilton</li>
<li><strong>年份</strong>：2010</li>
<li><strong>发表</strong>：IBM Journal of Research and Development</li>
<li><strong>引用</strong>：499，浏览1357</li>
<li><strong>摘要</strong>：This paper describes the information technology (IT) foundation and principles for Smarter Cities™. Smarter Cities are urban areas that exploit operational data, such as that arising from traffic congestion, power consumption statistics, and public safety events, to optimize the operation of city services. The foundational concepts are instrumented, interconnected, and intelligent. Instrumented refers to sources of near-real-time real-world data from both physical and virtual sensors. Interconnected means the integration of those data into an enterprise computing platform and the communication of such information among the various city services. Intelligent refers to the inclusion of complex analytics, modeling, optimization, and visualization in the operational business processes to make better operational decisions. This approach enables the adaptation of city services to the behavior of the inhabitants, which permits the optimal use of the available physical infrastructure and resources, for example, in sensing and controlling consumption of energy and water, managing waste processing and transportation systems, and applying optimization to achieve new efficiencies among these resources. Additional roles exist in intelligent interaction between the city and its inhabitants and further contribute to operational efficiency while maintaining or enhancing quality of life.</li>
<li><strong>关键词</strong>：Information technology, Urban areas, Smart buildings, Decision making, Intelligent structures, Structural engineering</li>
<li><strong>点评</strong>：宏观框架，需要一读</li>
</ul>
<h2 id="1-6"><a href="#1-6" class="headerlink" title="1-6"></a>1-6</h2><p>   Three Decades of Driver Assistance Systems: Review and Future Perspectives <a href="https://ieeexplore.ieee.org/document/6936444">驾驶辅助系统的三个十年：回顾和未来展望</a></p>
<ul>
<li><strong>作者</strong>：Klaus Bengler; Klaus Dietmayer; Berthold Farbe</li>
<li><strong>年份</strong>：2014</li>
<li><strong>发表</strong>：IEEE Intelligent Transportation Systems Magazine</li>
<li><strong>引用</strong>：414，,浏览10237</li>
<li><strong>摘要</strong>：This contribution provides a review of fundamental goals, development and future perspectives of driver assistance systems. Mobility is a fundamental desire of mankind. Virtually any society strives for safe and efficient mobility at low ecological and economic costs. Nevertheless, its technical implementation significantly differs among societies, depending on their culture and their degree of industrialization. A potential evolutionary roadmap for driver assistance systems is discussed. Emerging from systems based on proprioceptive sensors, such as ABS or ESC, we review the progress incented by the use of exteroceptive sensors such as radar, video, or lidar. While the ultimate goal of automated and cooperative traffic still remains a vision of the future, intermediate steps towards that aim can be realized through systems that mitigate or avoid collisions in selected driving situations. Research extends the state-of-the-art in automated driving in urban traffic and in cooperative driving, the latter addressing communication and collaboration between different vehicles, as well as cooperative vehicle operation by its driver and its machine intelligence. These steps are considered important for the interim period, until reliable unsupervised automated driving for all conceivable traffic situations becomes available. The prospective evolution of driver assistance systems will be stimulated by several technological, societal and market trends. The paper closes with a view on current research fields.</li>
<li><strong>关键词</strong>：Vehicle safety, Sensor systems, Laser radar, Advanced driver assistance systems, Vehicle dynamics, Automatic control, Research and development, Technology forecasting</li>
<li><strong>点评</strong>：综述类型，需要一读。</li>
</ul>
<h1 id="二、雷达-AI-无人驾驶"><a href="#二、雷达-AI-无人驾驶" class="headerlink" title="二、雷达+AI+无人驾驶"></a>二、雷达+AI+无人驾驶</h1><h2 id="2-1"><a href="#2-1" class="headerlink" title="2-1"></a>2-1</h2><p>   On-Road Vehicle Detection and Tracking Using MMW Radar and Monovision Fusion <a href="https://ieeexplore.ieee.org/document/7463071">使用毫米波雷达和 Monovision Fusion 进行道路车辆检测和跟踪</a></p>
<ul>
<li><strong>作者</strong>：Xiao Wang; Linhai Xu; Hongbin Sun; Jingmin Xin; Nanning Zheng</li>
<li><strong>年份</strong>：2016</li>
<li><strong>发表</strong>：IEEE Transactions on Intelligent Transportation Systems</li>
<li><strong>引用</strong>：80，浏览4229</li>
<li><strong>摘要</strong>：With the potential to increase road safety and provide economic benefits, intelligent vehicles have elicited a significant amount of interest from both academics and industry. A robust and reliable vehicle detection and tracking system is one of the key modules for intelligent vehicles to perceive the surrounding environment. The millimeter-wave radar and the monocular camera are two vehicular sensors commonly used for vehicle detection and tracking. Despite their advantages, the drawbacks of these two sensors make them insufficient when used separately. Thus, the fusion of these two sensors is considered as an efficient way to address the challenge. This paper presents a collaborative fusion approach to achieve the optimal balance between vehicle detection accuracy and computational efficiency. The proposed vehicle detection and tracking design is extensively evaluated with a real-world data set collected by the developed intelligent vehicle. Experimental results show that the proposed system can detect on-road vehicles with 92.36% detection rate and 0% false alarm rate, and it only takes ten frames (0.16 s) for the detection and tracking of each vehicle. This system is installed on Kuafu-II intelligent vehicle for the fourth and fifth autonomous vehicle competitions, which is called “Intelligent Vehicle Future Challenge” in China.</li>
<li><strong>关键词</strong>：Radar tracking, Radar detection, Vehicle detection, Vehicles, Cameras, Sensors</li>
<li><strong>点评</strong>：SVM，协同融合毫米波雷达和单目摄像头，可以关注一下“智能汽车未来挑战赛”，需要一读。</li>
</ul>
<h2 id="2-2"><a href="#2-2" class="headerlink" title="2-2"></a>2-2</h2><p>   Architecture Design and Implementation of an Autonomous Vehicle <a href="https://ieeexplore.ieee.org/document/8340798">自动驾驶汽车的架构设计与实现</a></p>
<ul>
<li><strong>作者</strong>：Wenhao Zong; Changzhu Zhang; Zhuping Wang</li>
<li><strong>年份</strong>：2018</li>
<li><strong>发表</strong>：IEEE Access </li>
<li><strong>引用</strong>：12，浏览11325</li>
<li><strong>摘要</strong>：Architecture design is one of the most important problems for an intelligent system. In this paper, a practical framework of hardware and software is proposed to reveal the external configuration and internal mechanism of an autonomous vehicle-a typical intelligent system. The main contributions of this paper are as follows. First, we compare the advantages and disadvantages of three typical sensor plans and introduce a general autopilot for a vehicle. Second, we introduce a software architecture for an autonomous vehicle. The perception and planning performances are improved with the help of two inner loops of simultaneous localization and mapping. An algorithm to enlarge the detection range of the sensors is proposed by adding an inner loop to the perception system. A practical feedback to restrain mutations of two adjacent planning periods is also realized by the other inner loop. Third, a cross-platform virtual server (named project cocktail) for data transmission and exchange is presented in detail. Through comparisons with the robot operating system, the performance of project cocktail is proven to be considerably better in terms of transmission delay and throughput. Finally, a report on an autonomous driving test implemented using the proposed architecture is presented, which shows the effectiveness, flexibility, stability, and low-cost of the overall autonomous driving system.</li>
<li><strong>关键词</strong>：Robot sensing systems, Autonomous vehicles, Cameras, Millimeter wave radar, Laser radar, Wheels</li>
<li><strong>点评</strong>：论文里有三种传感器方案的比较，车的自动驾驶操作系统，硬软件都有，可以大致读一下</li>
</ul>
<h2 id="2-3"><a href="#2-3" class="headerlink" title="2-3"></a>2-3</h2><p>   Deep Learning-based Object Classification on Automotive Radar Spectra <a href="https://ieeexplore.ieee.org/document/8835775">基于深度学习的汽车雷达光谱对象分类</a></p>
<ul>
<li><strong>作者</strong>：Kanil Patel; Kilian Rambach; Tristan Visentin</li>
<li><strong>年份</strong>：2019</li>
<li><strong>发表</strong>：2019 IEEE Radar Conference (RadarConf)</li>
<li><strong>引用</strong>：17，浏览1528</li>
<li><strong>摘要</strong>：Scene understanding for automated driving requires accurate detection and classification of objects and other traffic participants. Automotive radar has shown great potential as a sensor for driver assistance systems due to its robustness to weather and light conditions, but reliable classification of object types in real time has proved to be very challenging. Here we propose a novel concept for radar-based classification, which utilizes the power of modern Deep Learning methods to learn favorable data representations and thereby replaces large parts of the traditional radar signal processing chain. We propose to apply deep Convolutional Neural Networks (CNNs) directly to regions-of-interest (ROI) in the radar spectrum and thereby achieve an accurate classification of different objects in a scene. Experiments on a real-world dataset demonstrate the ability to distinguish relevant objects from different viewpoints. We identify deep learning challenges that are specific to radar classification and introduce a set of novel mechanisms that lead to significant improvements in object classification performance compared to simpler classifiers. Our results demonstrate that Deep Learning methods can greatly augment the classification capabilities of automotive radar sensors.</li>
<li><strong>关键词</strong>：Deep learning, Automotive engineering, Azimuth, Radar imaging, Radar tracking, Training</li>
<li><strong>点评</strong>：CNN应用于分析雷达光谱，优化传统雷达信号处理方法，可用的现实世界训练数据有限情况下。</li>
</ul>
<h2 id="2-4"><a href="#2-4" class="headerlink" title="2-4"></a>2-4</h2><p>   Robust vehicle localization in urban environments using probabilistic maps <a href="https://ieeexplore.ieee.org/document/5509700">使用概率图在城市环境中进行稳健的车辆定位</a></p>
<ul>
<li><strong>作者</strong>：Jesse Levinson; Sebastian Thrun</li>
<li><strong>年份</strong>：2010</li>
<li><strong>发表</strong>：2010 IEEE International Conference on Robotics and Automation</li>
<li><strong>引用</strong>：285，浏览4931</li>
<li><strong>摘要</strong>：Autonomous vehicle navigation in dynamic urban environments requires localization accuracy exceeding that available from GPS-based inertial guidance systems. We have shown previously that GPS, IMU, and LIDAR data can be used to generate a high-resolution infrared remittance ground map that can be subsequently used for localization. We now propose an extension to this approach that yields substantial improvements over previous work in vehicle localization, including higher precision, the ability to learn and improve maps over time, and increased robustness to environment changes and dynamic obstacles. Specifically, we model the environment, instead of as a spatial grid of fixed infrared remittance values, as a probabilistic grid whereby every cell is represented as its own gaussian distribution over remittance values. Subsequently, Bayesian inference is able to preferentially weight parts of the map most likely to be stationary and of consistent angular reflectivity, thereby reducing uncertainty and catastrophic errors. Furthermore, by using offline SLAM to align multiple passes of the same environment, possibly separated in time by days or even months, it is possible to build an increasingly robust understanding of the world that can be then exploited for localization. We validate the effectiveness of our approach by using these algorithms to localize our vehicle against probabilistic maps in various dynamic environments, achieving RMS accuracy in the 10cm-range and thus outperforming previous work. Importantly, this approach has enabled us to autonomously drive our vehicle for hundreds of miles in dense traffic on narrow urban roads which were formerly unnavigable with previous localization methods.</li>
<li><strong>关键词</strong>：Robustness, Remotely operated vehicles, Vehicle dynamics, Mobile robots, Navigation, Global Positioning System, Laser radar, Gaussian distribution, Bayesian methods, Reflectivity</li>
<li><strong>点评</strong>：在动态环境中根据概率图做车辆定位，地图导航向，有点意思。</li>
</ul>
<h2 id="2-5"><a href="#2-5" class="headerlink" title="2-5"></a>2-5</h2><p>   MapLite: Autonomous Intersection Navigation Without a Detailed Prior Map <a href="https://ieeexplore.ieee.org/document/8936918">MapLite：无需详细事先地图的自主交叉路口导航</a></p>
<ul>
<li><strong>作者</strong>：Teddy Ort; Krishna Murthy; Rohan Banerjee</li>
<li><strong>年份</strong>：2019</li>
<li><strong>发表</strong>：IEEE Robotics and Automation Letters</li>
<li><strong>引用</strong>：1，浏览2964</li>
<li><strong>摘要</strong>：In this work, we present MapLite: a one-click autonomous navigation system capable of piloting a vehicle to an arbitrary desired destination point given only a sparse publicly available topometric map (from OpenStreetMap). The onboard sensors are used to segment the road region and register the topometric map in order to fuse the high-level navigation goals with a variational path planner in the vehicle frame. This enables the system to plan trajectories that correctly navigate road intersections without the use of an external localization system such as GPS or a detailed prior map. Since the topometric maps already exist for the vast majority of roads, this solution greatly increases the geographical scope for autonomous mobility solutions. We implement MapLite on a full-scale autonomous vehicle and exhaustively test it on over 15 km of road including over 100 autonomous intersection traversals. We further extend these results through simulated testing to validate the system on complex road junction topologies such as traffic circles.</li>
<li><strong>关键词</strong>：Roads, Navigation, Sensors, Autonomous vehicles, Laser radar, Support vector machines, Surface texture</li>
<li><strong>点评</strong>：地图导航向，激光雷达，无需详细地图的自动驾驶。</li>
</ul>
<h2 id="2-6"><a href="#2-6" class="headerlink" title="2-6"></a>2-6</h2><p>   Object Classification and Recognition From Mobile Laser Scanning Point Clouds in a Road Environment <a href="https://ieeexplore.ieee.org/document/7287763">基于移动激光扫描点云的道路环境目标分类与识别</a></p>
<ul>
<li><strong>作者</strong>：Matti Lehtomäki; Anttoni Jaakkola; Juha Hyyppä</li>
<li><strong>年份</strong>：2015</li>
<li><strong>发表</strong>：IEEE Transactions on Geoscience and Remote Sensing</li>
<li><strong>引用</strong>：51，浏览2410</li>
<li><strong>摘要</strong>：Automatic methods are needed to efficiently process the large point clouds collected using a mobile laser scanning (MLS) system for surveying applications. Machine-learning-based object recognition from MLS point clouds in a road and street environment was studied in order to create maps from the road environment infrastructure. The developed automatic processing workflow included the following phases: the removal of the ground and buildings, segmentation, segment classification, and object location estimation. Several novel geometry-based features, which were previously applied in autonomous driving and general point cloud processing, were applied for the segment classification of MLS point clouds. The features were divided into three sets, i.e., local descriptor histograms (LDHs), spin images, and general shape and point distribution features, respectively. These were used in the classification of the following roadside objects: trees, lamp posts, traffic signs, cars, pedestrians, and hoardings. The accuracy of the object recognition workflow was evaluated using a data set that contained more than 400 objects. LDHs and spin images were applied for the first time for machine-learning-based object classification in MLS point clouds in the surveying applications of the road and street environment. The use of these features improved the classification accuracy by 9.6% (resulting in 87.9% accuracy) compared with the accuracy obtained using 17 general shape and point distribution features that represent the current state of the art in the field of MLS; therefore, significant improvement in the classification accuracy was achieved. Connected component segmentation and ground extraction were the cause of most of the errors and should be thus improved in the future.</li>
<li><strong>关键词</strong>：Three-dimensional displays, Histograms, Roads, Image segmentation, Buildings, Object recognition, Accuracy</li>
<li><strong>点评</strong>：目标识别+移动激光扫描系统收集的大型点云，关系不大，仅供参考。</li>
</ul>
<h2 id="2-7"><a href="#2-7" class="headerlink" title="2-7"></a>2-7</h2><p>   Machine Vision Based Traffic Sign Detection Methods: Review, Analyses and Perspectives <a href="https://ieeexplore.ieee.org/document/8746141">基于机器视觉的交通标志检测方法：回顾、分析和展望</a></p>
<ul>
<li><strong>作者</strong>：Chunsheng Liu; Shuang Li; Faliang Chang</li>
<li><strong>年份</strong>：2019</li>
<li><strong>发表</strong>：IEEE Access</li>
<li><strong>引用</strong>：18，浏览2431</li>
<li><strong>摘要</strong>：Traffic signs recognition (TSR) is an important part of some advanced driver-assistance systems (ADASs) and auto driving systems (ADSs). As the first key step of TSR, traffic sign detection (TSD) is a challenging problem because of different types, small sizes, complex driving scenes, and occlusions. In recent years, there have been a large number of TSD algorithms based on machine vision and pattern recognition. In this paper, a comprehensive review of the literature on TSD is presented. We divide the reviewed detection methods into five main categories: color-based methods, shape-based methods, color- and shape-based methods, machine-learning-based methods, and LIDAR-based methods. The methods in each category are also classified into different subcategories for understanding and summarizing the mechanisms of different methods. For some reviewed methods that lack comparisons on public datasets, we reimplemented part of these methods for comparison. The experimental comparisons and analyses are presented on the reported performance and the performance of our reimplemented methods. Furthermore, future directions and recommendations of the TSD research are given to promote the development of the TSD.</li>
<li><strong>关键词</strong>：Cameras, Shape, Laser radar, Color, Support vector machines, Machine vision, Roads</li>
<li><strong>点评</strong>：综述类型，针对交通标志识别，激光雷达，道路场景</li>
</ul>
<h2 id="2-8"><a href="#2-8" class="headerlink" title="2-8"></a>2-8</h2><p>   Unexpected Collision Avoidance Driving Strategy Using Deep Reinforcement Learning <a href="https://ieeexplore.ieee.org/document/8961990">使用深度强化学习的意外碰撞避免驾驶策略</a></p>
<ul>
<li><strong>作者</strong>：Myounghoe Kim; Seongwon Lee; Jaehyun Lim</li>
<li><strong>年份</strong>：2020</li>
<li><strong>发表</strong>：IEEE Access</li>
<li><strong>引用</strong>：4，浏览1380</li>
<li><strong>摘要</strong>：In this paper, we generated intelligent self-driving policies that minimize the injury severity in unexpected traffic signal violation scenarios at an intersection using the deep reinforcement learning. We provided guidance on reward engineering in terms of the multiplicity of objective function. We used a deep deterministic policy gradient method in the simulated environment to train self-driving agents. We designed two agents, one with a single-objective reward function of collision avoidance and the other with a multi-objective reward function of both collision avoidance and goal-approaching. We evaluated their performances by comparing the percentages of collision avoidance and the average injury severity against those of human drivers and an autonomous emergency braking (AEB) system. The percentage of collision avoidance of our agents were 78.89% higher than human drivers and 84.70% higher than the AEB system. The average injury severity score of our agents were only 8.92% of human drivers and 6.25% of the AEB system.</li>
<li><strong>关键词</strong>：Reinforcement learning, Collision avoidance, Injuries, Vehicles, Gradient methods, Wheels, Laser radar</li>
<li><strong>点评</strong>：意外场景下避免碰撞的自动驾驶策略，仅使用单通道lidar，有点意思。</li>
</ul>
<h1 id="三、-多传感器融合"><a href="#三、-多传感器融合" class="headerlink" title="三、 多传感器融合"></a>三、 多传感器融合</h1><h2 id="2-1-1"><a href="#2-1-1" class="headerlink" title="2-1"></a>2-1</h2><h2 id="3-1"><a href="#3-1" class="headerlink" title="3-1"></a>3-1</h2><p>   An introduction to multisensor data fusion <a href="https://ieeexplore.ieee.org/document/554205">多传感器数据融合简介</a></p>
<ul>
<li><strong>作者</strong>：D.L. Hall; J. Llinas</li>
<li><strong>年份</strong>：1997</li>
<li><strong>发表</strong>：Proceedings of the IEEE</li>
<li><strong>引用</strong>：1403，浏览15349</li>
<li><strong>摘要</strong>：Multisensor data fusion is an emerging technology applied to Department of Defense (DoD) areas such as automated target recognition, battlefield surveillance, and guidance and control of autonomous vehicles, and to non-DoD applications such as monitoring of complex machinery, medical diagnosis, and smart buildings. Techniques for multisensor data fusion are drawn from a wide range of areas including artificial intelligence, pattern recognition, statistical estimation and other areas. This paper provides a tutorial on data fusion, introducing data fusion applications, process models, and identification of applicable techniques. Comments are made on the state-of-the-art in data fusion.</li>
<li><strong>关键词</strong>：Target recognition, Surveillance, Navigation, Automatic control, Intelligent vehicles, Remotely operated vehicles, Mobile robots, Biomedical monitoring, Computerized monitoring, Condition monitoring</li>
<li><strong>点评</strong>：综述类型，需要一读</li>
</ul>
<h1 id="四、5G定位-雷达"><a href="#四、5G定位-雷达" class="headerlink" title="四、5G定位+雷达"></a>四、5G定位+雷达</h1>]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS入学需知</title>
    <url>/NUS%E5%85%A5%E5%AD%A6%E9%9C%80%E7%9F%A5/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ul>
<li>附件0 清单<ul>
<li>步骤</li>
<li>NUS有用链接</li>
<li>疫情通知</li>
</ul>
</li>
<li>附件1 校历<ul>
<li>总时间表</li>
<li>活动时间表</li>
<li>军训</li>
</ul>
</li>
<li>附件2 课程及其他要求<ul>
<li>课程要求</li>
<li>Seminar要求</li>
<li>QE</li>
<li>论文提交</li>
<li>英语要求</li>
<li>EG5911R: Information Literacy Skills for Research</li>
</ul>
</li>
<li>附件3 体检<ul>
<li>入学前体检</li>
<li>学生准证申请体检</li>
<li>注意事项</li>
</ul>
</li>
<li>附件4 2021-2022学年学费</li>
<li>附件5 国际生须知<ul>
<li>出国前<ul>
<li>入境 Immigration</li>
<li>入学</li>
<li>资产</li>
<li>私人物品</li>
<li>生活费预算</li>
<li>住宿</li>
</ul>
</li>
<li>抵达新加坡<ul>
<li>海关申报表</li>
<li>相关通知</li>
</ul>
</li>
<li>前往NUS(Kent Ridge)</li>
<li>抵达NUS</li>
<li>其他事务<ul>
<li>保险</li>
<li>医疗</li>
<li>大使馆/最高委员会登记</li>
<li>银行</li>
<li>国际生服务ISS</li>
</ul>
</li>
<li>出发前核对清单<ul>
<li>完成表格</li>
<li>重要文件</li>
<li>申请宿舍</li>
<li>工作日/周末后到达</li>
<li>国际生介绍会</li>
<li>Visa需求(仅适用于ICA网站上所列出的国家)</li>
<li>行程安排</li>
<li>免疫检查(可选)</li>
<li>居家通知和检测制度</li>
<li>体检</li>
<li>医保</li>
<li>财务准备</li>
</ul>
</li>
<li>注意事项</li>
</ul>
</li>
<li>附件6 更多信息<ul>
<li>候选期 Period of candidature</li>
<li>居住要求 Residency requirement</li>
<li>医保计划 Medical Insurance Scheme</li>
<li>电子设备</li>
<li>手册和论文</li>
</ul>
</li>
<li>附件7 在线答复offer</li>
<li>附件8 奖学金</li>
<li>附件9 其他<ul>
<li>地图</li>
</ul>
</li>
</ul>
<hr>
<h1 id="附件0-清单"><a href="#附件0-清单" class="headerlink" title="附件0 清单"></a>附件0 清单</h1><h2 id="一、步骤"><a href="#一、步骤" class="headerlink" title="一、步骤"></a>一、步骤</h2><p>收到offer后，</p>
<ol>
<li><p>在 <a href="https://inetapps.nus.edu.sg/GDA2">https://inetapps.nus.edu.sg/GDA2</a> 完成<strong>在线答复</strong>。</p>
</li>
<li><p>你会收到 NUS Graduate School 的指示，请参考 Registrar’s Office Guideline 给的<a href="https://nus.edu.sg/registrar/docs/info/registration-guides/registration-guide-for-graduate-research-students.pdf">注册指南</a> 在截止日期前完成状态更新：</p>
<p>完成海外旅行申报单<strong>Overseas Travel Declaration (OTD)</strong>(自2021.6起)</p>
<ul>
<li>对于新生：<br>   请用以下方式登录<a href="https://myaces.nus.edu.sg/OverseasTravelDecl/applicantLogin">OTD申请系统</a><ol>
<li>申请号</li>
<li>申请密码/PIN</li>
<li>选择学生类型</li>
</ol>
</li>
<li>对于老生：<br>   使用NUSNET ID登录</li>
</ul>
</li>
<li><p>必须完成<strong>注册（part1）</strong> <a href="https://myregistration.nus.edu.sg/">https://myregistration.nus.edu.sg/</a> </p>
<p>注册系统从<strong>2021-6-14</strong>开放，使用GDA2申请号和密码登录pre-registration系统。</p>
<p>需要更新的资料和声明如下：</p>
<ul>
<li>学生行为守则Code of Student Conduct</li>
<li>犯罪记录声明</li>
<li>健康和support声明</li>
<li>可接受的IT资源使用政策Acceptable Use Policy for IT Resources</li>
<li>不端性行为惩罚</li>
<li>NUS拒收电话政策(Do-Not-Call)</li>
<li>NUS知识产权政策</li>
<li>NUS学生隐私政策</li>
<li>费用补贴(Fee Subsidy)申报</li>
<li>承诺书(适用于奖学金获得者)</li>
<li>解除债务</li>
<li>医疗程序授权</li>
<li>Appointment of Local Representative</li>
</ul>
</li>
<li><p>入境申请(Entry Approval)：<a href="https://safetravel.ica.gov.sg/stpl/requirements-and-process">STO-STP网站</a></p>
</li>
<li><p>获得有效护照，雇佣护照(适用于part-time学生)，IPA信(如果有必要的话，部分国家又要求)。</p>
<p>带上关键文件的原件，如成绩单、出生证明/身份证/护照等，以及录取信中列出的任何未完成的文件。</p>
</li>
<li><p>注册诊断英语考试Diagnostic English Test(DET)（如果offer里列出你需要参加的话）</p>
<ol>
<li>在线注册时间：2021.7.2-2021.7.8</li>
<li>参加考试：2021.7.21(<a href="http://www.nus.edu.sg/celc/">地点</a>)</li>
</ol>
</li>
<li><p>在每个新的学期前需要进行在线modules注册（新学期开始两周前开始module注册）。</p>
<p>请关注系办公室(Department Office)通知。</p>
<p>module(s)的选择需要和导师/部门讨论。</p>
</li>
<li><p>在新加坡国立大学健康中心(UHC)进行入学前体检(如果您没有在本国完成的话)(在注册前完成)</p>
</li>
<li><p>教授迎新讲座(Faculty’s Orientation Talk)(具体细节8月前会发邮件确认)。</p>
</li>
<li><p>参加适用于国际生的国际生迎新电子简报会(<a href="http://nus.edu.sg/osa/studentlife/international-students/briefing">OSA website</a>)</p>
</li>
<li><p>向系办公室(Department Office)报到完成**注册(part2)**：具体细节7月初会通知你。</p>
<ul>
<li>收(Collect)学生卡</li>
<li>从office那里获得讲座时间表</li>
<li>参加部门迎新讲座(Department’s Orientation Talk)(请和您的部门确认)</li>
</ul>
</li>
<li><p>向导师报到。</p>
<p>导师会对你的科研给出指导和更多的信息。（仅适用于有指定导师的学生）<a href="https://myregistration.nus.edu.sg/">https://myregistration.nus.edu.sg/</a></p>
</li>
</ol>
<h2 id="二、有用链接"><a href="#二、有用链接" class="headerlink" title="二、有用链接"></a>二、有用链接</h2><ul>
<li><p>RO 注册办公室(Registrar’s Office)</p>
<p><a href="http://www.nus.edu.sg/registrar/">http://www.nus.edu.sg/registrar/</a></p>
</li>
<li><p>NUS研究生院(Graduate School)：</p>
<p><a href="https://nusgs.nus.edu.sg/">https://nusgs.nus.edu.sg/</a></p>
</li>
<li><p>OGP 工程学院-研究生课程办公室(Faculty of Engineering – Office of Graduate Programmes)</p>
<p><a href="https://www.eng.nus.edu.sg/graduate/">https://www.eng.nus.edu.sg/graduate/</a></p>
</li>
<li><p>NUS图书馆</p>
<p><a href="http://libportal.nus.edu.sg/frontend/ms/central-library/about-central-library">http://libportal.nus.edu.sg/frontend/ms/central-library/about-central-library</a></p>
</li>
<li><p>OSA 学生事务办公室(Office of Student Affairs)</p>
<p><a href="http://www.nus.edu.sg/osa/">http://www.nus.edu.sg/osa/</a></p>
</li>
<li><p>UHC 大学健康中心(University Health Centre)</p>
<p>  <a href="http://www.nus.edu.sg/uhc/">http://www.nus.edu.sg/uhc/</a></p>
</li>
<li><p>大学健康中心(Graduate&amp;Non-Graduate保险计划)</p>
<p> <a href="http://www.nus.edu.sg/uhc/services/billing-insurance/insurance-matters">http://www.nus.edu.sg/uhc/services/billing-insurance/insurance-matters</a></p>
</li>
<li><p>NUS校园地图</p>
<p> <a href="http://map.nus.edu.sg/">http://map.nus.edu.sg/</a></p>
</li>
</ul>
<h2 id="三、疫情通知"><a href="#三、疫情通知" class="headerlink" title="三、疫情通知"></a>三、疫情通知</h2><p>鉴于COVID-19的现状，学生需要检查：</p>
<ol>
<li>国际学生需要查看 <a href="https://www.moh.gov.sg/covid-19">卫生部Ministry of Health(MOH)网站</a> 上的”Measures which apply to Inbound Travellers”，规划如何入境。</li>
<li>定期查看收件箱中NUS的邮件，关注最新动态。</li>
<li>参考以下NUS网站:<ol>
<li>应对COVID-19的其他措施 <a href="https://www.nus.edu.sg/registrar/academic-activities/registration/administrative-matters">RO注册办公室</a></li>
<li><a href="https://emergency.nus.edu.sg/">OSHE</a></li>
<li>关于保险：<a href="https://nus.edu.sg/uhc/general-health/billing-insurance/insurance-matters">大学健康中心UHC</a></li>
</ol>
</li>
</ol>
<hr>
<h1 id="附件1-校历"><a href="#附件1-校历" class="headerlink" title="附件1 校历"></a>附件1 校历</h1><h2 id="一、总时间表"><a href="#一、总时间表" class="headerlink" title="一、总时间表"></a>一、总时间表</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210508001604.png"><br><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210508002007.png"></p>
<h2 id="二、活动时间表"><a href="#二、活动时间表" class="headerlink" title="二、活动时间表"></a>二、活动时间表</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210508092125.png"></p>
<p><a href="http://www.nus.edu.sg/ModReg">http://www.nus.edu.sg/ModReg</a></p>
<p><a href="http://www.nus.edu.sg/registrar/academic-activities/special-term">http://www.nus.edu.sg/registrar/academic-activities/special-term</a></p>
<p><a href="http://www.nus.edu/sg/commencement">http://www.nus.edu/sg/commencement</a></p>
<h2 id="三、军训"><a href="#三、军训" class="headerlink" title="三、军训"></a>三、军训</h2><p>针对来自SAF/SPF/SCDF的本科NSmen，学院跟国防部、内政部一起组织了ICT训练(In-Camp Training)，该训练仅在学校假期的一段特殊时间段内进行。</p>
<p>ICT期间学校不会安排或进行任何强制性的学术项目。需要参加ICT的本科NSmen不会因为学术承诺而获得延期。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210508093229.png"></p>
<hr>
<h1 id="附件2-课程及其他要求"><a href="#附件2-课程及其他要求" class="headerlink" title="附件2 课程及其他要求"></a>附件2 课程及其他要求</h1><p>针对MEng/EngD/PhD学生的课程及其他要求，以下内容仅列出与PhD相关部分。</p>
<h2 id="一、课程要求"><a href="#一、课程要求" class="headerlink" title="一、课程要求"></a>一、课程要求</h2><p>候选人需就其感兴趣的领域进行研究，并在考试的最长期限前提交论文。除了论文需求，候选人还需要参加规定数量的课程，这些课程是导师认为对候选人有用的。</p>
<p>课程组成部分：</p>
<ol>
<li><p>模块学分(Modular Credits)：</p>
<p>每个包括39课时的研究生模块(module)，都被分配了4个模块学分(MC)。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">Each graduate module of 39 lecture hours is to be assigned 4 modular credits (MC).</span><br></pre></td></tr></tbody></table></figure></li>
<li><p>等级和绩点<br>字母等级对应绩点如下所示：</p>
<table>
<thead>
<tr>
<th align="left">Grade</th>
<th align="left">Grade Point</th>
</tr>
</thead>
<tbody><tr>
<td align="left">A+</td>
<td align="left">5.00</td>
</tr>
<tr>
<td align="left">A</td>
<td align="left">5.00</td>
</tr>
<tr>
<td align="left">A-</td>
<td align="left">4.50</td>
</tr>
<tr>
<td align="left">B+</td>
<td align="left">4.00</td>
</tr>
<tr>
<td align="left">B</td>
<td align="left">3.50</td>
</tr>
<tr>
<td align="left">B-</td>
<td align="left">3.00</td>
</tr>
<tr>
<td align="left">C+</td>
<td align="left">2.50</td>
</tr>
<tr>
<td align="left">C</td>
<td align="left">2.00</td>
</tr>
<tr>
<td align="left">D+</td>
<td align="left">1.50</td>
</tr>
<tr>
<td align="left">D</td>
<td align="left">1.00</td>
</tr>
<tr>
<td align="left">F(Fail)</td>
<td align="left">0</td>
</tr>
</tbody></table>
<p><strong>Phd要求CAP必须&gt;=3.50</strong></p>
</li>
<li><p>学术警告、留校察看、退学与毕业 </p>
<ol>
<li><p>关于继续学习(continuation)：</p>
<ul>
<li>在第一学期的学习中，CAP不得低于1.50；or，</li>
<li>对于PhD学生： CAP不得连续两学期低于3.00；or， CAP不得连续三学期低于3.50。</li>
</ul>
<p>CAP不满足要求的学生会被建议退学。</p>
<p>任一学期中，如果CAP低于毕业要求(PhD要求3.50以上)，学生会收到学术警告或者留校察看通知。此外，在资格考试(QE)、科研或者其他课程要求中表现不佳的学生同样可能会收到学术警告或者留校察看通知。</p>
</li>
<li><p>关于毕业(Graduation)：</p>
<p><strong>针对ECE的PhD学生</strong></p>
<ul>
<li>获得至少24 MCs（不包括博士研讨会(Doctoral Seminars)和研究生英语课程模块），这24个MCs必须是该学科或者相关科目的研究生水平，须经系里批准。MCs包括<strong>2个EE5000模块</strong>、<strong>2个EE6000模块</strong>，和<strong>2个无限制模块</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">每个模块module (约39h的课时) 包括4个模块学分MC，即1模块=4MC。</span><br><span class="line">毕业需要完成24个MC，等于6个模块。</span><br><span class="line">这6个模块包括2个EE5000模块、2个EE6000模块、2个任意模块。</span><br></pre></td></tr></tbody></table></figure></li>
<li>4 MCs(2x2) 的EE6990 Research Attachment需要获得令人满意的成绩。</li>
<li>最好的6个模块(=24 MCs)的CAP&gt;=3.50.</li>
<li>通过资格考试（Qualifying Examination, QE）。</li>
<li>通过Phd论文和口头考核。</li>
<li>在研究生英语课程（中等水平）中获得最低为C的等级。</li>
<li>在ES5101 Technical Communication for Engineers（0 MC, graded）中获得最低为C的等级。</li>
<li>在EG5911R Literacy Skills for Research中获得令人满意的成绩。</li>
<li>在Doctoral Seminars中获得令人满意的成绩。</li>
</ul>
</li>
</ol>
</li>
</ol>
<p><em>注意：CAP = Cumulative Average Point累计绩点 = Sum(Grade Pt x MC)/Sum(MC)</em></p>
<p>对于尚未达到最小毕业MC的学生而言，所有字母等级需要换算成CAP。</p>
<p>而对于已达毕业MC的学生，the CAP is computed using the best modules equivalent to minimum number of modular credits(inclusive of foundation/core modules, where required)。评级为F的模块不获得任何MC。</p>
<p>在计算完成课程需求的绩点时，CELC模块（比如，研究生英语课程）不被计入其中。</p>
<p>所有课程一般会在周一至周五的晚上6:00-9:00进行。关于需要上啥课，Candidates需要和导师讨论并获得导师的批准。</p>
<h2 id="二、Seminar要求"><a href="#二、Seminar要求" class="headerlink" title="二、Seminar要求"></a>二、Seminar要求</h2><p>所有研究型学生都需要参加研讨会(Seminar)。在你注册成一个NUS的学生后，请从你的Department/Division处获得关于这部分要求的更多信息。</p>
<h2 id="三、QE"><a href="#三、QE" class="headerlink" title="三、QE"></a>三、QE</h2><p>除了课程要求，所有工程学院的博士候选人都需要参加并通过资格考试(QE)，该考试包括以下内容：</p>
<ol>
<li>综合资格考试；</li>
<li>提交一份30-40页的关于正在进行的科研的研究报告；</li>
<li>在至少3个成员（包括你的导师）组成的小组面前，完成有关你研究报告的口头答辩。</li>
</ol>
<p><strong>关于QE的时间：</strong></p>
<p>对于全日制和非全日制的直博候选人，综合资格考试将在第一年内（自申请开始之日起？）进行，而口头资格考试需要在24个月（2年）内通过。</p>
<p>未通过QE的候选人将被提名到研究生委员会，终止其资格（退学）。</p>
<p><strong>针对获得NUS研究型奖学金的学生</strong><br>自通过口头资格考试之日起，学生可以每月额外获得$500的助学津贴。</p>
<p>追加的款项将在奖学金申请的第四年/截止日期（取较早者）内发放。</p>
<h2 id="四、论文提交"><a href="#四、论文提交" class="headerlink" title="四、论文提交"></a>四、论文提交</h2><p>对于PhD学生：within 4 years of your candidature to be in time for the degree to be conferred to you by 5 years.</p>
<p>更详细的指导请参考：<a href="https://myportal.nus.edu.sg/studentportal/nusgs/gd/docs/Thesis%20Submission%20and%20Examination.pdf">https://myportal.nus.edu.sg/studentportal/nusgs/gd/docs/Thesis%20Submission%20and%20Examination.pdf</a></p>
<h2 id="五、英语需求"><a href="#五、英语需求" class="headerlink" title="五、英语需求"></a>五、英语需求</h2><p>针对需要参加DET考试的学生，但雨我无瓜。</p>
<h2 id="六、EG5911R"><a href="#六、EG5911R" class="headerlink" title="六、EG5911R"></a>六、EG5911R</h2><p>EG5911R: Information Literacy Skills for Research</p>
<p>自2013/14的第一学期起，PhD学生被要求注册这个模块。该模块需在第一学期进行。该模块为工程研究的学生提供如何高效查找期刊论文的背景知识。是有关剽窃问题和实验室安全的最好实践。</p>
<p>该模块是完成毕业要求的一部分。它是0 MCs课程，使用令人满意的完成/不令人满意的完成（CS/SC）的标准来评分。学生需要获得CS。</p>
<p>图书馆指导员仅提供一个上午的有关期刊搜索的讲座。</p>
<p>对于PhD学生而言，该模块需要在口头资格考试前完成。</p>
<hr>
<h1 id="附件3-体检"><a href="#附件3-体检" class="headerlink" title="附件3 体检"></a>附件3 体检</h1><p>入学条件是健康且没有器官疾病，在入学前，所有学生都必须完成强制的预入学体检。</p>
<h2 id="一、入学前体检"><a href="#一、入学前体检" class="headerlink" title="一、入学前体检"></a>一、入学前体检</h2><p>在入学前，所有研究生都必须经过下述的pre-enrolment体检：</p>
<ul>
<li><p>当地学生（略）</p>
</li>
<li><p>国际生</p>
<p>除了NUS pre-enrolment体检，申请学生准证(Student’s Pass)还需要进行HIV检测。</p>
<ul>
<li>HIV检测和体检可以在原国家或者新加坡完成。原始的HIV检测和胸部X光检查报告，必须和用于学生准证的ICA体检报告一起，在发布后三个月内上交到移民与关卡局(Immigration &amp; Checkpoints Authorit, ICA)。 <strong>注意：体检报告、测试报告和X光报告都必须是英文版的。胸部X光报告上需要有学生的姓名、身份证号、出生日期等个人信息。</strong></li>
<li>如果学生选择在UHC做NUS入学前体检和学生准证体检，在GST（消费税）后费用是$55(包括胸部X光合HIV检查)。请注意检查结果只会在5个工作日后给出。</li>
<li>请带上 <a href="https://www.ica.gov.sg/docs/default-source/ica/forms/medical-examination-report.pdf">ICA学生准证体检表</a> 和 <a href="http://www.nus.edu.sg/uhc/docs/default-source/default-document-library/graduate.pdf?sfvrsn=7f37a850_2">入学前体检表</a>(包括第一部分的自我声明和第二部分的医生证明) 以供医生填写。请参考<a href="http://www.nus.edu.sg/uhc/services/medical-examination/pre-admission/pre-admission-medical-exam">UHC官网</a>的最新版表格，不要使用旧版。</li>
</ul>
</li>
</ul>
<p>选择在UHC进行学生准证体检的同学必须进行医疗预约，以便在ICA Off Site Enrolment (OSE)前至少3天上传体检报告。</p>
<p>从2021.4起，学生可以在UHC进行预约。请参考<a href="http://www.nus.edu.sg/uhc/services/medical-examination/pre-admission/pre-admission-medical-exam">UHC官网</a>获取更多信息。</p>
<p>针对入学前体检，请参考<a href="https://nus.edu.sg/registrar/docs/info/registration-guides/registration-guide-for-graduate-research-students.pdf">注册指南</a>（<em>此为旧版</em>）第四页。如果你计划在UHC做这个体检，请参考 <a href="http://www.nus.edu.sg/uhc/services/medical-examination/pre-admission/pre-admission-medical-exam-proces">http://www.nus.edu.sg/uhc/services/medical-examination/pre-admission/pre-admission-medical-exam-proces</a> 获得如何在线预约的相关指引。</p>
<h2 id="二、STP申请体检"><a href="#二、STP申请体检" class="headerlink" title="二、STP申请体检"></a>二、STP申请体检</h2><p><strong>重要：只要在获得学生准证的In-Principal Approval(IPA)信后，才能进行旅行。</strong></p>
<p>对于国际生，如果要申请学生准证，（尤其当你要在自己国家完成体检时）你必须下载并提交由医生认证的两个表格</p>
<p>   <code>Admission Medical Examination Report for</code></p>
<ul>
<li><a href="https://www.nus.edu.sg/uhc/docs/default-source/default-document-library/graduate.pdf?sfvrsn=7f37a850_2">Graduate Students Form (UHC)</a>;</li>
<li><a href="https://www.ica.gov.sg/docs/default-source/ica/forms/medical-examination-report.pdf">ICA Student Pass Medical Examination Form</a></li>
</ul>
<p>对于具有SOLAR状态，IPA(Pending Document Submission)或 IPA(Pending Issuance Fee)的学生，必须在OSE前至少3天在网上提交未完成的材料和/或支付必要的费用。</p>
<p>体检包括以下内容：</p>
<ul>
<li>Physical检查</li>
<li>Laboratory检查*</li>
<li>胸部X光</li>
<li>HIV测试（仅适用于国际生）</li>
</ul>
<p>*<em>注意：女生请在例假结束后至少5-7天后再来体检，因为月经会影响尿检结果。</em></p>
<p>体检费用需要由学生自己负担。UHC的费用如下：</p>
<ul>
<li>标准体检（包括胸部X光和尿检）—$40.00</li>
<li>标准体检与学生准证体检（国际生）—$55.00</li>
</ul>
<p>学生准证的签发将视体检的结果而定。那些被发现患有活动性肺结核或HIV感染的人将不能获得相关通行证，因此，他们必须自费返回各自的国家。</p>
<h2 id="三、注意事项"><a href="#三、注意事项" class="headerlink" title="三、注意事项"></a>三、注意事项</h2><ol>
<li><p>总结一下就是国际生要交俩表：</p>
<ul>
<li><p><a href="https://www.nus.edu.sg/uhc/docs/default-source/default-document-library/graduate.pdf">Graduate Students Form (UHC)</a></p>
</li>
<li><p><a href="https://www.ica.gov.sg/docs/default-source/ica/forms/medical-examination-report.pdf">ICA Student Pass Medical Examination Form</a>。</p>
</li>
</ul>
<p>表1自己写part1。</p>
<p>在当地国际旅行卫生保健中心体检就行，提前电话预约，准备相关资料，带上1000现金，空腹。</p>
</li>
<li><p>鉴于当前COVID-19的国际形势，学生需要关注:</p>
<ol>
<li>对于国际生，请参考<a href="https://www.moh.gov.sg/covid-19">Ministry of Health (MOH) 官网</a>上的“Measures which apply to Inbound Travelers”内容，规划前往新加坡的行程。</li>
<li>定期检查邮箱中来自NUS的邮件以获得最新指示。</li>
</ol>
</li>
<li><p><code>E:\留学\准备事宜\附件3-1.pdf</code> = <a href="https://www.nus.edu.sg/uhc/docs/default-source/default-document-library/graduate.pdf">Graduate Students Form (UHC)</a></p>
</li>
</ol>
<hr>
<h1 id="附件4-学费"><a href="#附件4-学费" class="headerlink" title="附件4 学费"></a>附件4 学费</h1><p>政府资助的硕博项目</p>
<p>已更新，详情可见 <a href="https://www.nus.edu.sg/registrar/docs/info/administrative-policies-procedures/">https://www.nus.edu.sg/registrar/docs/info/administrative-policies-procedures/</a> =  <code>E:\留学\准备事宜\入学指南\2021-22学费.pdf</code>。</p>
<table>
<thead>
<tr>
<th align="left">学院</th>
<th align="left">新加坡居民</th>
<th align="left">新加坡永久居住者</th>
<th align="left">有服务义务(3,7)的国际生/研究生助教奖学金项目</th>
<th align="left">不在MOE资助范围内(1.2,4,5)的新加坡居民</th>
<th align="left">不在MOE资助范围内的新加坡永久居住者和国际生</th>
</tr>
</thead>
<tbody><tr>
<td align="left">工程学院</td>
<td align="left">9500</td>
<td align="left">14000</td>
<td align="left">21400</td>
<td align="left">38550</td>
<td align="left">40600</td>
</tr>
</tbody></table>
<p>注意事项：</p>
<ol>
<li><p>以上学费单位都是S$/y，由于需要逐年审查，因此可能有所调整。</p>
<ol>
<li><p>在2020/21学年入学的新加坡学生的授课型和研究型项目的剩余课程期间的学费计划将在2021年学年开始前审核。</p>
</li>
<li><p>在余下的课程期间，2020/21学年入学的新加坡永久居民(PR)和国际生(IS)的授课型和研究型项目的学费每年会分别增加1%和1.5%，capped at the dollar increase in AY2020.</p>
</li>
<li><p>自2019/20学年起，授课型学生如果延期毕业，在剩余的学期内需缴纳无资助的全款学费(无MOE版本)。</p>
<p><a href="http://www.nus.edu.sg/registrar/prospective-students/graduate/scholarship">延毕参考链接</a></p>
</li>
<li><p>对于建筑系硕士balabala，雨我无瓜。</p>
</li>
</ol>
</li>
<li><p>对于新加坡居民和永久居民balabala，雨我无瓜。</p>
</li>
<li><p>国际生应支付应缴费用的现行消费税GST(当前为7%)，上述学费已包含了GST。</p>
</li>
<li><p>无MOE资助的学生需缴纳上列的无资助版学费（已包含GST）。</p>
</li>
<li><p>之前在硕博项目中享受过政府资助或政府机构（比如Ministries, Public Service Commission和Statutory Board）资助的学生，需要参考 <a href="http://nus.edu.sg/registrar/docs/info/administrative-policies-procedures/gd-eligibility-guidelines.pdf">Eligibility Guidelines for MOE Subsidy</a> = <code>E:\留学\准备事宜\入学指南\附件4-1.pdf</code>。不符合MOE资助的学生也不符合大多数奖学金要求。获取更多信息请参考<a href="http://www.nus.edu.sg/registrar/prospective-students/graduate/scholarship">Scholarships/Awards</a>。</p>
</li>
<li><p><a href="http://www.skillsfuture.sg/enhancedsubsidy">SkillsFuture Mid-Career Enhanced Subsidy</a>，针对40+新加坡居民，雨我无瓜。</p>
</li>
<li><p><a href="http://www.nus.edu.sg/registrar/prospective-students/graduate/service-obligation-(so)-scheme">服务义务方案</a></p>
<p>服务义务包含在一些MOE资助项目中。基于工业需求，符合条件并签署了服务义务协议的国际生将减免学费。在服务义务下应支付的费用和教育部补贴的数额将反映在他们的<a href="http://www.nus.edu.sg/finance/NoticeonPaymentofFees.html">个人学生帐单</a>中。最终解释权贵学校所有。</p>
<ol>
<li>自2017/18学年起，获得MOE奖学金资助的国际生，如果有研究生助教奖学金项目(Graduate Assistantship Programme, GAP)要求—(包括NGSS、PGF、NUS研究型奖学金RS、TFA和SINGA)，则不需要签署服务协议。<strong>简言之，我奖学金的一部分属于NUS研究型奖学金，只需要做GAP项目，不用管服务协议。</strong></li>
<li>自2018/19学年起，中国人民大学(RUC)工商管理硕士(MBA)和房地产理学硕士(MRE)双学位项目的新录取国际生不符合MOE，因此，不签署服务协议。</li>
<li>学生如果违反协议需要付违约赔偿金(LD)，且每学年需要支付服务协议下的MOE资助总额，外加10%的复利。</li>
</ol>
</li>
<li><p>雨我无瓜的学院的学费查找途径。</p>
</li>
<li><p><a href="http://www.nus.edu.sg/registrar/academic-activities/special-term/graduate-special-term">特殊学期</a><br> 特殊学期中，课程计划的阅读模块的费用需学生支付。</p>
<p> 不过据说雨我无瓜。</p>
</li>
</ol>
<hr>
<h1 id="附件5-国际生须知"><a href="#附件5-国际生须知" class="headerlink" title="附件5 国际生须知"></a>附件5 国际生须知</h1><h2 id="一、出国前"><a href="#一、出国前" class="headerlink" title="一、出国前"></a>一、出国前</h2><h3 id="1-入境"><a href="#1-入境" class="headerlink" title="1. 入境"></a>1. 入境</h3><p>国际生如果想进入新加坡需要有效护照。对于全日制学生，学校会通过学生准证在线申请和注册系统(Student Pass On-Line Application &amp; Registration, <code>SOLAR</code>)为他们申请学生准证(Student Pass, <code>STP</code>)，该系统由移民与关卡局(Immigration &amp; Checkpoints Authority, <code>ICA</code>) 管理。如果学生接受了offer，我们会写信告诉他们如何完成最后的申请步骤。获得条件型offer(con offer)的学生需要在收到满足入学要求的确认后，才能开始申请学生准证。ICA会收取S$30的手续费。学生必须在提交<code>eForm 16</code>时通过信用卡或国际银行缴纳费用。如果没有付款，ICA将不处理该申请，申请将在SOLAR中继续等待。即使学生撤销申请，费用也不会退还。如果学生在提交了eForm 16、缴纳了申请费后发现姓名或者申请时期有误，需要重新申请并重新缴费。</p>
<p>对于入境需要<code>entry visa</code>的一些国家的同学（具体细节请参考<a href="https://www.ica.gov.sg/visitor/visitor_entryvisa">移民与关卡局</a>）,学校也会通过SOLAR系统为他们申请visa cum student pass。如果申请通过，我们会给他们寄<code>In-Principle Approval信</code>(ICA出具)。入境时，该信需要和有效护照一起递交给移民与关卡局的执勤人员(Duty Officer)。</p>
<p>在新加坡，国际生最快两周会收到<code>居留许可</code>(Social Visit Pass)。在这期间，学生在注册办公室(Registrar’s Office, RO)注册并获得<code>学生注册卡</code>(student registration card)后，必须带着In-Principle Approval信去ICA，换取他的学生准证。ICA官员将在NUS帮助学生完成其学生准则申请手续（日期在serialised信中给出）。未能在指定日期前完成的同学，需要在线预约并前往ICA大楼完成他们的学生准证申请。</p>
<p><strong>重要：只有通过<a href="https://safetravel.ica.gov.sg/stpl/requirements-and-process">STO-STP网站</a>获得<code>入境许可</code>(Entry Approval)以及用于申请学生准证STP的In-Principal Approval(IPA)信(<code>STP-IPA</code>)后，才能安排旅行。</strong></p>
<p>有关STP和STP-IPA持有者的入境和逗留通知，请参考<a href="https://safetravel.ica.gov.sg/stpl/requirements-and-process">这里</a>。</p>
<p>非全日制国际学生不符合学生准证的资格，必须持有有效的就业准证才能留在新加坡。</p>
<p><em><strong>体检</strong></em><br>所有获得用于申请6个月以上学生准证/居留许可的IPA的学生，在获得证件前必须先通过体检。没有通过体检的人会被自费遣返。<strong>国际生需要在他们的国家完成体检。</strong> 国际生需要要求医师完成两份体检报告(<code>NUS入学体检表</code>和ICA体检表)，但是只需要做一次体检。详情请参考附件3.</p>
<p>全日制研究生的配偶和/或子女(未婚且年龄在17岁以下)可以得到学校的资助，获得居留许可后留在新加坡。研究生须在大学注册并取得学生准证后才可提交申请。详情参考<a href="http://www.nus.edu.sg/registrar/administrative-policies-procedures/graduate/social-visit-pass-for-spouse-and-child-of-full-time-graduate-research-students">这里</a>。</p>
<p>有关入境事宜的详情，可以参考<a href="http://www.ica.gov.sg/">移民与关卡局官网</a>。</p>
<h3 id="2-入学"><a href="#2-入学" class="headerlink" title="2. 入学"></a>2. 入学</h3><p>请带上你的offer信，护照/身份证，学历证明(Education Certificates)和其他寄给你的必要文件（如果你在离开你的国家前收到他们的话）。</p>
<p>根据学校电子邮件的要求，在规定时间内到报到地点完成报到。</p>
<h3 id="3-资产"><a href="#3-资产" class="headerlink" title="3. 资产"></a>3. 资产</h3><p>在新加坡，新币(Singapore dollars, S$) 是当前使用的币种。1 dollars=100 cents。你带入新加坡的国际货币和旅行支票(traveller’s cheques)没有额度限制。你可以以<code>银行汇票(bank draft)</code>的形式带上一笔可观的钱，用于学费和住宿费用。大多数国际信用卡都是可以用的（比如American Express, Diners, Visa, MasterCard）。</p>
<p>请准备足够的现金，以支付旅行、交通、临时住宿和来时的生活开销（比如餐饮）。如果你带了现金，但是不能在你的国家换成新币，你可以到<code>Changi机场</code>的银行兑换柜台进行兑换，该柜台向所有航班开放。或者，你可以去银行或者外币兑换处(licensed money changer)。有关生活费的预算，请参考后面的第5条。此外，你需要研究向新加坡银行转账的程序，购买旅行支票,如有需要，准备好信用卡。最好使用在新加坡有分行的银行开具的新币银行汇票。请注意，海外银行开具的银行汇票大约需要3周才能兑现。</p>
<h3 id="4-私人物品"><a href="#4-私人物品" class="headerlink" title="4. 私人物品"></a>4. 私人物品</h3><ol>
<li>带上一打护照大小的照片(35mm x 43mm)。</li>
<li>非正式的轻便服装。值得一提的还是购物中心的衣服价格还算合理。</li>
<li>照相机、吹风机、洗漱用品、闹钟、雨伞、浴巾和计算器。可以自己带也可以在这里买，价格相对便宜。<strong>新加坡电压：230 volts, 50 cycles。</strong></li>
<li>请注意，违禁文献、管控药品、版权作品和音频(CSs/VCDs/DVDs)的复印版，一旦发现会被海关没收。电影、录像、磁带、书籍、报纸、杂志只有在获得有关部门的进口许可证或授权后才能进入。</li>
</ol>
<h3 id="5-生活费预算"><a href="#5-生活费预算" class="headerlink" title="5. 生活费预算"></a>5. 生活费预算</h3><p>除了学费，国际学生每月的开销预算如下：</p>
<table>
<thead>
<tr>
<th align="left">类别</th>
<th align="left">开销</th>
<th align="left">金额</th>
</tr>
</thead>
<tbody><tr>
<td align="left">住宿</td>
<td align="left">校内(每学期)：<br>NUS研究生宿舍 PGPR/GDR/<a href="http://www.nus.edu.sg/ohs/properties/utown/units_gr.php">uTown</a> <br><br><a href="http://www.nus.edu.sg/osa/has/other-accommodation">校外</a>(每月)：<br>租屋租金<br>公寓租金</td>
<td align="left">s$1980-6480（详情请参考<a href="http://www.nus.edu.sg/osa/has/graduate/hostel-rates">这里</a>）<br><br><br><br>S$500-800 <br>S$1800-2500</td>
</tr>
<tr>
<td align="left">食品(每月)</td>
<td align="left">学校食堂/美食街(Food Courts)<br>校外餐饮</td>
<td align="left">S$250-400<br>S$400-800</td>
</tr>
<tr>
<td align="left">书籍/材料(每月)</td>
<td align="left">取决于所学课程</td>
<td align="left">S$200-350</td>
</tr>
<tr>
<td align="left">交通(每月)</td>
<td align="left">公交/MRT</td>
<td align="left">S$200-300</td>
</tr>
<tr>
<td align="left">私人开销(每月)</td>
<td align="left">洗漱化妆、衣服、生活用品、娱乐等</td>
<td align="left">S$250-350</td>
</tr>
<tr>
<td align="left">学生杂费(每学期)(含GST)</td>
<td align="left">学生服务费SSF(Lab-Based)<br>健康服务费HSF</td>
<td align="left">S$176.45(全日制)/132.15(非全日制)<br>S$67.95</td>
</tr>
</tbody></table>
<h3 id="6-住宿"><a href="#6-住宿" class="headerlink" title="6. 住宿"></a>6. 住宿</h3><p>国际生可以考虑住在NUS研究生宿舍或者校外的私人住所。</p>
<p>如果想申请NUS研究生宿舍，可以在<a href="http://nus.edu.sg/osa/has">这里</a>查看相关信息并完成在线注册。学生之后可以通过线上大学宿舍管理系统(UHMS)查看他们的申请结果。如果申请人在提交在线申请时遇到困难，可以在<a href="http://www.hosteladmission.nus.edu.sg/app/utils/login_form/redirect/ask">这里</a>提交你的问题。</p>
<p>如果想找校外的私人住所，可以在<a href="http://nus.edu.sg/osa/has/other-accommodation">这里</a>获取一些有用的联系方式。</p>
<p>如果你在住宿服务方面需要帮助，可以看看<a href="http://www.nus.edu.sg/osa/has">学生事务办公室网站</a>或者在<a href="http://www.hosteladmission.nus.edu.sg/app/utils/login_form/redirect/ask">这里</a>提交你的问题。</p>
<h2 id="二、抵达新加坡"><a href="#二、抵达新加坡" class="headerlink" title="二、抵达新加坡"></a>二、抵达新加坡</h2><h3 id="1-海关申报表"><a href="#1-海关申报表" class="headerlink" title="1. 海关申报表"></a>1. 海关申报表</h3><p>完成<code>海关申报表(Customs Declaration form)</code>，你会在飞机上收到该表，请认真填写不要有遗漏。到达新加坡机场后，你要将该表和护照一起交给移民局官员(Immigration Officers)。</p>
<h3 id="2-相关通知"><a href="#2-相关通知" class="headerlink" title="2. 相关通知"></a>2. 相关通知</h3><p>有关学生准证STP和STP-IPA持有者的入境和居留通知，请参考<a href="https://safetravel.ica.gov.sg/stpl/requirements-and-process">这里</a>获取详细信息。</p>
<h2 id="三、前往NUS-Kent-Ridge"><a href="#三、前往NUS-Kent-Ridge" class="headerlink" title="三、前往NUS(Kent Ridge)"></a>三、前往NUS(Kent Ridge)</h2><p>NUS(Kent Ridge)</p>
<ol>
<li>从Changi机场</li>
</ol>
<ul>
<li><p>乘坐地铁(MRT)。</p>
<p>从Changi Airport站出发，乘坐开往Joo Koon的列车（西线）。在Clementi MRT站下车。然后走到Clementi公交车换乘站，乘坐96路公交车前往校园。</p>
<p><strong>注意：MRT规定乘客行李不能超过81cm x 58cm x30cm。</strong></p>
</li>
<li><p>乘坐出租车。</p>
<p>车费大约S$30。如果从机场出发，需要额外收取S$3.5-5。从午夜到6 a.m.，需要加收计费表上50%的深夜附加费。高峰期和公共假期的附加费也是如此。更多细节请参考<a href="https://www.cdgtaxi.com.sg/web/corp/ride-with-us/fares">这里</a>。</p>
</li>
</ul>
<ol start="2">
<li>从公交总站(对于来自Malaysia的公交)</li>
</ol>
<ul>
<li><p>Golden Mile 购物中心(Beach Road)</p>
<p>走到Victoria街(10min)，乘坐33路公交车前往校园。在Clementi路上的工程学院下车。</p>
</li>
<li><p>Ban San街</p>
<p>走到Victoria街，乘坐33路公交车前往校园。在Clementi路上的工程学院下车。</p>
<p>或者，走到Bugis MRT站，乘坐列车前往Clementi MRT站，然后在Clementi公交换乘点乘坐96路公交车前往校园。</p>
</li>
<li><p>Kallang Bahru / Lavender Street Junction</p>
<p>走到Lavender MRT站，乘坐MRT前往Clementi MRT站，再乘坐96路公交车前往校园。</p>
</li>
</ul>
<ol start="3">
<li><p>从Railway站<br>从Woodlands Train Checkpoint乘坐911/913路公交车前往Woodlands MRT站，乘坐MRT前往Clementi MRT站，然后走到CLementi公交换乘点乘坐96路公交车前往校园。</p>
</li>
<li><p>从Mass Rapid Transit(MRT)站<br>从Clementi MRT站走到Clementi公交换乘点，然后坐96路公家车前往NUS。</p>
</li>
</ol>
<h2 id="四、抵达NUS"><a href="#四、抵达NUS" class="headerlink" title="四、抵达NUS"></a>四、抵达NUS</h2><ol>
<li><p>按照计划入住您的住处或者亲友的家。</p>
</li>
<li><p>Register：在预定的时间和地点报到，领取<code>学生注册卡(Student Registration Card)</code>。</p>
</li>
<li><p>报到后，你需要在你的<code>居留许可Social Visit Pass</code>到期前至少4个工作日，前往一下任一地点申请<code>学生准证</code>。</p>
<ul>
<li><p>ICA booth</p>
<ul>
<li><p><strong>多功能体育馆1(Multi-Purpose Sports Hall 1, MPSH1)-临时</strong></p>
</li>
<li><p>为OSE(Off Site Enrolment)准备的文件清单如下:</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210515174608.png"></p>
</li>
</ul>
</li>
<li><p>Student’s Pass Issuance</p>
<ul>
<li>日期：2021 8.12&amp;13</li>
<li>时间：9:00 am-12:30 pm；2:00 pm-5:00 pm（8.13下午4:30提前结束）</li>
<li>地点Venue：MPSH1</li>
</ul>
</li>
<li><p>ICA</p>
<ul>
<li>ICA大楼 4th Storey, 10 Kallang Road Singapore 208718</li>
<li>电话：63916100</li>
<li>网址：<a href="http://www.ica.gov.sg/">http://www.ica.gov.sg/</a></li>
</ul>
</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left">注意事项</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">如在2021.7.26-30在MPSH1-临时报到点报到，需要在OSE在线预约系统(Online Appointment Booking System for OSE)上提前预约日期和时间</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">在申请学生准证前，在<a href="https://eservices.ica.gov.sg/solar/index.xhtml">SOLAR网站上</a>完成付款并打印<a href="https://www.ica.gov.sg/reside/STP/apply/ihl">收据</a>；带上收据和其他ICA要求的文件、以及符合ICA<a href="https://www.ica.gov.sg/common/photo-guidelines">照片要求</a>的照片</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">学生没有在预约时间到达或者没有带<a href="https://www.ica.gov.sg/pass/studentpass/ihl">ICA要求的文件和收据</a>的会被拒绝</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">在OSE, MPSH1, 2021.7.26-30期间，也提供付费的摄影、复印、打印服务</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left">错过预约的学生，或者没有按时取得体检报告，亦或是申请学生准证后计划离开新加坡的学生，建议通过<a href="https://icaeservices.ica.gov.sg/ibook/index.do">线上预约</a>在ICA总部申请他们的学生准证</td>
</tr>
<tr>
<td align="left">6</td>
<td align="left">ICA会登记申请人的虹膜图像，请不要佩戴有色、有图案、装饰作用的隐形眼镜。学生需要摘下眼镜，方可拍摄红膜图像</td>
</tr>
<tr>
<td align="left">7</td>
<td align="left">在前往ICA大楼前，需要在<a href="https://eservices.ica.gov.sg/solar/index.xhtml">ICA网站</a>上进行线上预约。你的护照将在一周内退回，此外还要带上你的IPA信(须有大学认可)</td>
</tr>
</tbody></table>
<p>以下列出申请学生准证时需要提交的材料：</p>
<ul>
<li>在SOLAR上提交的eForm 16的打印版(要求签名并附上1张近期拍摄的护照大小的白底彩色照片)</li>
<li>有效护照和居留许可(Social Visit Pass)</li>
<li>离机/入境卡(Disembarkation/Embarkation Card)—进入新加坡时获得</li>
<li>IPA信</li>
<li>学生登记卡(Student Registration Card)</li>
<li>ICA体检表 &amp; 实验室报告(包括X-光合HIV血检报告)</li>
<li>学生准证的条款 &amp; 条件(Term &amp; Condition)的复印件</li>
<li>费用<ul>
<li>手续费：S$30</li>
<li>发证费：S$60</li>
<li>更换费 (遗失学生准证时补领)：S$100</li>
<li>多次入境签证(Multiple-Entry Visa) (适用于需要签证的国民)：S$30</li>
</ul>
</li>
</ul>
<p>3.1 延长逗留时间</p>
<p>如果你想在学生准证过期后再在新加坡待一小段时间(少于两周)，你可以在学生准证过期前，通过<code>Visitor Services Centre, ICA(4th Storey)</code>申请居留许可(Social Visit Pass)。你会被要求出示你已确定的机票来证明你的离境时间。</p>
<p>如果你的居留许可到期了，你会被视为在新加坡非法居留，你需要缴纳罚款，否则会被起诉。</p>
<p>3.2 注销Cancellation</p>
<p>如果学生在学校的学习提前终止（比如退学或拒绝再入学），需要带上学生准证，在停止学业后7天内前往ICA办理注销手续。</p>
<p>如果你关于学生准证或居留许可有任何疑问，请咨询学生事务办公室(Office of Student Affairs)的负责国际生服务(ISS)的工作人员，或者发邮件给<code>international@nus.edu.sg</code>。</p>
<ol start="4">
<li><p>在注册办公室(Registrar’s Office)报到后，需到系办公室(Department Office)报到。</p>
<p>（不适用于Biomedical Eng, Civil &amp; Environmental Eng, and Industrial Systems Eng &amp; Management）</p>
</li>
<li><p>向你的导师报到，他可能会提供一些指导或者关于科研的信息。</p>
</li>
<li><p>在跟<code>导师/系里</code>讨论过你应该参加的课程类型后，在系办公室处拿<code>lectures时间表</code>。</p>
</li>
<li><p>在你选择的银行开户。详见下述的”其他事务”部分。</p>
</li>
<li><p>参加<code>Orientations</code>：</p>
<ol>
<li>工程学院副院长关于硕博项目的<code>Orientation Talk</code>（具体细节之后会邮件通知）。</li>
<li>国际生Orientation（请关注学生事务办公室网站上的相关内容<a href="http://nus.edu.sg/osa/student-life/international-students/briefing%EF%BC%89%E3%80%82">http://nus.edu.sg/osa/student-life/international-students/briefing）。</a></li>
<li>图书馆Orientation，熟悉学校的设备和服务。</li>
</ol>
</li>
</ol>
<h2 id="五、其他事务"><a href="#五、其他事务" class="headerlink" title="五、其他事务"></a>五、其他事务</h2><h3 id="1-保险"><a href="#1-保险" class="headerlink" title="1. 保险"></a>1. 保险</h3><p>研究生保险计划(Graduate Insurance Scheme)是所有全日制国际生都必须参加的。</p>
<p><strong>COVID-19 保险</strong><br><a href="http://nus.edu.sg/uhc/docs/default-source/insurance/frequently-asked-questions-on-covid-19.pdf">保险范围</a></p>
<h3 id="2-医疗"><a href="#2-医疗" class="headerlink" title="2. 医疗"></a>2. 医疗</h3><p>UHC(University Health Centre)的诊所提供医疗服务。此外，Government Polyclinic、Outpatient Dispensary也提供医疗服务。</p>
<h3 id="3-大使馆-高级委员会登记"><a href="#3-大使馆-高级委员会登记" class="headerlink" title="3. 大使馆/高级委员会登记"></a>3. 大使馆/高级委员会登记</h3><p>抵达新加坡后，学生可以向其<code>驻新加坡大使馆/高级委员会</code>报到。在离家前，学生可以了解一下其驻新加坡大使馆/高级委员会(High Commission)提供的设施和服务的相关信息。</p>
<h3 id="4-银行"><a href="#4-银行" class="headerlink" title="4. 银行"></a>4. 银行</h3><p>银行通常在周一至周五的8:30 am-4:30 pm; 周六的8:30 am-1:00pm营业。</p>
<p>学校附近的银行(Clementi Branch)：</p>
<ul>
<li><p>Development Bank of Singapore (DBS)</p>
<p> Blk 450, Clementi Avenue 3</p>
<p> #01-293/295</p>
<p> Singapore 120450</p>
<p> Tel: (65) 1800-111 1111</p>
</li>
<li><p>United Overseas Bank (UOB)</p>
<p> Blk 450, Clementi Avenue 3</p>
<p> #01-287/289</p>
<p> Singapore 120450</p>
<p> Tel: (65) 1800-222 2121</p>
</li>
<li><p>Post Office Savings Bank (POSB)</p>
<p> Blk 449, Clementi Avenue 3</p>
<p> #01-243</p>
<p> Singapore 120449</p>
<p> Tel: (65) 6339 6666</p>
</li>
<li><p>Oversea-Chinese Banking     Corporation (OCBC)</p>
<p> 3155 Commonwealth Avenue West</p>
<p> #04-52/55</p>
<p> The Clementi Mall</p>
<p> Singapore 129588</p>
<p> Tel: (65) 6530 5930</p>
</li>
</ul>
<p>校内的ATMs分别位于</p>
<ul>
<li>Faculty of Arts &amp; Social Sciences (LT9附近)</li>
<li>Faculty of Science (LT27和S16外面，Science Canteen附近)</li>
<li>Yusof Ishak House (Level 3)</li>
<li>National University Hospital</li>
</ul>
<h3 id="5-国际生服务ISS"><a href="#5-国际生服务ISS" class="headerlink" title="5. 国际生服务ISS"></a>5. 国际生服务ISS</h3><p>ISS部门的建立是为了监督国际生在大学的福利。有关入境immigration、财务、学业、社交、健康、招聘和其他事务，该部门能提供咨询和帮助。国际生的个人问题也能得到其关注。</p>
<p>如果需要更多信息和帮助，可以联系他们：</p>
<ul>
<li>电话：(65) 6516 4817</li>
<li>传真：(65) 6778 5902</li>
<li>邮箱：<a href="mailto:international@nus.edu.sg">international@nus.edu.sg</a></li>
</ul>
<p>有关国际生迎新简报会、文化活动、离校简报会以及社会活动等项目的一般问题：</p>
<ul>
<li>Mr Alvin Wong </li>
<li>邮箱：<a href="mailto:Alvin.wong@nus.edu.sg">Alvin.wong@nus.edu.sg</a></li>
<li>地址：International Student Services, Office of Student Affairs (3rd Storey, Yusof Ishak House)<br>National University of Singapore<br>31 Lower Kent Ridge Road, Singapore 119078</li>
<li>网站：<a href="http://www.nus.edu.sg/osa/">http://www.nus.edu.sg/osa/</a></li>
<li>工作时间: <ul>
<li>周一至周四 8.30 am – 6.00 pm</li>
<li>周五 8.30 am –– 5.30 pm</li>
<li>周末及季节日不工作</li>
</ul>
</li>
</ul>
<h2 id="六、出发前核对清单"><a href="#六、出发前核对清单" class="headerlink" title="六、出发前核对清单"></a>六、出发前核对清单</h2><h3 id="1-完成表格"><a href="#1-完成表格" class="headerlink" title="1. 完成表格"></a>1. 完成表格</h3><p>在规定的截止日期前，完成录取材料并把它交给注册办公室Registrar’s Office。</p>
<h3 id="2-重要文件"><a href="#2-重要文件" class="headerlink" title="2. 重要文件"></a>2. 重要文件</h3><ul>
<li>有效签证 &amp; 雇佣证明(仅适用于非全日制)</li>
<li><strong>通过<a href="https://safetravel.ica.gov.sg/stpl/requirements-and-process">STO-STP网站</a>和IPA信(如果需要的话)获得入境许可(Entry Approval)</strong></li>
<li>原始成绩单</li>
<li>出生证明/护照</li>
<li>offer信</li>
<li>等</li>
</ul>
<h3 id="3-申请宿舍"><a href="#3-申请宿舍" class="headerlink" title="3. 申请宿舍"></a>3. 申请宿舍</h3><p>在线提交宿舍申请，收到OSA(住宅服务)发的有关分配结果的邮件。有关住宿的具体细节可以参考 <a href="http://www.nus.edu.sg/osa/has%E3%80%82">http://www.nus.edu.sg/osa/has。</a></p>
<h3 id="4-工作日或周末后到达"><a href="#4-工作日或周末后到达" class="headerlink" title="4. 工作日或周末后到达"></a>4. 工作日或周末后到达</h3><p>如果你成功申请到了硕博生宿舍，请将你的预计到达日期和时间告知你所分配到的住处，并安排延迟入住(如果必要)。如果未能申请到宿舍，请提前安排好youth hostle, hotel或者亲友家之类的住所。</p>
<h3 id="5-国际生介绍会"><a href="#5-国际生介绍会" class="headerlink" title="5. 国际生介绍会"></a>5. 国际生介绍会</h3><p>请注意，国际生可以参加<a href="http://nus.edu.sg/osa/student-life/international-students/briefing">OSA网站</a>上的国际生Orientation电子简报会。根据我们的经验，参加了该介绍会的学生，在后续的适应和居住方面会少些困难。</p>
<h3 id="6-Visa需求"><a href="#6-Visa需求" class="headerlink" title="6. Visa需求"></a>6. Visa需求</h3><p>仅适用于<a href="http://www.ica.gov.sg/">ICA网站</a>上所列出的国家</p>
<p>如果你来自有visa需求的国家，需要通过SOLAR完成visa的线上申请，并打印Form 16。请与你的入境部门确认你是否需要申请出境visa。</p>
<p><strong>提交form16后，如果审核通过，你会收到进入新加坡所需的IPA(In-Principal Approval)信。</strong></p>
<h3 id="7-行程安排"><a href="#7-行程安排" class="headerlink" title="7. 行程安排"></a>7. 行程安排</h3><p>通过信誉良好的traval agency安排你的行程，在offer信中给出的规定日期抵达。</p>
<p>如果有必要，填好并上交更改报到日期/时间的表格。</p>
<h3 id="8-免疫检查-可选"><a href="#8-免疫检查-可选" class="headerlink" title="8. 免疫检查(可选)"></a>8. 免疫检查(可选)</h3><p>根据世界卫生组织WHO的规定，在新加坡旅行、居住需要接受防疫要求。你可能需要带上你的医疗记录、眼科处方、或药品信息的副本。</p>
<h3 id="9-居家通知和检测制度"><a href="#9-居家通知和检测制度" class="headerlink" title="9. 居家通知和检测制度"></a>9. 居家通知和检测制度</h3><p>Stay-Home Notice and Testing Regime</p>
<p>请参考<a href="https://safetravel.ica.gov.sg/stpl/requirements-and-process">这里</a>获得更多有关学生准证STP和STP-IPA持有者的入境许可及居家通知的相关信息。</p>
<h3 id="10-体检"><a href="#10-体检" class="headerlink" title="10. 体检"></a>10. 体检</h3><p>申请学生准证和入学前体检都需要一份体检报告。该报告必须以英文形式完成。你可以选择在新加坡或者在本国完成体检。体检报告不得早于提交前三个月以上出具。（请参考附件3获取更多信息）</p>
<h3 id="11-医保"><a href="#11-医保" class="headerlink" title="11. 医保"></a>11. 医保</h3><p>根据个人需要，在NUS就读期间，你可以参加额外的医疗保险。对于全日制学生而言，除非有其他医疗/保险计划的证明，否则必须参加NUS的<code>health insurance scheme</code>。更多详情请参考<a href="http://www.nus.edu.sg/uhc/services/billing-insurance/insurance-matters">这里</a>。</p>
<h3 id="12-财务准备"><a href="#12-财务准备" class="headerlink" title="12. 财务准备"></a>12. 财务准备</h3><p>请准备好足够的金钱带去新加坡，包含旅行开销、临时居住和抵达后的生活费。（详情请参考page 2的Int’l Students for estimated cost）</p>
<p>研究如何向新加坡银行转账的程序。如有需要，可以购买旅行支票(traveller’s cheques)、准备信用卡。最好选择在新加坡有分行的银行开具新加坡币的银行汇票(bank draft)。汇票上需要印有新加坡分行地址。请注意，向海外银行开出的银行汇票需要大约3周才能兑现。</p>
<p><em>注意：(可选)你可能希望安排personal and credit references，这在租房和在银行开户等方面都很有用</em></p>
<h3 id="七、注意事项"><a href="#七、注意事项" class="headerlink" title="七、注意事项"></a>七、注意事项</h3><ul>
<li><p>更多国际生需注意的信息，请参考<a href="http://www.nus.edu.sg/registrar/academic-activities/registration/information-for-international-students">注册办公室网站</a></p>
</li>
<li><p>鉴于COVID-19，学生需要：</p>
<ul>
<li>查看<a href="https://www.moh.gov.sg/covid-19">卫生部(Ministry of Health, MOH)网站</a>上<code>Measures which apply to Inbound Travelers</code>内容，安排前往新加坡的行程。</li>
<li>定期检查来自NUS的邮件以获得最新通知。</li>
<li>参考以下NUS网站：<ul>
<li>应对COVID-19的其他措施: <a href="https://www.nus.edu.sg/registrar/academic-activities/registration/administrative-matters">RO网站</a></li>
<li><a href="https://emergency.nus.edu.sg/">OSHE网站</a></li>
<li>关于保险: <a href="https://nus.edu.sg/uhc/general-health/billing-insurance/insurance-matters">UHC网站</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h1 id="附件6-更多信息"><a href="#附件6-更多信息" class="headerlink" title="附件6 更多信息"></a>附件6 更多信息</h1><h2 id="一、候选期"><a href="#一、候选期" class="headerlink" title="一、候选期"></a>一、候选期</h2><p>你的候选人资格于学期第一天(如，2021.8.2)或报到那天（二者取其晚）开始。MEng的候选期最长为3年。EngD或PhD的候选期最长为5年。你的论文提交时间不得晚于最长候选期。</p>
<p>请注意，除非学校同意，否则学生不得同时作一个以上学位的候选人，也不得同时作NUS和其他学校或机构的候选人。</p>
<h2 id="二、居住要求"><a href="#二、居住要求" class="headerlink" title="二、居住要求"></a>二、居住要求</h2><p>不在新加坡居住的候选人必须在候选期内完成居住要求，MEng和EngD/PhD的居住要求分别是6个月和18个月。</p>
<h2 id="三、医保计划"><a href="#三、医保计划" class="headerlink" title="三、医保计划"></a>三、医保计划</h2><p>所有全日制的学生都必须参加团体医保计划，该计划可以帮他们支付由于住院/手术、意外而产生的医疗费用(部分或全部)。对于研究学者(research scholars)，我们将按学期从他们的津贴中扣除保险费。</p>
<p>更多信息请参考<a href="http://www.nus.edu.sg/uhc/services/billing-insurance/insurance-matters">这里</a></p>
<h2 id="四、电子设备"><a href="#四、电子设备" class="headerlink" title="四、电子设备"></a>四、电子设备</h2><p>建议学生带上一台可用的笔记本电脑到学校里使用。因为NUS大部分区域都覆盖免费Wi-Fi，因此电脑将会是有用的。有时，你的课程会要求你使用笔记本电脑并下载资料，以便上课时实操。当然你还需要带上一部手机。</p>
<h2 id="五、手册和论文"><a href="#五、手册和论文" class="headerlink" title="五、手册和论文"></a>五、手册和论文</h2><p>建议你熟悉下列的候选期要求：</p>
<ul>
<li><a href="http://www.nus.edu.sg/registrar/administrative-policies-procedures/graduate/nus-statutes-and-regulations">NUS章程</a>(Statutes of the National University of Singapore)</li>
<li>研究生手册，<a href="https://myportal.nus.edu.sg/studentportal/eng/gd/">下载链接</a></li>
<li><a href="http://www.nus.edu.sg/registrar/administrative-policies-procedures/graduate/acceptance-record#IP">NUS知识产权政策</a>(NUS Intellectual Property Policy)</li>
</ul>
<hr>
<h1 id="附件7-在线答复offer"><a href="#附件7-在线答复offer" class="headerlink" title="附件7 在线答复offer"></a>附件7 在线答复offer</h1><p>这部分已经搞过了，所以简写一下~</p>
<p>在研究生招生系统中在线答复offer：<a href="https://inetapps.nus.edu.sg/GDA2">https://inetapps.nus.edu.sg/GDA2</a></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210519205448.png"></p>
<p>有关研究生招生系统的更多细节请参考以下链接：<a href="https://nus.edu.sg/registrar/docs/info/academic-activities/registration/applicant-guide-for-graduate-admission-system.pdf">Applicant Guide For Graduate Admission System</a></p>
<hr>
<h1 id="附件8-奖学金"><a href="#附件8-奖学金" class="headerlink" title="附件8 奖学金"></a>附件8 奖学金</h1><p><em>仅适用于已获得的学生</em></p>
<ul>
<li>校长奖学金 PRESIDENT’S GRADUATE SCHOLARSHIP</li>
<li>NUS研究型奖学金 NUS RESEARCH SCHOLARSHIP</li>
<li>联邦奖学金 COMMONWEALTH SCHOLARSHIP</li>
</ul>
<p>PhD学生奖学金期限最长为4年。奖学金有效期为1年，每半年/一年需延长一次。然而，奖学金随时可能由于表现不佳而暂停。</p>
<p>2014/15年起，获得NUS研究型奖学金、校长奖学金、联邦奖学金及以下列出的其他财政资助的国际学生，需要满足奖学金条款与条件中所附的<strong>研究生助教计划GAP</strong>的要求。</p>
<table>
<thead>
<tr>
<th align="left">奖学金</th>
<th align="left">条款与条件</th>
</tr>
</thead>
<tbody><tr>
<td align="left">NUS Research Scholarship (with GAP)</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-research-scholarship-terms-conditions/">https://nusgs.nus.edu.sg/nus-research-scholarship-terms-conditions/</a></td>
</tr>
<tr>
<td align="left">NUS Research Scholarship (GAP exempted)</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-research-scholarship-terms-conditions-gap-exempted/">https://nusgs.nus.edu.sg/nus-research-scholarship-terms-conditions-gap-exempted/</a></td>
</tr>
<tr>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-research-scholarship-terms-conditions-gap-exempted/President's">President’s</a> Graduate Fellowship (with GAP)</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/president-graduate-fellowships-terms-conditions/">https://nusgs.nus.edu.sg/president-graduate-fellowships-terms-conditions/</a></td>
</tr>
<tr>
<td align="left">President’s Graduate Fellowship(GAP exempted)</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/president-graduate-fellowship-terms-conditions-gap-exempted/">https://nusgs.nus.edu.sg/president-graduate-fellowship-terms-conditions-gap-exempted/</a></td>
</tr>
<tr>
<td align="left"><a href="https://nusgs.nus.edu.sg/president-graduate-fellowship-terms-conditions-gap-exempted/Commonwealth">Commonwealth</a> Scholarship</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions/">https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions/</a></td>
</tr>
<tr>
<td align="left">Tuition Fee Allowance (GAP exempted)</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions-gap-exempted/">https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions-gap-exempted/</a></td>
</tr>
<tr>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions-gap-exempted/Tuition">Tuition</a> Fee Allowance</td>
<td align="left"><a href="https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions/">https://nusgs.nus.edu.sg/nus-tuition-fee-allowance-terms-conditions/</a></td>
</tr>
</tbody></table>
<p>如果候选人目前有工作，其奖学金只有在他暂停从当前雇主处领取薪水后才开始发放。</p>
<p>如果你在新加坡或马来西亚工作，在你注册前请提交一封信说明你最后一天的工资。这封信应该是你的雇主所写，或者是你给雇主的辞职信的副本。建议你在雇佣期的最后一天后再进行注册。否则，你会被认为是自费生，并被要求支付学费。</p>
<p>如果你希望被录取到大学的全日制研究型项目，而你正在接受奖学金或奖金，亦或是你已经获得了scholarship/award for which you are bonded，你需要取得有关部门的批准并向我们提交相关证明文件。</p>
<p>学生需要在新加坡的银行开户。不同的银行有不同的要求，也有不同类型的储蓄和支票账户。如果想获得更多信息，请浏览各自银行的网站。当你决定好在哪个银行开户时，请确保你带了足够的现金来支付费用。以下是你开户所需的文件：</p>
<ul>
<li>护照(原版和影印版)</li>
<li>学生准证 或 STP-IPA信(In-Principle student’s pass approval letter)</li>
<li>学生卡(如果有的话) 或者 来自NUS的录取通知(Offer Letter of Admission)</li>
<li>最低限度的初始存款(具体多少取决于银行的要求)</li>
</ul>
<p>已获得奖学金的学生，需要在<a href="https://myedurec.nus.edu.sg/">Education Records System (EduRec)</a>更新你的信用银行账户信息，以避免延迟发放奖学金。</p>
<p>有关银行开户的更多信息，请参考学生事务办公室网页: <a href="http://www.askstudentservice.nus.edu.sg/app/answers/detail/a_id/2042">http://www.askstudentservice.nus.edu.sg/app/answers/detail/a_id/2042</a></p>
<p>如果你在规定的日期完成注册，你会在2021.8.31收到第一笔津贴。如果没有，你就只能再2021.9.18收到8月和9月份的津贴。建议国际生在收到津贴前带些钱(支付1-1.5个月的开销)。</p>
<p>有关生活费的预算请参考附件5。</p>
<hr>
<h1 id="附录9-其他"><a href="#附录9-其他" class="headerlink" title="附录9 其他"></a>附录9 其他</h1><table>
<thead>
<tr>
<th align="left">部门/项目办公室</th>
<th align="left">位置</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Office of Graduate Programmes, Faculty of Eng[1]</td>
<td align="left">EA 06-16</td>
</tr>
<tr>
<td align="left">Biomedical Eng[3]</td>
<td align="left">E4 04-08</td>
</tr>
<tr>
<td align="left">Chemical &amp; Biomolecular Eng[4]</td>
<td align="left">E5 02-09</td>
</tr>
<tr>
<td align="left">Civil &amp; Env Eng[2]</td>
<td align="left">E1A 07-03</td>
</tr>
<tr>
<td align="left">Electrical &amp; Computer Eng[3]</td>
<td align="left">E4 05-45</td>
</tr>
<tr>
<td align="left">Industrial Systems Eng &amp; Management[2]</td>
<td align="left">E1A 06-25</td>
</tr>
<tr>
<td align="left">Materials Science &amp; Eng[1]</td>
<td align="left">EA 03-09</td>
</tr>
<tr>
<td align="left">Mechanical Eng[1]</td>
<td align="left">EA 07-08</td>
</tr>
</tbody></table>
<ul>
<li><p>University Health Centre[5]    </p>
<ul>
<li>UHC Clinic (medical examination)</li>
</ul>
</li>
<li><p>Yusof Ishak House[6]</p>
<ul>
<li>Level 1: Student Service Centre (paying fees)</li>
<li>Level 3: Office of Student Affairs (apply student pass)</li>
</ul>
</li>
<li><p>E6 Techno Edge Canteen</p>
</li>
<li><p>EW1 Engineering Workshop 1</p>
</li>
<li><p>EW2 Engineering Workshop 2</p>
</li>
</ul>
<p><strong>NUS Faculty of Engineering, 10 Kent Ridge Crescent</strong></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210520004227.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210520004411.png"></p>
<h2 id="一、地图"><a href="#一、地图" class="headerlink" title="一、地图"></a>一、地图</h2><p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/blog_files/img/Pic-Github/OpenGLconfig/20210520004643.png"></p>
<p><a href="http://www.nus.edu.sg/campusmap/">最新地图</a></p>
<p><a href="http://www.nus.edu.sg/oca/Transport-and-Parking/Getting-around-NUS.html">校内班车 internal shuttle bus services</a></p>
]]></content>
      <categories>
        <category>留学</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>NUS</tag>
      </tags>
  </entry>
  <entry>
    <title>论文笔记：paying more attention to attention</title>
    <url>/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%9Apaying-more-attention-to-attention/</url>
    <content><![CDATA[<h2 id="Paying-more-attention-to-attention-improving-the-performance-of-convolutional-neural-networks-via-attention-transfer"><a href="#Paying-more-attention-to-attention-improving-the-performance-of-convolutional-neural-networks-via-attention-transfer" class="headerlink" title="Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer"></a>Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer</h2><h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><h2 id="1）-NLP："><a href="#1）-NLP：" class="headerlink" title="1） NLP："></a>1） NLP：</h2><p>自然语言处理</p>
<h2 id="2）-encoder-decoder："><a href="#2）-encoder-decoder：" class="headerlink" title="2） encoder-decoder："></a>2） encoder-decoder：</h2><p>   编码器：现实问题转化为数学问题；</p>
<p>   解码器：求解数学问题，并转化为现实世界的解决方案；</p>
<p>   <img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/SLAM/20210912005008.png"></p>
<ul>
<li>主要应用：文字-文字；音频-文字；图片-文字</li>
<li>主要问题：中间向量长度必须固定，导致输入信息过长时会丢失部分信息。</li>
<li>解决方案：attention机制，中间向量被编码成了一个向量的序列：</li>
</ul>
<pre><code>![](https://raw.githubusercontent.com/OrderAngel/Picture/main/study/SLAM/20210912005634.png)
</code></pre>
<h2 id="3）-seq2seq："><a href="#3）-seq2seq：" class="headerlink" title="3） seq2seq："></a>3） seq2seq：</h2><p>encoder-decoder的一种。输入一个序列，输出另一个序列；这两个序列的长度都可变</p>
<h2 id="4）-attention"><a href="#4）-attention" class="headerlink" title="4） attention"></a>4） attention</h2><p>   attention最早是2014年neural machine translation中提出的，该文章在seq2seq中引入attention，将attention分为soft attention和hard attention两种。</p>
<p>   <a href="https://www.bilibili.com/video/BV1Wi4y1b7NS">李宏毅 attention based model</a></p>
<p>   <a href="https://www.zhihu.com/question/68482809">参考</a></p>
<p>   <a href="https://zhuanlan.zhihu.com/p/91839581">一文看懂 Attention（本质原理+3大优点+5大类型）</a></p>
<p>   在人类的视觉系统中，attention机制是将有限的注意力集中在重点信息上，从而节省资源，快速获得最有效的信息。</p>
<p>   在AI领域，attention最早在cv里用，后来伴随着BERT和GPT的优秀在NLP领域大放异彩。</p>
<ul>
<li><p>优点：</p>
<ul>
<li>参数少</li>
<li>速度快</li>
<li>效果好</li>
</ul>
</li>
<li><p>原理：</p>
<p> <img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/SLAM/20210912105322.png"></p>
<p> 第一步：query和key计算相似度得到权值</p>
<p> 第二步：将权值归一化得到可用的权重</p>
<p> 第三步：将权重和value加权求和</p>
</li>
<li><p>类型：</p>
<p> <img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912105629.png"></p>
<p> 值得一提的是其中的<code>CNN+Attention</code>：</p>
<p> 首先我们先分析一下CNN：CNN的卷积操作可以提取重要特征，attention差不多也是这种思想，但是CNN的卷积感受野是局部的，需要叠很多层去扩大视野。此外，CNN中的max pooling直接提取数值最大的特征，有点像hard attention的直接选中某特征。</p>
<p> 将Attention机制引入CNN：（以2016年的<a href="https://zhuanlan.zhihu.com/p/48254913">ABCNN</a>为例和attention pooling）</p>
<ol>
<li><p>在卷积操作前做attention。比如attention-based BCNN-1，这个任务是文本蕴含任务需要处理两段文本，同时对两段输入的序列向量做attention，计算出特征向量，再拼接到原始向量中，作为卷积层的输入（等于卷积层的输入多了一些两段input的attention信息）</p>
</li>
<li><p>在卷积操作后做attention。</p>
<p>比如在ABCNN-2中，对两段文本的卷积层的输出做attention，作为pooling层的输入。</p>
</li>
<li><p>在pooling层做attention来取代max pooling。</p>
<p>比如attention pooling，首先用LSTM学习到一个比较好的句向量作为query，然后用CNN学习到一个特征矩阵key，再用query对key计算权重，进行attention，得到最后的句向量。</p>
</li>
</ol>
<ul>
<li>attention在CNN上的应用主要分为两种：spatial attention和channel attention。</li>
</ul>
<p> <code>纯attention</code>：比如attention is all you need里面的transformer，用的是self-attention</p>
</li>
</ul>
<h2 id="5）-CNN"><a href="#5）-CNN" class="headerlink" title="5） CNN"></a>5） CNN</h2><p>   <a href="https://zhuanlan.zhihu.com/p/251068800">CNN卷积核与通道讲解</a></p>
<h2 id="6）-transformer"><a href="#6）-transformer" class="headerlink" title="6） transformer"></a>6） transformer</h2><p>   encoder-decoder结构.</p>
<p>   由于RNN不能做并行，而CNN只能部分的提特征(除非叠很多层)，故使用self-attention来替代RNN。</p>
<p>   transformer，在原先的seq2seq中加入attention机制</p>
<p>   以前用seq2seq的地方都可以用transformer来替代。</p>
<p>   transformer进阶：使用multi-head self-attention；universal transformer…</p>
<p>   transformer也不是只能用在文字上，cv上也可以，比如self-attention GAN</p>
<p>   <a href="https://www.bilibili.com/video/av56239558">李宏毅-Transformer</a></p>
<p>   <a href="https://www.bilibili.com/video/BV19t411S74Z">【Transformer】Attention Is All You Need</a></p>
<h2 id="7）-知识蒸馏"><a href="#7）-知识蒸馏" class="headerlink" title="7） 知识蒸馏"></a>7） 知识蒸馏</h2><p><a href="https://www.bilibili.com/s/video/BV1s7411h7K2">神经网络知识蒸馏 Knowledge Distillation</a></p>
<p>步骤：</p>
<ol>
<li>采用传统的方式训练一个教师网络</li>
<li>建立学生网络模型，模型的输出采用传统的softmax函数，拟合目标为one-hot形式的训练集输出，输出和目标之间的距离记为loss1</li>
<li>将训练完成的教师网络的softmax分类器加入温度参数，作为具有相同温度参数softmax分类器的学生网络的拟合目标，将教师与学生网络的温度版softmax分类器之间的距离记为loss2</li>
<li>引入参数$\alpha$，将训练的损失函数设为$loss1*(1-\alpha)+loss2*\alpha$，训练网络</li>
</ol>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913144723.png"></p>
<p>  <img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913144841.png"> 其中CE为交叉熵。</p>
<p>可见t与平缓程度相关，增大t可以放大教师网络的暗知识；$\alpha$与学生网络训练时参考教师网络蒸馏来的知识的比重有关，该值越大，越依赖教师网络的暗知识。</p>
<h2 id="8）spatial-attention-和-channel-attention"><a href="#8）spatial-attention-和-channel-attention" class="headerlink" title="8）spatial attention 和 channel attention"></a>8）spatial attention 和 channel attention</h2><p><a href="https://blog.csdn.net/u014134327/article/details/109669042">Spatial Attention和Channel Attention的个人理解</a></p>
<p><a href="https://blog.csdn.net/weixin_42560055/article/details/85225111">参考2</a></p>
<p>attention机制本质上是学习一个权重分布，再拿这个权重分布施加在原来的特征图上，简单来讲：</p>
<p>(1) 这个加权可以是保留所有分量均做加权—soft attention；也可以是在分布中以某种采样策略选取部分分量—hard attention；</p>
<p>(2) 这个加权可以作用在空间尺度上，给不同的区域加权—spatial attention；也可以作用在channel尺度上，给不同的通道特征加权—channel attention；还可以给特征图上每个元素加权；</p>
<p>(3) 这个加权可以作用在不同时刻历史特征上，如machine translation</p>
<h2 id="9）迁移学习Transfer-learning"><a href="#9）迁移学习Transfer-learning" class="headerlink" title="9）迁移学习Transfer learning"></a>9）迁移学习Transfer learning</h2><p>知识蒸馏被广泛应用于模型压缩和迁移学习中，常见的迁移学习方式就是在一个大的数据集上先做预训练，然后使用预训练得到的参数在一个小的数据集上做微调（两个数据集往往领域不同或者任务不同）</p>
<p>例如：在联邦广告中，先通过大量曝光和点击数据进行 CTR 建模（大的数据集），然后通过知识蒸馏，将这部分信息迁移到 CVR 模型中（小的数据集）</p>
<h2 id="10）关于DL里面各种classifier线性层的称谓："><a href="#10）关于DL里面各种classifier线性层的称谓：" class="headerlink" title="10）关于DL里面各种classifier线性层的称谓："></a>10）关于DL里面各种classifier线性层的称谓：</h2><ul>
<li>linear：线性层。没有隐层的单层结构。</li>
<li>dense：密集层。可以指单层linear也可以指多层线性层的堆叠，可以没有隐层也可以有，隐层一般大于2。</li>
<li>MLP：多层感知机。多层linear的堆叠，有隐层。</li>
<li>FC：全连接层。单层多层均可，是对linear classifer的一种笼统称谓。<h2 id="11）top-1和top-5"><a href="#11）top-1和top-5" class="headerlink" title="11）top-1和top-5"></a>11）top-1和top-5</h2></li>
</ul>
<p>top-1：预测结果中排名第一的类别与实际结果相符的准确率；</p>
<p>top-5：预测结果中排名前五的类别包含实际结果的准确率。</p>
<h2 id="12）反向传播算法"><a href="#12）反向传播算法" class="headerlink" title="12）反向传播算法"></a>12）反向传播算法</h2><p>反向传播算法由两个阶段组成：激励传播+权重更新</p>
<ul>
<li>激励传播（每次迭代的传播阶段分两步）：<ul>
<li>前向传播：将训练输入送入网络以获得激励响应</li>
<li>反向传播：将激励响应同输入所对应的目标输出求差。以获得输出层和隐藏层的响应误差</li>
</ul>
</li>
<li>权重更新<ul>
<li>先将输入激励和误差响应相乘，获得权重的梯度</li>
<li>再将这个梯度乘上一个比例（训练因子）并取反后加到权重上<h2 id="13）正则化"><a href="#13）正则化" class="headerlink" title="13）正则化"></a>13）正则化</h2><a href="https://daimajiaoliu.com/daima/56a4f0d1f3c8808">深度学习下的正则化</a></li>
</ul>
</li>
</ul>
<p>我们需要通过最小化误差来拟合训练数据。正则化是解决高方差问题的方案之一，也是减小过拟合的方法。</p>
<ul>
<li>l0、l1、l2、l无穷: 限制模型的学习能力<ul>
<li>l2正则化：倾向于使网络的权值接近0，使得前一层神经元对后一层神经元的影响降低，实质上是对权值做线性衰减。</li>
</ul>
</li>
<li>其他方法：<ul>
<li>dropout：在训练过程中，对于每个神经元，概率p保持其为激活状态，概括1-p直接关闭。由于每个神经元都可能会被丢弃，模型训练的时候，模型不会给任何神经元过大的参数</li>
<li>early-stopping<h2 id="14）批正则化Batch-Normalization"><a href="#14）批正则化Batch-Normalization" class="headerlink" title="14）批正则化Batch Normalization"></a>14）批正则化Batch Normalization</h2></li>
</ul>
</li>
</ul>
<p>对数据做批正则化，使得数据满足均值为0，方差为1的正态分布，可以缓解CNN等训练中梯度消失或梯度爆炸的现象，加快模型的训练速度。</p>
<h2 id="15）automatic-differentiation自动微分"><a href="#15）automatic-differentiation自动微分" class="headerlink" title="15）automatic differentiation自动微分"></a>15）automatic differentiation自动微分</h2><p>现代dl系统（比如MXNet，TensorFlow等）都用到了自动微分技术。</p>
<p>自动微分是一种可以借由计算机程序计算一个函数的导数。</p>
<p>自动微分认为，所有数值计算归根结底是一系列有限的可微算子的组合，它是一种介于符号微分和数值微分的方法，本质上是一种图计算。</p>
<h2 id="16）ZCA白化"><a href="#16）ZCA白化" class="headerlink" title="16）ZCA白化"></a>16）ZCA白化</h2><p>白化是一种重要的数据预处理过程，目的是降低输入数据的冗余性，白化后的数据：</p>
<ul>
<li>特征间的相关性较低</li>
<li>所有特征具有相同的方差</li>
</ul>
<p>白化处理分为PCA白化和ZCA白化。前者用于保证数据各维度的方差为1，可以降维也可以去相关；后者保证数据各维度的方差相同，主要用于去相关，且尽量使白化后的数据接近原始输入数据。</p>
<ul>
<li><p>PCA白化：使用PCA求出特征向量，然后把数据X映射到新的特征空间，以去除特征之间的相关性。</p>
</li>
<li><p>ZCA白化，把PCA白化的结果又变换到原来的坐标系下。</p>
</li>
</ul>
<h2 id="17）WRN：Wide-residual-networks"><a href="#17）WRN：Wide-residual-networks" class="headerlink" title="17）WRN：Wide residual networks"></a>17）WRN：Wide residual networks</h2><p>WRN-16-1，0.2M：表示深度16，宽度1，参数量0.2M</p>
<h2 id="18）seed：随机种子"><a href="#18）seed：随机种子" class="headerlink" title="18）seed：随机种子"></a>18）seed：随机种子</h2><p><a href="https://blog.csdn.net/qq_41375609/article/details/99327074">参考</a></p>
<h2 id="19）CUB数据集："><a href="#19）CUB数据集：" class="headerlink" title="19）CUB数据集："></a>19）CUB数据集：</h2><p>Caltech-UCSD Birds-200-2011，FGCV中广泛使用的数据集，包括鸟类的200个子类别的11788张图像，其中5994张用于训练，5794张用于测试。每张图像的注释包括：1 subcategory label, 15 Part Locations, 312 Binary Attributes, 1 Bounding Box。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913172708.png"></p>
<p>需要注意，此数据集的图像与ImageNet中的图像重叠，在使用ImageNet预训练网络时需要小心，因为CUB的测试集可能与原始网络的训练集重叠。</p>
<h2 id="20）Fine-Grained-Visual-Categorization"><a href="#20）Fine-Grained-Visual-Categorization" class="headerlink" title="20）Fine-Grained Visual Categorization"></a>20）Fine-Grained Visual Categorization</h2><p>细粒度视觉分类FGCV，即识别细分类的任务，一般需要同时使用全局图像信息与局部图像信息精准识别图像子类别。</p>
<h2 id="21）MIT-indoor-scene-classification数据集："><a href="#21）MIT-indoor-scene-classification数据集：" class="headerlink" title="21）MIT indoor scene classification数据集："></a>21）MIT indoor scene classification数据集：</h2><p>包括67个室内类别，共15620张图像。</p>
<p><a href="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913173104.png"></a></p>
<h2 id="22）ImageNet数据集"><a href="#22）ImageNet数据集" class="headerlink" title="22）ImageNet数据集"></a>22）ImageNet数据集</h2><p>ImageNet 是根据 WordNet 层次结构组织的图像数据集。WordNet 中的每个有意义的概念，可能由多个单词或单词短语描述，称为同义词集或 synset。</p>
<p>ImageNet 有大约 100 K 个同义词集，平均每个同义词集约有 1,000 个人工注释图像。 ImageNet 仅存储对图像的引用，而图像存储在互联网上的原始位置。在深度学习论文中，ImageNet-1K 是指作为 ImageNet 的大规模视觉识别挑战（ ILSVRC ）的一部分发布的数据集，用于将数据集分类为 1,000 个类别。</p>
<p>简而言之，就是一个巨大的图像数据集！</p>
<h1 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0. 摘要"></a>0. 摘要</h1><p>本文是attention在知识蒸馏中的应用，即，如何定义CNN中的attention，使得学生网络可以通过mimic教师网络的attention maps来提高自己的性能。</p>
<p>为此，本文提出了几种transfer attention的方法，实验证实这些方法在多种数据集和CNN结构中<strong>都</strong>表现良好。</p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>作为人类，attention在visual experience中很关键，同时也与感知密切相关。</p>
<p>在AI方面，artificial attention mechanisms比较流行。</p>
<p>有一种假设是：存在non-attentional perception processes和attentional perception processes。前者可以在观察场景的过程中获取高层次的信息，将这些信息与其他思维过程相关联，可以帮助控制attention processes——将注意力集中于场景中的特定区域。从另一个角度来讲，不同的观察者（教师网络）会拥有不同的知识和不同目标，针对同一个场景，不同的attentional strategies看到的东西也会不一样。这是本文的启发点：人工视觉中的注意力有何不同？我们能否利用注意力信息来提高CNN的性能？更具体来讲，一个教师网络是否可以通过向另一个学生网络提供”它将注意力集中在哪里”的信息，来提高学生网络的性能？</p>
<p>为了解决上述问题，我们首先需要明确的点是：在一个给定的CNN中，注意力机制是如何定义的。我们可以认为注意力是一组spatial maps，这组maps试图encode on网络在做出输出决定时最关注的那些输入区；此外，这组maps可以根据网络的各个层来定义，以便它们能够同时capture低、中、高层的representation information。<strong>更具体来讲，我们定义了两类spatial attention maps：activation-based和gradient-based，然后探索了这两种注意力地图是如何在不同的数据集和网络结构中变化的，并说明了这两种注意力地图确实包含了一些有用信息（这些信息可以显著提高CNN性能）。为此，我们还提出了几种新颖的方法来将注意力从教室网络transfer到学生网络上，来提高后者的性能。</strong></p>
<ul>
<li>【换言之，本文首先定义了两种空间注意力地图，然后论证两种空间注意力地图都对提高CNN性能有帮助，然后提出了几种在知识蒸馏中transfer attention from teacher to students的办法】</li>
</ul>
<p>本文的贡献：</p>
<ul>
<li>我们认为注意力是一种将知识从一个网络转移到另一个网络的机制</li>
<li>我们提出了使用activation-based和gradient-based 空间注意力地图</li>
<li>我们通过实验表明，我们的方法在各种数据集和深度网络架构上都有显著的改进，包括残差和非残差网络</li>
<li>我们发现activation-based attention transfer比full-activation transfer有更好的改善，并且可以与知识蒸馏相结合</li>
</ul>
<h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h1><h1 id="3-attention-transfer"><a href="#3-attention-transfer" class="headerlink" title="3. attention transfer"></a>3. attention transfer</h1><h2 id="3-1-activation-based-attention-transfer"><a href="#3-1-activation-based-attention-transfer" class="headerlink" title="3.1 activation-based attention transfer"></a>3.1 activation-based attention transfer</h2><p>考虑一个CNN层和对应的激活张量<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912231918.png">，C个通道（特征面），每个特征面维度是H x W。activation-based 映射函数F将该3d激活张量作为输入，输出一个2维的spatial attention  map：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912232300.png"></p>
<p>在定义这个空间注意力映射函数F之前，我们需要认可一个潜在的假设：hidden neuron activation（给定输入时网络预测出的结果）的绝对值可以用于指示该神经元的重要性。因此，我们可以通过计算A的绝对值在通道维度上统计结果来构建spatial attention map。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912233056.png"></p>
<p>具体来讲，本文使用以下spatial attention maps：</p>
<ul>
<li>绝对值求和：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912233315.png"></li>
<li>绝对值指数求和：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912233336.png"></li>
<li>绝对值指数求最大值：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912233351.png"></li>
</ul>
<p>我们可视化了多个数据集上的多种网络，包括ImageNet分类和定位，COCO目标检测，人脸识别，以及fine-grained识别。我们主要关注没有顶层dense linear layer的现代结构，比如Network-In-Network，ResNet和Inception，这些网络都是流线型的卷积结构。此外，我们还使用不同的框架，在相同结构、宽度和深度的网络上，通过训练得到了不同的性能。</p>
<p>我们发现，隐层激活的统计信息不但与图像层面上的预测目标具有空间相关性，而且相关性与准确度正相关，即准确度高的网络，相关性也高，更强大的网络有更尖锐的注意力。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210912235644.png"></p>
<p>此外，attention maps针对不同的网络层关注不同的部分。在前面的层，神经元的激活水平对低层次的梯度点来说很高（？）；在中间层，激活水平对最具辨识度的区域（比如眼睛、鼻子、轮廓）来说比较高；而在顶层则反映了完整的物体。例如，为人脸识别而训练的网络的中层注意图在眼睛、鼻子和嘴唇周围会有较高的激活，而顶层的激活将对应于全脸。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913014806.png"></p>
<p>对于上面说的不同的注意力映射函数，有一些属性上的小差别：</p>
<ul>
<li>与<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913015113.png">相比，<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913015139.png">对有更高激活的神经元的空间位置有更大权重，比如，对最具辨识度的部分设置了更大的权重（p越大，对高激活区域的关注度越高）；</li>
<li>此外，在同一个空间位置的所有神经元激活中，<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913015823.png">只会考虑其中之一来为该空间位置设置权重；相反，<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913015933.png">更倾向于多个神经元高激活的区域（？？？）。</li>
</ul>
<p>为了进一步说明这些函数的区别，我们可视化了3个性能不同的网络：Network-In-Network (62% top-1 val accuracy), ResNet-34 (73% top-1 val accuracy) and ResNet-101 (77.3% top-1 val accuracy)，每个网络取最后一个下采样前的activation maps，上图左边是中间层，右边是顶层平均池化前的激活图。顶层地图略模糊，因为其原始分辨率只有7*7，很明显，具有辨识度的区域有更高的激活级别。比如，狼的脸。当p减小时，可以看到形状细节消失了。</p>
<p>在attention transfer中，给定教师网络的spatial attention maps（该map使用上面的attention映射函数计算得到），我们的目标是训练一个学生网络，该网络不只能做正确的预测，还要有和教师相似的attention maps。通常，可以在每一层上计算attention maps的transfer losses。比如，在ResNet中，根据教师和学生的深度考虑以下两种情况：</p>
<ul>
<li>相同深度：在每个残差块后做attention transfer；</li>
<li>不同深度：在每个残差块组后做attention transfer。（如图）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913022058.png"></p>
<p>类似的情况也可以应用于其他网络结构（比如NIN，一组是指一个3 × 3,1 × 1,1 × 1的卷积块）。</p>
<h3 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h3><p>我们假设转移损失被置于相同空间分辨率的学生和教师的注意力图之间，但如果需要，attention maps可以插值以匹配它们的形状（？？？）。</p>
<p>学生网络j-th激活图的向量表示：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913091853.png"></p>
<p>教师网络j-th激活图的向量表示：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913091931.png"></p>
<p>损失函数定义为：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913023100.png"></p>
<p>其中W是权重，<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913023219.png">是标准交叉熵【前面那部分可以理解为likelihood，后面那部分是教师网络给的先验知识？？】</p>
<p>attention transfer也可以和知识蒸馏相结合，损失函数定义为：<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913023825.png"></p>
<h1 id="3-2-Gradient-based-attention-transfer"><a href="#3-2-Gradient-based-attention-transfer" class="headerlink" title="3.2 Gradient-based attention transfer"></a>3.2 Gradient-based attention transfer</h1><p>我们将注意力定义为输入的梯度。这里输入的梯度可以看做输入敏感地图，输入空间位置对应的注意力编码了输出预测对该输入位置变化的灵敏度（比方说，如果一个像素的小变化可以对网络的输出造成较大的影响，我们就可以合理假设网络“paying attention to”那个像素）。下式定义了教师和学生的输入损失的梯度：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913093505.png"></p>
<p>然后，为了让学生的gradient attention与教师的更接近，我们最小化二者的距离：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913100632.png"></p>
<p>因为WT和x都是给定的，我们求上式关于Ws的导数：[??????????????]</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913100826.png"></p>
<p>所以，为了做一次更新，我们需要先做一个前向传播和反向传播来得到Js和JT（？？？），计算第二部分那个二范数误差，然后再做一次传播。第二次传播与这里的前向传播相似，包括二阶混合偏导数。上述计算类似于D&amp;L的双反向传播技术。此外，它可以在支持automatic differentiation的框架里实现，而在具有复杂图的现代框架中也可以实现。除了正向传播外，第二次反向传播的代价与第一次反向的代价差不多。<br>所以，为了做一次更新，我们需要先做一个前向传播和反向传播来得到Js和JT（？？？），计算第二部分那个二范数误差，然后再做一次传播。第二次传播与这里的前向传播相似，包括二阶混合偏导数。上述计算类似于D&amp;L的双反向传播技术。此外，它可以在支持automatic differentiation的框架里实现，而在具有复杂图的现代框架中也可以实现。除了正向传播外，第二次反向传播的代价与第一次反向的代价差不多。（？？？？？？）</p>
<p>我们还提出了要使gradient attention map上水平翻转不变。为了做到这点，我们将原图和水平翻转后的图像都做传播，反向传播并翻转gradient attention maps。在得到的attentions和输出的二范数损失，再做第二次BP：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913104353.png"></p>
<p>这与Cohen &amp;Welling(2016)的Group Equivariant CNN方法相似，但并不是硬性约束。我们实验发现，这对训练有正则化作用。</p>
<p>值得注意的是，在本文中我们只考虑输入层的梯度，但是一般情况下，可能需要在更高层的网络中考虑attention transfer和对称约束。</p>
<h1 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h1><p>我们在多种图像分类数据集上作做attention transfer。第一部分中，我们在CIFAR数据集上做activation-based attention transfer和gradient-based attention transfer的实验；在第二部分中，我们在更大的数据集上做activation-based attention transfer的实验。</p>
<p>对于activation-based attention transfer，我们使用相比于AlexNet或者VGG而言性能更好的NIN和ResNet-based结构（Wide Residual Network），在Scenes，CUB和ImageNet数据集上，我们使用ResNet-18和ResNet-34进行实验。</p>
<p>对于gradient-based attention transfer，由于需要复杂的自动微分，我们将实验限制在没有批正则化的NIN网络和CIFAR数据集上。</p>
<h2 id="4-1-CIFAR实验"><a href="#4-1-CIFAR实验" class="headerlink" title="4.1 CIFAR实验"></a>4.1 CIFAR实验</h2><p>CIFAR数据集，包含60000张彩色图片，分为10个类型，图片大小为32*32。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913140826.png"></p>
<p>下采样后，顶层的activations的分辨率会更小，因此看上去并没有很多的空间留给attention transfer。但有趣的是，即便在这种情况下，attention transfer依然可以提高所有cases的性能。我们使用水平翻转和随机剪裁来做数据增强，并且所有的网络都进行了批正则化。我们发现ZCA whitening对有效的准确率有负面影响，因此为了更简单的meanst normalization而省略了它。</p>
<p>我们将ResNet transfer的知识蒸馏的温度t提高到4(温度越高，概率分布越平滑)，使用 $\alpha=0.9$。</p>
<h3 id="4-1-1-Activation-based-attention-transfer"><a href="#4-1-1-Activation-based-attention-transfer" class="headerlink" title="4.1.1 Activation-based attention transfer"></a>4.1.1 Activation-based attention transfer</h3><p>在CIFAR-10数据集上，多种网络的attention transfer（使用<img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913145430.png">注意力地图）结果如表所示：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913145517.png"></p>
<ul>
<li>教师网络与学生网络具有相同的深度：WRN-16-1/WRN-16-2</li>
<li>教授网络与学生网络具有不同的深度：WRN-16-1/WRN-40-1; WRN-16-2/WRN-40-2</li>
</ul>
<p>表中数据单位是<code>Percentage error</code>，是使用不同的随机seed跑了5次后的平均分类错误率，AT都有显著提升(对比原students)，当AT+KD时，网络效果最好【！但是单纯的AT好像没有KD效果好】。</p>
<p>F-ActT是full-activation transfer</p>
<p>为了验证在WRN transfer中每组有至少一个activation-based attention transfer是否重要，我们分别在组1、组2和组3中训练了每个网络只有一个转移损失的三个网络，并与用所有三个损失训练的网络进行比较。相应的结果是8.11、7.96、7.97（单独的损失）和综合损失的7.93（使用WRN16-2/WRN-16-1作为教师/学生对）。每项损失都提供了某种程度的额外注意力转移。【<strong>这个步骤是为了验证每个group的AT都是有一些作用的</strong>】</p>
<p>我们还探索了使用WRN-16-1和WRN16-2对时哪种注意力映射函数表现最好，结果如下表所示：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913154439.png"></p>
<p>有趣的是，基于总和的函数效果非常相似，而且比基于最大值的函数更好【<strong>why？</strong>】。从现在起，我们将使用注意力映射函数F2的平方之和。至于公式2中的参数β，它通常变化在0.1左右，因为我们设置为：$10^3/attention map上的元素数量和每层的batch size$ 。在结合AT和KD的情况下，为了简化学习较难的例子，我们在transfer的过程中衰减了它。</p>
<h3 id="4-1-2-Activation-based-AT-对比-Transfering-full-activation"><a href="#4-1-2-Activation-based-AT-对比-Transfering-full-activation" class="headerlink" title="4.1.2 Activation-based AT 对比 Transfering full activation"></a>4.1.2 Activation-based AT 对比 Transfering full activation</h3><p>为了检查从full-activation转移信息是否比从attention map转移信息更有利，我们实验了FitNets-style hints，直接在全激活层上使用l2损失，用1×1卷积层来匹配张量形状，发现相比其他transfer，这种方法对学生baseline的改进是最小的（见表1的F-ActT列）。</p>
<p>对于相同宽度不同深度的网络，我们尝试直接回归到激活，没有1×1卷积。我们还在转移损失之前使用l2正则化，并在训练期间衰减β，因为这些都能提供更好的性能。如图所示，我们发现，AT和全激活转移一样，都大大加快了收敛速度，但AT相比full-activation transfer对准确率的提高效果更好。由此可见，attention maps相比于full activation，携带了更多的对transfer比较重要的信息。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913160555.png"></p>
<ul>
<li>bold line是测试结果，dashed line是训练结果，可以看到在WRN-16-2—WRN-16-1的transfer中，AT和F-ActT收敛都挺快，但是AT最终的结果略好一些。</li>
</ul>
<h3 id="4-1-3-Gradient-based-attention-transfer"><a href="#4-1-3-Gradient-based-attention-transfer" class="headerlink" title="4.1.3 Gradient-based attention transfer"></a>4.1.3 Gradient-based attention transfer</h3><p>为了简单起见，我们在这些实验中使用了thin Network-in-Network模型，并且没有做批量正则化中的随机剪裁，只是进行了水平翻转的数据增强【因为梯度求导啥的比较难算】。我们也只使用确定性的算法和固定种子的采样，所以实验结果来自单次运行的实验【前面是5次的平均】。我们发现，在这种设置下，网络已经很难适应训练数据了，所以即使在基线实验中也要关闭权重衰减。</p>
<p>在未来，我们计划使用批量归一化来探索师生对的gradient-based attention，因为到目前为止还不清楚批量归一化在gradient-based attention transfer中的第二个反向传播步骤中应该如何表现（例如，不知道它是有助于批量归一化参数，or is a separate forward propagation with fixed parameters needed【？？？】）。</p>
<p>我们探索了以下方法：</p>
<ul>
<li>最小化输入梯度的l2范数，即双重反向传播方法【双反向传播正则化使Jacobian 矩阵偏小】 </li>
<li>gradient attention map的对称范数（公式Lsym）</li>
<li>学生-老师gradient-based attention transfer（不加对称约束的gradient版本）</li>
<li>学生-老师activation-based attention transfer</li>
</ul>
<p>各种方法的结果显示在下表中：</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913163920.png"></p>
<p>有趣的是，仅仅最小化梯度的l2准则就已经很好了。另外，对称norm也是表现最好的注意力准则之一，我们计划将来在其他数据集上也进行研究。我们还观察到，与activation-based AT类似，使用gradient-based AT也会使性能提高。我们还在相同的训练条件下用activation-based AT训练了一个网络，结果在所有方法中表现最好。<strong>我们应该注意到，没有批量规范化的学生NIN的结构与教师网络略有不同，它在池化层之前没有ReLU激活，这导致没有批量规范化的性能更好</strong>。因此，为了达到activation-based AT的最佳性能，我们必须训练一个新的教师，在池化层之前没有ReLU激活，并且在卷积层的输出上有AT损失。【结果呢？】</p>
<h2 id="4-2-Large-input-image-network"><a href="#4-2-Large-input-image-network" class="headerlink" title="4.2 Large input image network"></a>4.2 Large input image network</h2><p>在本节中，我们在输入图像大小为224 × 224的ImageNet网络上进行了隐层activation-based transfer的实验。据推测，在这类网络中，注意力更为重要，因为注意力地图的空间分辨率更高。</p>
<h3 id="4-2-1-transfer-learning"><a href="#4-2-1-transfer-learning" class="headerlink" title="4.2.1 transfer learning"></a>4.2.1 transfer learning</h3><p>【微调就是预训练一个网络，然后在新的数据集上微调】<br>为了了解attention transfer在微调中的作用，我们选择了两个数据集。Caltech-UCSD Birds-200-2011 fine-grained classification（CUB）和MIT室内场景分类（Scenes），两者都包含大约5K的图像训练图像。我们采用ResNet-18和ResNet-34在ImageNet上进行预训练，并在这两个数据集上进行了微调。在CUB上，我们裁剪边界框，在一个维度上重新缩放到256，然后采取随机裁剪。微调时，固定批量正则层，冻结第一组残余块。然后，我们把经过微调的ResNet-34网络作为在ImageNet上预训练的ResNet-18的老师，使用最后两组的F2sum attention loss 【第一组被冻结了】。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913174040.png"></p>
<p>如表所示，在这两种情况下，attention transfer都提供了明显的改进，缩小了ResNet-18和ResNet-34在准确性上的差距。在Scenes上，AT的效果和KD一样好，而在CUB上，AT的效果要好得多，我们推测这是因为中间注意力对细粒度识别的重要性。此外，经过微调后，学生的注意力图确实与教师的注意力图更加相似。【对于细粒度的重要性可不可以有别的验证方式？？？至少也像下面这样给个图吧orz】</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913174420.png"></p>
<ul>
<li>顶层activation attention map：列1是微调前的（会有分类错误），列2是学生网络，列3是AT后的，列4是教师网络，效果理论上该越来越好。比如行1就越来越接近室内的场景结构【可以用线框模型画一下图！attention map能不能用到室内场景场景建模上，即使是分类错误的预训练模型，也感觉可以得到结构信息！！！】</li>
</ul>
<h3 id="4-2-2-ImageNet"><a href="#4-2-2-ImageNet" class="headerlink" title="4.2.2 ImageNet"></a>4.2.2 ImageNet</h3><p>为了在ImageNet上展示activation-based AT，我们把ResNet-18作为学生，把ResNet-34作为老师，并试图提高ResNet-18的准确性。</p>
<p>我们在最后两组残余块中增加了两个损失，并使用F2sum。我们也没有时间调整任何超参数，并阻止它们进行微调。尽管如此，带有AT的ResNet-18取得了1.1% top-1和0.8% top-5的较好validation accuracy，<strong>我们计划用所有的4组残余块的损失来进阶我们的论文</strong>。</p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913180258.png"></p>
<p><img src="https://raw.githubusercontent.com/OrderAngel/Picture/main/study/paper/20210913180400.png"></p>
<ul>
<li>solid lines代表top-5 validation error，dashed lines代表top-5 training error。只用了AT损失，没用KD。</li>
</ul>
<p>我们没能用KD在ImageNet上取得积极的结果。在ResNet-18-ResNet-34师生对中，它实际上损害了与CIFAR上相同的超参数的收敛性【？】。如果教师和学生有不同的架构/深度，KD就很难发挥作用（我们在CIFAR上观察到同样的情况）【why？？？】，因此我们尝试使用相同的架构和深度来transfer attention【不知道是不是笔误，但是AT没用相同的深度吧？，还是说KD必须深度相同，但是AT不用？应该是笔误，深度相同结构也相同还迁移个啥！】。</p>
<p>在CIFAR上，AT和KD在这种情况下都工作得很好，并且提高了收敛性和最终的准确性，但在ImageNet上，KD的收敛速度明显较慢（由于缺乏计算资源，我们没有训练到最后）。我们在文献中也找不到FitNets、KD或类似方法在ImageNet上的应用。鉴于此，我们可以认为提出的基于激活的AT是第一个在ImageNet上成功应用的知识转移方法。【为啥那俩用不了？？？】</p>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><p>我们提出了几种（2种）将注意力从一个网络转移到另一个网络的方法，并对几个图像识别数据集进行了实验结果。有趣的是，在空间信息更重要的情况下（例如目标检测或弱监督定位）attentio transfer是如何工作的，这也是我们<strong>计划在未来探索的问题</strong>。</p>
<p>总的来说，我们认为我们的方法将有助于知识蒸馏的进一步发展，也有助于卷积神经网络的普遍理解。</p>
<h1 id="6-问题"><a href="#6-问题" class="headerlink" title="6. 问题"></a>6. 问题</h1><ol>
<li><p>这两种注意力地图有啥区别</p>
</li>
<li><p>知识蒸馏是迁移学习的一种，attention在transfer learning中的其他应用</p>
</li>
<li><p>数据集ImageNet等</p>
</li>
<li><p>beita是什么</p>
</li>
<li><p>教师网络给学生网络注意力地图不是已经是知识蒸馏了吗？为何还可以与知识蒸馏相结合重新定义损失函数？</p>
<p>solution：文章刚出炉那会，AT还不属于知识蒸馏的方法，文中的KD指的就是开山的那篇soft-target辅助hard-target一起训练的文章；</p>
</li>
<li><p>水平翻转不变性有啥作用？对于训练有正则化作用？？</p>
<p>此处的水平翻转是数据增广的一种方案，数据增广可以减少过拟合</p>
<p>不过，为什么只做水平翻转？？？</p>
<p>因为有的动物图片翻转后就是倒着的了，没有实际意义；但是对于人脸这种具有对称结构的情况来说，只做左右翻转没有太大意义，无对称结构的图还有有用的！</p>
<p>除了水平翻转，或许还可以部分置黑</p>
</li>
<li><p>如何在更高层的网络中考虑attention transfer</p>
</li>
<li><p>文章中的attention蒸馏适用于教师模型和学生模型整体结构类似的情况</p>
</li>
<li><p> 本文的ATLoss可以与RKD、PKT、SP、VID等用来学习网络最终输出蒸馏的方式结合使用，仿佛：AT和PKT结合会产生不错的效果</p>
</li>
<li><p>可以介绍一下其他知识蒸馏的方法，再说结合使用的好处</p>
</li>
<li><p>文章是分类，能否在目标检测中使用</p>
</li>
<li><p>从第一个实验的结果来看，层数更高AT效果更好，wider的话KD效果更好，但是也有结合后效果不好的，文章没有专门对比KD和AT，也没有对结合后效果不好的情况专门做讨论。</p>
</li>
<li><p>使用批量归一化来探索师生对的gradient-based attention</p>
</li>
<li><p>symmetry norm在其他数据集上的表现</p>
</li>
<li><p>l1正则化也行：文章只说了也行，但确实没做实验，未来可以探索一下</p>
</li>
<li><p>查一下作者对gradient和symmetry的探索</p>
</li>
<li><p>白化不好，但没实验</p>
</li>
<li><p>4.2.2是不是笔误，因为网络结构相同可以理解，但是深度肯定要不同啊。</p>
</li>
<li><p>如果网络结构不同，怎么知识蒸馏？为什么结构不同不行？</p>
</li>
</ol>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
</search>
